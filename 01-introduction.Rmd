\mainmatter

# Introduction {#intro}


What is machine learning and why is it important?

Black box

Why is explainability important?


Outline of the book.



Definition of interpretability / explainability


System is interpretable if it falls into certain class of models, where authors claim that this class is interpretable and the authors present algorithms to optimize within that class. [Towards A Rigorous Science of Interpretable Machine Learning]

There is no good definition of interpretability yet?



Classic statistics usually aims at having interpretable models. That's why doctors, sociologists and banks tend to go to statisticians with research questions instead of computer scientists.



Some systems need more interpretability. The more impactful the decision, the more explainable it should be. A possibly incorrect product recommendation might is not as bad as a wrong diagnose and recommendation of an inappropriate treatment.


Need for explainability arises when something goes wrong. Because having an explanation for a faulty classification helps to understand the cause of the fault. It delivers a direction for how to fix the system. Consider an example of a husky versus wolf classifier, that missclassifies some huskys as wolfs. If there is an explanation to the classification you can see, that the missclassification happend due to the snow on the image. The classifier learned to use snow as a feature for classifying images as wolfs, which might make sense in terms of separating features in the training data set, but not in the real world use.  [TODO: Add image from Ribeiro + ask for permission]




As a machine learning practitioner, your main goal is to drive down the loss function while also keeping the learned model generalizable to other data sets.




## Is good user experience enough?
Maybe it is enough to show that the algorithm works and does what it is supposed to. The recommended movies are all reasonable and my self-driving car never had an accident.


We have to distinguish between between low and high stakes scenario and individual risks and systematic biases.


For low-risk applications (e.g. product recommender systems) there is not so much damage if something goes wrong. No one will die because they got a product recommendation on Amazon for something they are not interested in. Biggest risk is for the company deploying those algorithms that they do not work and loose customers to competitors.
But there is the risk for a systematic bias and while for each individual the impact might be negligible on a group or society level it is quite problematic. Social bubbles through newsfeeds? An example is a restaurant recommender system that would never recommend restaurants to a certain minority, because they are from that minority. 

High risk applications are self-driving cars, AI doctors etc. Here it is quite important to have explainability. Only with explainability can you 'debug' why a car accident happend by a self-driving car or decide if you want to trust the diagnose of a machine learning algorithm.
