# Datasets
Throughout the book all the models and techniques will be used on real datasets, which are freely available online.
We will be using different datasets for different types of problems: classification, regression and text classification.

## Bike sharing counts (regression) {#bike.data}
This dataset contains daily counts of bike rentals from bike sharing company [Capital-Bikeshare](https://www.capitalbikeshare.com/) in Washington D.C., including weather and seasonal information.
The data is kindly open source by Capital-Bikeshare and the folks from [@bike2013] have added  weather data and seasonal information. The goal is to predict how many rental bike will be out on the street given weather and day. The data can be downloaded from the [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset).


Variables in the dataset:

- instant: record index
- dteday : date
- season : season (1:springer, 2:summer, 3:fall, 4:winter)
- yr : year (0: 2011, 1:2012)
- mnth : month ( 1 to 12)
- hr : hour (0 to 23)
- holiday : weather day is holiday or not (extracted from [Web Link])
- weekday : day of the week
- workingday : if day is neither weekend nor holiday is 1, otherwise is 0.
+ weathersit :
- 1: Clear, Few clouds, Partly cloudy, Partly cloudy
- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist
- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds
- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog
- temp : Temperature in Celsius
- atemp: Feeling temperature in Celsius
- hum: Humidity
- windspeed: Wind speed in km per hour
- casual: count of casual users
- registered: count of registered users
- cnt: count of total rental bikes including both casual and registered


You can look at a sample of 50 dates here:
```{r show-bike-count-data}
source(sprintf('%s/get_bike_sharing_dataset.R', src_dir))

set.seed(42)
bike.raw.display = bike.raw[sample(1:nrow(bike.raw), size=50), ]

DT::datatable(bike.raw.display, options = list(scrollX=TRUE))
```

## Youtube spam comments (text classification) {#spam.data}
As an example for text classification we will be using 1956 comments from 5 different YouTube videos . Thankfully the authors that used this dataset in a paper about spam classification made the data  [freely available](http://dcomp.sor.ufscar.br/talmeida/youtubespamcollection/) [@alberto2015tubespam].

Data was collected through the YouTube API from five of the ten most viewed videos
on YouTube in the first half of 2015. All of the 5 videos are music videos. One of them is the wildly popular "Gangnam Style" from korean artist Psy. The other artists where Katy Perry, LMFAO, Eminem and Shakira.


You can flip through the comments. The comments had been hand labeled as spam or legitimate.
Spam has been coded with a '1' and legitimate comments with a '0'.
<br />
<br />

```{r show-dating-data-TubeSpam}
tube_spam = read.csv(sprintf('%s/TubeSpam.csv', data_dir))

DT::datatable(tube_spam[c('CONTENT', 'CLASS')], options = list(scrollX=TRUE))
```
<br />
<br />

You could also go over to YouTube and have a look at the comment section. But please don't get trapped in the YouTube hell, ending up watching videos about monkeys stealing and drinking coktails from tourists on the beach. Also the Google Spam detector probably has changed a lot since 2015. Watch the view-record breaking video below "Gangnam Style" below:

<iframe width="560" height="315" src="https://www.youtube.com/embed/9bZkp7q19f0" frameborder="0" allowfullscreen></iframe>

## Risk factors for cervical cancer (classification) {#cervical.data}

The cervical cancer dataset contains indicators and risk factors for predicting if a woman gets cervical cancer. The features contain demograpics (e.g. age), habits and medical history. The data can be downloaded from the [UCI Machine Learning repository](https://archive.ics.uci.edu/ml/datasets/Cervical+cancer+%28Risk+Factors%29).

The variable contained in the dataset are:

- (int) Age
- (int) Number of sexual partners
- (int) First sexual intercourse (age)
- (int) Num of pregnancies
- (bool) Smokes
- (bool) Smokes (years)
- (bool) Smokes (packs/year)
- (bool) Hormonal Contraceptives
- (int) Hormonal Contraceptives (years)
- (bool) IUD
- (int) IUD (years)
- (bool) STDs
- (int) STDs (number)
- (bool) STDs:condylomatosis
- (bool) STDs:cervical condylomatosis
- (bool) STDs:vaginal condylomatosis
- (bool) STDs:vulvo-perineal condylomatosis
- (bool) STDs:syphilis
- (bool) STDs:pelvic inflammatory disease
- (bool) STDs:genital herpes
- (bool) STDs:molluscum contagiosum
- (bool) STDs:AIDS
- (bool) STDs:HIV
- (bool) STDs:Hepatitis B
- (bool) STDs:HPV
- (int) STDs: Number of diagnosis
- (int) STDs: Time since first diagnosis
- (int) STDs: Time since last diagnosis
- (bool) Dx:Cancer
- (bool) Dx:CIN
- (bool) Dx:HPV
- (bool) Dx
- (bool) Hinselmann: target variable
- (bool) Schiller: target variable
- (bool) Cytology: target variable
- (bool) Biopsy: target variable

As the biopsy serves as the gold standard for diagnosing cervical cancer, the classification tasks in this book used the biopsy outcome as the target.
Missing values for each column were imputed by the mode (most frequent value), which is probably a bad solution, because the value of the answer might be correlated with the probability for missingness.
There is probably this bias, because the question are of a very private nature.
But this is not a book about missing data imputation, so the mode imputation will suffice!

<br />
<br />

```{r show-cervical-data}
cervical = read.csv(sprintf('%s/risk_factors_cervical_cancer.csv', data_dir))

DT::datatable(cervical, options = list(scrollX=TRUE))
```
<br />
<br />



[@fernandes2017transfer]
