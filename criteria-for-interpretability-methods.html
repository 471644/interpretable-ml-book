<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Interpretable Machine Learning</title>
  <meta name="description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisions more interpretable.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Interpretable Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisions more interpretable." />
  <meta name="github-repo" content="christophM/interpretable-ml-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Interpretable Machine Learning" />
  
  <meta name="twitter:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisions more interpretable." />
  

<meta name="author" content="Christoph Molnar">


<meta name="date" content="2018-05-24">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="interpretability-importance.html">
<link rel="next" href="scope-of-interpretability.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110543840-1"></script>
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-110543840-1', 'https://christophm.github.io/interpretable-ml-book/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>



<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Interpretable machine learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="storytime.html"><a href="storytime.html"><i class="fa fa-check"></i><b>1.1</b> Storytime</a><ul>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#lightning-never-strikes-twice"><i class="fa fa-check"></i>Lightning Never Strikes Twice</a></li>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#trust-fall"><i class="fa fa-check"></i>Trust Fall</a></li>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#fermis-paperclips"><i class="fa fa-check"></i>Fermi’s Paperclips</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html"><i class="fa fa-check"></i><b>1.2</b> What Is Machine Learning?</a></li>
<li class="chapter" data-level="1.3" data-path="definitions.html"><a href="definitions.html"><i class="fa fa-check"></i><b>1.3</b> Definitions</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="interpretability.html"><a href="interpretability.html"><i class="fa fa-check"></i><b>2</b> Interpretability</a><ul>
<li class="chapter" data-level="2.1" data-path="interpretability-importance.html"><a href="interpretability-importance.html"><i class="fa fa-check"></i><b>2.1</b> The Importance of Interpretability</a></li>
<li class="chapter" data-level="2.2" data-path="criteria-for-interpretability-methods.html"><a href="criteria-for-interpretability-methods.html"><i class="fa fa-check"></i><b>2.2</b> Criteria for Interpretability Methods</a></li>
<li class="chapter" data-level="2.3" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html"><i class="fa fa-check"></i><b>2.3</b> Scope of Interpretability</a><ul>
<li class="chapter" data-level="2.3.1" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#algorithm-transparency"><i class="fa fa-check"></i><b>2.3.1</b> Algorithm transparency</a></li>
<li class="chapter" data-level="2.3.2" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-holistic-model-interpretability"><i class="fa fa-check"></i><b>2.3.2</b> Global, Holistic Model Interpretability</a></li>
<li class="chapter" data-level="2.3.3" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-model-interpretability-on-a-modular-level"><i class="fa fa-check"></i><b>2.3.3</b> Global Model Interpretability on a Modular Level</a></li>
<li class="chapter" data-level="2.3.4" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#local-interpretability-for-a-single-prediction"><i class="fa fa-check"></i><b>2.3.4</b> Local Interpretability for a Single Prediction</a></li>
<li class="chapter" data-level="2.3.5" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#local-interpretability-for-a-group-of-prediction"><i class="fa fa-check"></i><b>2.3.5</b> Local Interpretability for a Group of Prediction</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="evaluating-interpretability.html"><a href="evaluating-interpretability.html"><i class="fa fa-check"></i><b>2.4</b> Evaluating Interpretability</a><ul>
<li class="chapter" data-level="2.4.1" data-path="evaluating-interpretability.html"><a href="evaluating-interpretability.html#approaches-for-evaluating-the-interpretability-quality"><i class="fa fa-check"></i><b>2.4.1</b> Approaches for Evaluating the Interpretability Quality</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="explanation.html"><a href="explanation.html"><i class="fa fa-check"></i><b>2.5</b> Human-style Explanations</a><ul>
<li class="chapter" data-level="2.5.1" data-path="explanation.html"><a href="explanation.html#what-is-an-explanation"><i class="fa fa-check"></i><b>2.5.1</b> What is an explanation?</a></li>
<li class="chapter" data-level="2.5.2" data-path="explanation.html"><a href="explanation.html#good-explanation"><i class="fa fa-check"></i><b>2.5.2</b> What is a “good” explanation?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>3</b> Datasets</a><ul>
<li class="chapter" data-level="3.1" data-path="bike-data.html"><a href="bike-data.html"><i class="fa fa-check"></i><b>3.1</b> Bike Sharing Counts (Regression)</a></li>
<li class="chapter" data-level="3.2" data-path="spam-data.html"><a href="spam-data.html"><i class="fa fa-check"></i><b>3.2</b> YouTube Spam Comments (Text Classification)</a></li>
<li class="chapter" data-level="3.3" data-path="cervical.html"><a href="cervical.html"><i class="fa fa-check"></i><b>3.3</b> Risk Factors for Cervical Cancer (Classification)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple.html"><a href="simple.html"><i class="fa fa-check"></i><b>4</b> Interpretable Models</a><ul>
<li class="chapter" data-level="4.1" data-path="limo.html"><a href="limo.html"><i class="fa fa-check"></i><b>4.1</b> Linear Model</a><ul>
<li class="chapter" data-level="4.1.1" data-path="limo.html"><a href="limo.html#interpretation"><i class="fa fa-check"></i><b>4.1.1</b> Interpretation</a></li>
<li class="chapter" data-level="4.1.2" data-path="limo.html"><a href="limo.html#interpretation-example"><i class="fa fa-check"></i><b>4.1.2</b> Interpretation Example</a></li>
<li class="chapter" data-level="4.1.3" data-path="limo.html"><a href="limo.html#interpretation-templates"><i class="fa fa-check"></i><b>4.1.3</b> Interpretation templates</a></li>
<li class="chapter" data-level="4.1.4" data-path="limo.html"><a href="limo.html#visual-parameter-interpretation"><i class="fa fa-check"></i><b>4.1.4</b> Visual parameter interpretation</a></li>
<li class="chapter" data-level="4.1.5" data-path="limo.html"><a href="limo.html#explaining-single-predictions"><i class="fa fa-check"></i><b>4.1.5</b> Explaining Single Predictions</a></li>
<li class="chapter" data-level="4.1.6" data-path="limo.html"><a href="limo.html#cat-code"><i class="fa fa-check"></i><b>4.1.6</b> Coding Categorical Features</a></li>
<li class="chapter" data-level="4.1.7" data-path="limo.html"><a href="limo.html#the-disadvantages-of-linear-models"><i class="fa fa-check"></i><b>4.1.7</b> The disadvantages of linear models</a></li>
<li class="chapter" data-level="4.1.8" data-path="limo.html"><a href="limo.html#do-linear-models-create-good-explanations"><i class="fa fa-check"></i><b>4.1.8</b> Do linear models create good explanations?</a></li>
<li class="chapter" data-level="4.1.9" data-path="limo.html"><a href="limo.html#extending-linear-models"><i class="fa fa-check"></i><b>4.1.9</b> Extending Linear Models</a></li>
<li class="chapter" data-level="4.1.10" data-path="limo.html"><a href="limo.html#sparse-linear"><i class="fa fa-check"></i><b>4.1.10</b> Sparse linear models</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="logistic.html"><a href="logistic.html"><i class="fa fa-check"></i><b>4.2</b> Logistic Regression</a><ul>
<li class="chapter" data-level="4.2.1" data-path="logistic.html"><a href="logistic.html#whats-wrong-with-linear-regression-models-for-classification"><i class="fa fa-check"></i><b>4.2.1</b> What’s Wrong with Linear Regression Models for Classification?</a></li>
<li class="chapter" data-level="4.2.2" data-path="logistic.html"><a href="logistic.html#logistic-regression"><i class="fa fa-check"></i><b>4.2.2</b> Logistic Regression</a></li>
<li class="chapter" data-level="4.2.3" data-path="logistic.html"><a href="logistic.html#interpretation-1"><i class="fa fa-check"></i><b>4.2.3</b> Interpretation</a></li>
<li class="chapter" data-level="4.2.4" data-path="logistic.html"><a href="logistic.html#example"><i class="fa fa-check"></i><b>4.2.4</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="tree.html"><a href="tree.html"><i class="fa fa-check"></i><b>4.3</b> Decision Tree</a><ul>
<li class="chapter" data-level="4.3.1" data-path="tree.html"><a href="tree.html#interpretation-2"><i class="fa fa-check"></i><b>4.3.1</b> Interpretation</a></li>
<li class="chapter" data-level="4.3.2" data-path="tree.html"><a href="tree.html#interpretation-example-1"><i class="fa fa-check"></i><b>4.3.2</b> Interpretation Example</a></li>
<li class="chapter" data-level="4.3.3" data-path="tree.html"><a href="tree.html#advantages"><i class="fa fa-check"></i><b>4.3.3</b> Advantages</a></li>
<li class="chapter" data-level="4.3.4" data-path="tree.html"><a href="tree.html#disadvantages"><i class="fa fa-check"></i><b>4.3.4</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="rulefit.html"><a href="rulefit.html"><i class="fa fa-check"></i><b>4.4</b> RuleFit</a><ul>
<li class="chapter" data-level="4.4.1" data-path="rulefit.html"><a href="rulefit.html#interpretation-and-example"><i class="fa fa-check"></i><b>4.4.1</b> Interpretation and Example</a></li>
<li class="chapter" data-level="4.4.2" data-path="rulefit.html"><a href="rulefit.html#guidelines"><i class="fa fa-check"></i><b>4.4.2</b> Guidelines</a></li>
<li class="chapter" data-level="4.4.3" data-path="rulefit.html"><a href="rulefit.html#theory"><i class="fa fa-check"></i><b>4.4.3</b> Theory</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="other-interpretable-models.html"><a href="other-interpretable-models.html"><i class="fa fa-check"></i><b>4.5</b> Other Interpretable Models</a><ul>
<li class="chapter" data-level="4.5.1" data-path="other-interpretable-models.html"><a href="other-interpretable-models.html#naive-bayes-classifier"><i class="fa fa-check"></i><b>4.5.1</b> Naive Bayes classifier</a></li>
<li class="chapter" data-level="4.5.2" data-path="other-interpretable-models.html"><a href="other-interpretable-models.html#k-nearest-neighbours"><i class="fa fa-check"></i><b>4.5.2</b> K-Nearest Neighbours</a></li>
<li class="chapter" data-level="4.5.3" data-path="other-interpretable-models.html"><a href="other-interpretable-models.html#and-so-many-more"><i class="fa fa-check"></i><b>4.5.3</b> And so many more …</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="agnostic.html"><a href="agnostic.html"><i class="fa fa-check"></i><b>5</b> Model-Agnostic Methods</a><ul>
<li class="chapter" data-level="5.1" data-path="pdp.html"><a href="pdp.html"><i class="fa fa-check"></i><b>5.1</b> Partial Dependence Plot (PDP)</a><ul>
<li class="chapter" data-level="5.1.1" data-path="pdp.html"><a href="pdp.html#examples"><i class="fa fa-check"></i><b>5.1.1</b> Examples</a></li>
<li class="chapter" data-level="5.1.2" data-path="pdp.html"><a href="pdp.html#advantages-1"><i class="fa fa-check"></i><b>5.1.2</b> Advantages</a></li>
<li class="chapter" data-level="5.1.3" data-path="pdp.html"><a href="pdp.html#disadvantages-1"><i class="fa fa-check"></i><b>5.1.3</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="ice.html"><a href="ice.html"><i class="fa fa-check"></i><b>5.2</b> Individual Conditional Expectation (ICE)</a><ul>
<li class="chapter" data-level="5.2.1" data-path="ice.html"><a href="ice.html#example-1"><i class="fa fa-check"></i><b>5.2.1</b> Example</a></li>
<li class="chapter" data-level="5.2.2" data-path="ice.html"><a href="ice.html#advantages-2"><i class="fa fa-check"></i><b>5.2.2</b> Advantages</a></li>
<li class="chapter" data-level="5.2.3" data-path="ice.html"><a href="ice.html#disadvantages-2"><i class="fa fa-check"></i><b>5.2.3</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="interaction.html"><a href="interaction.html"><i class="fa fa-check"></i><b>5.3</b> Feature Interaction</a><ul>
<li class="chapter" data-level="5.3.1" data-path="interaction.html"><a href="interaction.html#feature-interaction"><i class="fa fa-check"></i><b>5.3.1</b> Feature Interaction?</a></li>
<li class="chapter" data-level="5.3.2" data-path="interaction.html"><a href="interaction.html#theory-friedmans-h-statistic"><i class="fa fa-check"></i><b>5.3.2</b> Theory: Friedman’s H-statistic</a></li>
<li class="chapter" data-level="5.3.3" data-path="interaction.html"><a href="interaction.html#examples-1"><i class="fa fa-check"></i><b>5.3.3</b> Examples</a></li>
<li class="chapter" data-level="5.3.4" data-path="interaction.html"><a href="interaction.html#advantages-3"><i class="fa fa-check"></i><b>5.3.4</b> Advantages</a></li>
<li class="chapter" data-level="5.3.5" data-path="interaction.html"><a href="interaction.html#disadvantages-3"><i class="fa fa-check"></i><b>5.3.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.3.6" data-path="interaction.html"><a href="interaction.html#implementations"><i class="fa fa-check"></i><b>5.3.6</b> Implementations</a></li>
<li class="chapter" data-level="5.3.7" data-path="interaction.html"><a href="interaction.html#alternatives"><i class="fa fa-check"></i><b>5.3.7</b> Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="feature-importance.html"><a href="feature-importance.html"><i class="fa fa-check"></i><b>5.4</b> Feature Importance</a><ul>
<li class="chapter" data-level="5.4.1" data-path="feature-importance.html"><a href="feature-importance.html#the-theory"><i class="fa fa-check"></i><b>5.4.1</b> The Theory</a></li>
<li class="chapter" data-level="5.4.2" data-path="feature-importance.html"><a href="feature-importance.html#example-and-interpretation"><i class="fa fa-check"></i><b>5.4.2</b> Example and Interpretation</a></li>
<li class="chapter" data-level="5.4.3" data-path="feature-importance.html"><a href="feature-importance.html#advantages-4"><i class="fa fa-check"></i><b>5.4.3</b> Advantages</a></li>
<li class="chapter" data-level="5.4.4" data-path="feature-importance.html"><a href="feature-importance.html#disadvantages-4"><i class="fa fa-check"></i><b>5.4.4</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="global.html"><a href="global.html"><i class="fa fa-check"></i><b>5.5</b> Global Surrogate Models</a><ul>
<li class="chapter" data-level="5.5.1" data-path="global.html"><a href="global.html#theory-1"><i class="fa fa-check"></i><b>5.5.1</b> Theory</a></li>
<li class="chapter" data-level="5.5.2" data-path="global.html"><a href="global.html#example-3"><i class="fa fa-check"></i><b>5.5.2</b> Example</a></li>
<li class="chapter" data-level="5.5.3" data-path="global.html"><a href="global.html#advantages-5"><i class="fa fa-check"></i><b>5.5.3</b> Advantages</a></li>
<li class="chapter" data-level="5.5.4" data-path="global.html"><a href="global.html#disadvantages-5"><i class="fa fa-check"></i><b>5.5.4</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="lime.html"><a href="lime.html"><i class="fa fa-check"></i><b>5.6</b> Local Surrogate Models (LIME)</a><ul>
<li class="chapter" data-level="5.6.1" data-path="lime.html"><a href="lime.html#lime-for-tabular-data"><i class="fa fa-check"></i><b>5.6.1</b> LIME for Tabular Data</a></li>
<li class="chapter" data-level="5.6.2" data-path="lime.html"><a href="lime.html#lime-for-text"><i class="fa fa-check"></i><b>5.6.2</b> LIME for Text</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>5.7</b> Shapley Value Explanations</a><ul>
<li class="chapter" data-level="5.7.1" data-path="shapley.html"><a href="shapley.html#the-general-idea"><i class="fa fa-check"></i><b>5.7.1</b> The general idea</a></li>
<li class="chapter" data-level="5.7.2" data-path="shapley.html"><a href="shapley.html#examples-and-interpretation"><i class="fa fa-check"></i><b>5.7.2</b> Examples and Interpretation</a></li>
<li class="chapter" data-level="5.7.3" data-path="shapley.html"><a href="shapley.html#the-shapley-value-in-detail"><i class="fa fa-check"></i><b>5.7.3</b> The Shapley Value in Detail</a></li>
<li class="chapter" data-level="5.7.4" data-path="shapley.html"><a href="shapley.html#advantages-6"><i class="fa fa-check"></i><b>5.7.4</b> Advantages</a></li>
<li class="chapter" data-level="5.7.5" data-path="shapley.html"><a href="shapley.html#disadvantages-6"><i class="fa fa-check"></i><b>5.7.5</b> Disadvantages</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="future.html"><a href="future.html"><i class="fa fa-check"></i><b>6</b> A Look into the Crystal Ball</a><ul>
<li class="chapter" data-level="6.1" data-path="the-future-of-machine-learning.html"><a href="the-future-of-machine-learning.html"><i class="fa fa-check"></i><b>6.1</b> The Future of Machine Learning</a></li>
<li class="chapter" data-level="6.2" data-path="the-future-of-interpretability.html"><a href="the-future-of-interpretability.html"><i class="fa fa-check"></i><b>6.2</b> The Future of Interpretability</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="contribute.html"><a href="contribute.html"><i class="fa fa-check"></i><b>7</b> Contribute</a></li>
<li class="chapter" data-level="8" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i><b>8</b> Acknowledgements</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interpretable Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="criteria-for-interpretability-methods" class="section level2">
<h2><span class="header-section-number">2.2</span> Criteria for Interpretability Methods</h2>
<p>Methods for machine learning interpretability can be classified according to different criteria:</p>
<ul>
<li><strong>Intrinsic or post hoc?</strong> Intrinsic interpretability means selecting and training a machine learning model that is considered to be intrinsically interpretable (for example short decision trees). Post hoc interpretability means selecting and training a black box model (for example a neural network) and applying interpretability methods after the training (for example measuring the feature importance). The “intrinsic or post hoc”-criterion determined the layout of the chapters in the book: The two main chapters are the <a href="simple.html#simple">intrinsically interpretable models chapter</a> and the <a href="agnostic.html#agnostic">post hoc (and model-agnostic) interpretability methods chapter</a>.</li>
<li><strong>Model-specific or model-agnostic?</strong>: Model-specific interpretation tools are limited to specific model classes. The interpretation of regression weights in a linear model is a model-specific interpretation, since - by definition - the interpretation of intrinsically interpretable models is always model-specific. Any tool that only works for e.g. interpreting neural networks is model-specific. Model-agnostic tools can be used on any machine learning model and are usually post hoc. These agnostic methods usually operate by analysing feature input and output pairs. By definition, these methods can’t have access to any model internals like weights or structural information.</li>
<li><strong>Local or global?</strong>: Does the interpretation method explain a single prediction or the entire model behavior? Or is the scope somewhere in between? Read more about the scope criterion in the next section.</li>
</ul>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="interpretability-importance.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="scope-of-interpretability.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/christophM/interpretable-ml-book/edit/master/02-interpretability.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
