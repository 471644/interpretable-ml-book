<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Interpretable machine learning</title>
  <meta name="description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisons more interpretable.">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Interpretable machine learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisons more interpretable." />
  <meta name="github-repo" content="christophM/xai-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Interpretable machine learning" />
  
  <meta name="twitter:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisons more interpretable." />
  

<meta name="author" content="Christoph Molnar">


<meta name="date" content="2017-11-07">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="logistic-regression-a-linear-model-for-classification.html">
<link rel="next" href="other-simple-interpretable-models.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-0.9/htmlwidgets.js"></script>
<script src="libs/datatables-binding-0.2/datatables.js"></script>
<link href="libs/dt-core-1.10.12/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.12/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.12/js/jquery.dataTables.min.js"></script>



</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Interpretable machine learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="who-should-read-this-book.html"><a href="who-should-read-this-book.html"><i class="fa fa-check"></i><b>1.1</b> Who should read this book</a></li>
<li class="chapter" data-level="1.2" data-path="outline.html"><a href="outline.html"><i class="fa fa-check"></i><b>1.2</b> Outline</a></li>
<li class="chapter" data-level="1.3" data-path="what-is-machine-learning-and-why-is-it-important.html"><a href="what-is-machine-learning-and-why-is-it-important.html"><i class="fa fa-check"></i><b>1.3</b> What is machine learning and why is it important?</a></li>
<li class="chapter" data-level="1.4" data-path="definitions.html"><a href="definitions.html"><i class="fa fa-check"></i><b>1.4</b> Definitions</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="interpretability.html"><a href="interpretability.html"><i class="fa fa-check"></i><b>2</b> Interpretability</a><ul>
<li class="chapter" data-level="2.1" data-path="when-is-interpretability-important.html"><a href="when-is-interpretability-important.html"><i class="fa fa-check"></i><b>2.1</b> When is interpretability important?</a></li>
<li class="chapter" data-level="2.2" data-path="the-bigger-picture.html"><a href="the-bigger-picture.html"><i class="fa fa-check"></i><b>2.2</b> The bigger picture</a></li>
<li class="chapter" data-level="2.3" data-path="scope-of-explainability.html"><a href="scope-of-explainability.html"><i class="fa fa-check"></i><b>2.3</b> Scope of explainability</a><ul>
<li class="chapter" data-level="2.3.1" data-path="scope-of-explainability.html"><a href="scope-of-explainability.html#algorithm-transparency"><i class="fa fa-check"></i><b>2.3.1</b> Algorithm transparency</a></li>
<li class="chapter" data-level="2.3.2" data-path="scope-of-explainability.html"><a href="scope-of-explainability.html#global-holistic-model-explainability"><i class="fa fa-check"></i><b>2.3.2</b> Global, holistic model explainability</a></li>
<li class="chapter" data-level="2.3.3" data-path="scope-of-explainability.html"><a href="scope-of-explainability.html#global-model-explainability-on-a-modular-level"><i class="fa fa-check"></i><b>2.3.3</b> Global model explainability on a modular level</a></li>
<li class="chapter" data-level="2.3.4" data-path="scope-of-explainability.html"><a href="scope-of-explainability.html#explain-the-decision-for-a-single-instance"><i class="fa fa-check"></i><b>2.3.4</b> Explain the decision for a single instance</a></li>
<li class="chapter" data-level="2.3.5" data-path="scope-of-explainability.html"><a href="scope-of-explainability.html#explain-the-decisions-for-a-group-of-instances"><i class="fa fa-check"></i><b>2.3.5</b> Explain the decisions for a group of instances</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="evaluating-explainability.html"><a href="evaluating-explainability.html"><i class="fa fa-check"></i><b>2.4</b> Evaluating explainability</a><ul>
<li class="chapter" data-level="2.4.1" data-path="evaluating-explainability.html"><a href="evaluating-explainability.html#approaches-for-evaluation-of-the-explanation-quality"><i class="fa fa-check"></i><b>2.4.1</b> Approaches for evaluation of the explanation quality</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="datasets.html"><a href="datasets.html"><i class="fa fa-check"></i><b>3</b> Datasets</a><ul>
<li class="chapter" data-level="3.1" data-path="regression-dataset-bike-sharing-counts.html"><a href="regression-dataset-bike-sharing-counts.html"><i class="fa fa-check"></i><b>3.1</b> Regression dataset: Bike sharing counts</a></li>
<li class="chapter" data-level="3.2" data-path="the-dataset-speed-dating.html"><a href="the-dataset-speed-dating.html"><i class="fa fa-check"></i><b>3.2</b> The dataset: speed dating</a></li>
<li class="chapter" data-level="3.3" data-path="TubeSpam.html"><a href="TubeSpam.html"><i class="fa fa-check"></i><b>3.3</b> TubeSpam dataset: Spam classification on YouTube comments</a></li>
<li class="chapter" data-level="3.4" data-path="risk-factors-for-cervical-cancer.html"><a href="risk-factors-for-cervical-cancer.html"><i class="fa fa-check"></i><b>3.4</b> Risk factors for cervical cancer</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple.html"><a href="simple.html"><i class="fa fa-check"></i><b>4</b> Simple, interpretable models</a><ul>
<li class="chapter" data-level="4.1" data-path="terminology.html"><a href="terminology.html"><i class="fa fa-check"></i><b>4.1</b> Terminology</a></li>
<li class="chapter" data-level="4.2" data-path="overview.html"><a href="overview.html"><i class="fa fa-check"></i><b>4.2</b> Overview</a></li>
<li class="chapter" data-level="4.3" data-path="limo.html"><a href="limo.html"><i class="fa fa-check"></i><b>4.3</b> Linear models</a><ul>
<li class="chapter" data-level="4.3.1" data-path="limo.html"><a href="limo.html#interpretation"><i class="fa fa-check"></i><b>4.3.1</b> Interpretation</a></li>
<li class="chapter" data-level="4.3.2" data-path="limo.html"><a href="limo.html#interpretation-example"><i class="fa fa-check"></i><b>4.3.2</b> Interpretation example</a></li>
<li class="chapter" data-level="4.3.3" data-path="limo.html"><a href="limo.html#interpretation-templates"><i class="fa fa-check"></i><b>4.3.3</b> Interpretation templates</a></li>
<li class="chapter" data-level="4.3.4" data-path="limo.html"><a href="limo.html#visual-parameter-interpretation"><i class="fa fa-check"></i><b>4.3.4</b> Visual parameter interpretation</a></li>
<li class="chapter" data-level="4.3.5" data-path="limo.html"><a href="limo.html#explaining-single-predictions"><i class="fa fa-check"></i><b>4.3.5</b> Explaining single predictions</a></li>
<li class="chapter" data-level="4.3.6" data-path="limo.html"><a href="limo.html#coding-categorical-variables"><i class="fa fa-check"></i><b>4.3.6</b> Coding categorical variables:</a></li>
<li class="chapter" data-level="4.3.7" data-path="limo.html"><a href="limo.html#the-disadvantages-of-linear-models"><i class="fa fa-check"></i><b>4.3.7</b> The disadvantages of linear models</a></li>
<li class="chapter" data-level="4.3.8" data-path="limo.html"><a href="limo.html#towards-complexer-relationships-within-linear-model-class"><i class="fa fa-check"></i><b>4.3.8</b> Towards complexer relationships within linear model class</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="sparse-linear-models.html"><a href="sparse-linear-models.html"><i class="fa fa-check"></i><b>4.4</b> Sparse linear models</a></li>
<li class="chapter" data-level="4.5" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html"><i class="fa fa-check"></i><b>4.5</b> Logistic regression: a linear model for classification</a><ul>
<li class="chapter" data-level="4.5.1" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html#whats-wrong-with-linear-regression-for-classification"><i class="fa fa-check"></i><b>4.5.1</b> What’s wrong with linear regression for classification?</a></li>
<li class="chapter" data-level="4.5.2" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html#logistic-regression"><i class="fa fa-check"></i><b>4.5.2</b> Logistic regression</a></li>
<li class="chapter" data-level="4.5.3" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html#interpretation-1"><i class="fa fa-check"></i><b>4.5.3</b> Interpretation</a></li>
<li class="chapter" data-level="4.5.4" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html#example"><i class="fa fa-check"></i><b>4.5.4</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>4.6</b> Decision trees</a><ul>
<li class="chapter" data-level="4.6.1" data-path="decision-trees.html"><a href="decision-trees.html#interpretation-2"><i class="fa fa-check"></i><b>4.6.1</b> Interpretation</a></li>
<li class="chapter" data-level="4.6.2" data-path="decision-trees.html"><a href="decision-trees.html#interpretation-example-1"><i class="fa fa-check"></i><b>4.6.2</b> Interpretation example</a></li>
<li class="chapter" data-level="4.6.3" data-path="decision-trees.html"><a href="decision-trees.html#advantages"><i class="fa fa-check"></i><b>4.6.3</b> Advantages</a></li>
<li class="chapter" data-level="4.6.4" data-path="decision-trees.html"><a href="decision-trees.html#disadvantages"><i class="fa fa-check"></i><b>4.6.4</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html"><i class="fa fa-check"></i><b>4.7</b> Other simple, interpretable models</a><ul>
<li class="chapter" data-level="4.7.1" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html#naive-bayes-classifier"><i class="fa fa-check"></i><b>4.7.1</b> Naive bayes classifier</a></li>
<li class="chapter" data-level="4.7.2" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html#k-nearest-neighbours"><i class="fa fa-check"></i><b>4.7.2</b> k-nearest neighbours</a></li>
<li class="chapter" data-level="4.7.3" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html#rulefit"><i class="fa fa-check"></i><b>4.7.3</b> RuleFit</a></li>
<li class="chapter" data-level="4.7.4" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html#and-so-many-more"><i class="fa fa-check"></i><b>4.7.4</b> And so many more …</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="model-agnostic-explanations.html"><a href="model-agnostic-explanations.html"><i class="fa fa-check"></i><b>5</b> Model-agnostic explanations</a><ul>
<li class="chapter" data-level="5.1" data-path="global-explain-the-behaviour-of-a-model.html"><a href="global-explain-the-behaviour-of-a-model.html"><i class="fa fa-check"></i><b>5.1</b> Global: Explain the behaviour of a model</a><ul>
<li class="chapter" data-level="5.1.1" data-path="global-explain-the-behaviour-of-a-model.html"><a href="global-explain-the-behaviour-of-a-model.html#pdp"><i class="fa fa-check"></i><b>5.1.1</b> Partial dependence plot</a></li>
<li class="chapter" data-level="5.1.2" data-path="global-explain-the-behaviour-of-a-model.html"><a href="global-explain-the-behaviour-of-a-model.html#average-marginal-effects"><i class="fa fa-check"></i><b>5.1.2</b> Average Marginal Effects}</a></li>
<li class="chapter" data-level="5.1.3" data-path="global-explain-the-behaviour-of-a-model.html"><a href="global-explain-the-behaviour-of-a-model.html#feature-importance"><i class="fa fa-check"></i><b>5.1.3</b> Feature importance</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="local-explain-a-single-decisions.html"><a href="local-explain-a-single-decisions.html"><i class="fa fa-check"></i><b>5.2</b> Local: Explain a single decisions</a><ul>
<li class="chapter" data-level="5.2.1" data-path="local-explain-a-single-decisions.html"><a href="local-explain-a-single-decisions.html#individual-conditional-expectation-ice-plot"><i class="fa fa-check"></i><b>5.2.1</b> Individual Conditional Expectation (ICE) plot</a></li>
<li class="chapter" data-level="5.2.2" data-path="local-explain-a-single-decisions.html"><a href="local-explain-a-single-decisions.html#local-surrogate-models-lime"><i class="fa fa-check"></i><b>5.2.2</b> Local surrogate models (LIME)</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="model-agnostic-why-not-use-them-on-the-data-itself.html"><a href="model-agnostic-why-not-use-them-on-the-data-itself.html"><i class="fa fa-check"></i><b>5.3</b> Model-agnostic: Why not use them on the data itself?</a></li>
<li class="chapter" data-level="5.4" data-path="explanation-types.html"><a href="explanation-types.html"><i class="fa fa-check"></i><b>5.4</b> Explanation types</a><ul>
<li class="chapter" data-level="5.4.1" data-path="explanation-types.html"><a href="explanation-types.html#structured-output"><i class="fa fa-check"></i><b>5.4.1</b> Structured output</a></li>
<li class="chapter" data-level="5.4.2" data-path="explanation-types.html"><a href="explanation-types.html#viz-explanation"><i class="fa fa-check"></i><b>5.4.2</b> Visualization</a></li>
<li class="chapter" data-level="5.4.3" data-path="explanation-types.html"><a href="explanation-types.html#natural-language-narratives"><i class="fa fa-check"></i><b>5.4.3</b> Natural language (narratives)</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interpretable machine learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="decision-trees" class="section level2">
<h2><span class="header-section-number">4.6</span> Decision trees</h2>
<p>Linear models fail in situation where the relationship is non-linear and/or where the features are interacting with each other. Time to shine for the decision trees! Tree-based models partition the data along the features into rectangles. For predicting the outcome in each rectangle it fits a simple model (for example the average of the outcome of the instances that fall into this rectangle). Trees have an intuitive structure starting from a root and splitting into nodes, according to cutoff values of the features. After each split, the instances fall into one of the new nodes. At the end of the training all the instances from the training data set are assigned into one of the leaf nodes. See Figure @ref{fig:tree-artificial} for illustration.</p>
<p>There are a lot of different tree algorithms. They differ in structure (number of splits per node), criteria for how to find the splits, when to stop splitting and how to estimate the simple models within the leaf nodes. Classification and regression trees (CART) is one of the more popular algorithms for tree building. This book will only talk about CART, because in the interpretation they are all the same. If you know of some tree algorithm with a different interpretation, I would welcome your feedback.</p>
Each of these rectangles is associated with a simple model of the outcome of the interest. This is usually estimated by taking the mean of outcomes from all training instances that fall into a rectangle. I recommend the book ‘The elements of statistical learning’ <span class="citation">(Hastie, Tibshirani, and Friedman <a href="#ref-Hastie2009">2009</a>)</span> for a more detailed introduction.
<div class="figure"><span id="fig:tree-artificial"></span>
<img src="xai-book_files/figure-html/tree-artificial-1.svg" alt="Exemplary decision tree with artificial data" width="100%" />
<p class="caption">
FIGURE 4.4: Exemplary decision tree with artificial data
</p>
</div>
<p>The following formula describes relationship of y and x (in which rectangle does x fall?) <span class="math display">\[\hat{y}_i = \hat{f}(x_i) = \sum_{m = 1}^M c_m I\{x_i \in R_m\}\]</span> Each instance <span class="math inline">\(x_i\)</span> falls into exactly one leaf node (=rectangle), so <span class="math inline">\(I_{\{x_i \in R_m\}}\)</span> is only 1 for the this single leaf node (<span class="math inline">\(I\)</span> is the identity function which is 1 if <span class="math inline">\(x_i \in R_m\)</span> and else 0). If <span class="math inline">\(x_i\)</span> falls into leaf node <span class="math inline">\(R_l\)</span>, the predicted outcome <span class="math inline">\(\hat{y} = c_l\)</span>, where <span class="math inline">\(c_l\)</span> is the mean of all the training instances in leaf node <span class="math inline">\(R_l\)</span>.</p>
<p>But where do the ‘rectangles’ come from? This is quite simple: The algorithm takes a feature and tries which cut-off point minimizes the sum of squares if it is a regression task or the Gini index in classification tasks. It’s the cut-off point that makes the two resulting subsets as different as possible in terms of the outcome variable of interest. For categorial features the algorithm tries different groupings by category into to nodes. After this was done for each feature, the algorithm looks for the feature with the best cut-off and chooses this to split the node into two new nodes. The algorithm continues doing this in both new nodes until the stopping criteria is reached. Possible criteria are: A minimum number of observations that have to be in a node before the split, the minimum number of instances that have to be in a terminal node.</p>
<p>A common strategy is to grow a tree fully and then cut it back to optimize it’s complexity measure <span class="math inline">\(cp\)</span>.</p>
<div id="interpretation-2" class="section level3">
<h3><span class="header-section-number">4.6.1</span> Interpretation</h3>
<p>It’s easy: Starting from the root node you go to the next nodes and the edges tell you which subsets you are looking at. Once you reach the leaf node, the node tells you the predicted outcome. All the edges are connected by ‘AND’.</p>
<p>Template: If feature x is [smaller/bigger] than threshold c AND …, then the predicted value is <span class="math inline">\(\hat{y}\)</span>.</p>
</div>
<div id="interpretation-example-1" class="section level3">
<h3><span class="header-section-number">4.6.2</span> Interpretation example</h3>
<p>Let’s have a look again at the speed dating example. Again we want to predict the rating from the participants, how much they will like the rating partners.</p>
<div class="figure"><span id="fig:tree-example"></span>
<img src="xai-book_files/figure-html/tree-example-1.svg" alt="Regression tree fitted on the speed dating data. Categories of goal of date feature have been abbreviated for readability: f = for fun, m = meet new people, d = date, r = relationship, e = experience, o = other" width="672" />
<p class="caption">
FIGURE 4.5: Regression tree fitted on the speed dating data. Categories of goal of date feature have been abbreviated for readability: f = for fun, m = meet new people, d = date, r = relationship, e = experience, o = other
</p>
</div>
<p>The first split was done in the workingday variable, which tells if a day is a working day or a saturday/sunday/holiday. On days without work, the number of rental bikes was higher on average. In both child nodes the the next feature that was chosen was temperature.</p>
<p>In waves of size 20 or smaller, participants who gave 5/10 or more to importance of same religion of partner, they also rated lower on average (median around 6). If religion was less important (4 or lower), than they gave higher ratings.</p>
</div>
<div id="advantages" class="section level3">
<h3><span class="header-section-number">4.6.3</span> Advantages</h3>
<p>The tree structure is perfectly suited to <strong>cover interactions</strong> between features in the data. The data also ends up in <strong>distinct groups</strong>, which are easier to grasp than points on a hyperplane like in linear regression. The interpretation is arguably pretty straight forward. The tree structure also has a <strong>natural visualization</strong>, with it’s nodes and edges.</p>
</div>
<div id="disadvantages" class="section level3">
<h3><span class="header-section-number">4.6.4</span> Disadvantages</h3>
<p><strong>Handling of real linear relationships</strong>, that’s what trees suck at. Any real linear relationship between an input feature and the outcome has to be approximated by hard splits, which produces a step function. This is not efficient. This goes hand in hand with <strong>lack of smoothness</strong>. Slight changes in the input feature can have a big impact on the predicted outcome, which might not be desirable. Imagine a tree that predicts the worth of a house and the tree splits in the square meters multiple times. One of the splits is at 100.5 square meters. When a user measure his house and arrives at 99 square meters, types it into some nice web interface and get’s 200 000 Euro. The user notices that she forgot to measure a small storeroom with 2 square meters. The storeroom has a skewed wall, so she is not sure if she can count it fully towards the whole flat area or only half of the space. So she decides to try both 100.0 and 101.0 square meters. The results: 200 000 Euro and 205 000 Euro, which is quite unintuitive.</p>
<p>Trees are also quite <strong>unstable</strong>, so a few changes in the training data set might create a completely different tree. That’s because each splits depends on the parent split. It does not generate trust if the structure flips so easily.</p>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Hastie2009">
<p>Hastie, T, R Tibshirani, and J Friedman. 2009. <em>The elements of statistical learning</em>. <a href="http://link.springer.com/content/pdf/10.1007/978-0-387-84858-7.pdf" class="uri">http://link.springer.com/content/pdf/10.1007/978-0-387-84858-7.pdf</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="logistic-regression-a-linear-model-for-classification.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="other-simple-interpretable-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/christophM/xai-book/edit/master/04-interpretable-models.Rmd",
"text": "Edit"
},
"download": ["xai-book.pdf"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

<!-- </html> -->
