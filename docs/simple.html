<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>exML: Explainable machine learning</title>
  <meta name="description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisons more explainable.">
  <meta name="generator" content="bookdown 0.3.10 and GitBook 2.6.7">

  <meta property="og:title" content="exML: Explainable machine learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisons more explainable." />
  <meta name="github-repo" content="christophM/exML-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="exML: Explainable machine learning" />
  
  <meta name="twitter:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisons more explainable." />
  

<meta name="author" content="Christoph Molnar">


<meta name="date" content="2017-03-19">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="intro.html">
<link rel="next" href="data.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#what-is-machine-learning-and-why-is-it-important"><i class="fa fa-check"></i><b>1.1</b> What is machine learning and why is it important?</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#why-is-explainability-important"><i class="fa fa-check"></i><b>1.2</b> Why is explainability important?</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#who-this-book-is-for"><i class="fa fa-check"></i><b>1.3</b> Who this book is for</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#outline-of-the-book"><i class="fa fa-check"></i><b>1.4</b> Outline of the book</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#is-good-user-experience-enough"><i class="fa fa-check"></i><b>1.5</b> Is good user experience enough?</a></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#scope-of-explainability"><i class="fa fa-check"></i><b>1.6</b> Scope of explainability</a><ul>
<li class="chapter" data-level="1.6.1" data-path="intro.html"><a href="intro.html#algorithm"><i class="fa fa-check"></i><b>1.6.1</b> Algorithm</a></li>
<li class="chapter" data-level="1.6.2" data-path="intro.html"><a href="intro.html#global-model-explainability"><i class="fa fa-check"></i><b>1.6.2</b> Global model explainability</a></li>
<li class="chapter" data-level="1.6.3" data-path="intro.html"><a href="intro.html#explain-a-single-observation"><i class="fa fa-check"></i><b>1.6.3</b> Explain a single observation</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="intro.html"><a href="intro.html#measuring-explainability-comprehensibility-interpretability"><i class="fa fa-check"></i><b>1.7</b> Measuring explainability / comprehensibility / interpretability</a></li>
<li class="chapter" data-level="1.8" data-path="intro.html"><a href="intro.html#definitions"><i class="fa fa-check"></i><b>1.8</b> Definitions</a></li>
<li class="chapter" data-level="1.9" data-path="intro.html"><a href="intro.html#terminology"><i class="fa fa-check"></i><b>1.9</b> Terminology</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="simple.html"><a href="simple.html"><i class="fa fa-check"></i><b>2</b> Keep it simple</a><ul>
<li class="chapter" data-level="2.1" data-path="simple.html"><a href="simple.html#overview"><i class="fa fa-check"></i><b>2.1</b> Overview</a></li>
<li class="chapter" data-level="2.2" data-path="simple.html"><a href="simple.html#linear-models"><i class="fa fa-check"></i><b>2.2</b> Linear models</a><ul>
<li class="chapter" data-level="2.2.1" data-path="simple.html"><a href="simple.html#interpretation"><i class="fa fa-check"></i><b>2.2.1</b> Interpretation</a></li>
<li class="chapter" data-level="2.2.2" data-path="simple.html"><a href="simple.html#interpretation-example"><i class="fa fa-check"></i><b>2.2.2</b> Interpretation example</a></li>
<li class="chapter" data-level="2.2.3" data-path="simple.html"><a href="simple.html#coding-categorial-variables"><i class="fa fa-check"></i><b>2.2.3</b> Coding categorial variables:</a></li>
<li class="chapter" data-level="2.2.4" data-path="simple.html"><a href="simple.html#explaining-a-single-observation"><i class="fa fa-check"></i><b>2.2.4</b> Explaining a single observation:</a></li>
<li class="chapter" data-level="2.2.5" data-path="simple.html"><a href="simple.html#the-disadvantages-of-linear-models"><i class="fa fa-check"></i><b>2.2.5</b> The disadvantages of linear models</a></li>
<li class="chapter" data-level="2.2.6" data-path="simple.html"><a href="simple.html#linear-models-beyond-gaussian-regression"><i class="fa fa-check"></i><b>2.2.6</b> Linear models beyond gaussian regression</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="simple.html"><a href="simple.html#decision-trees"><i class="fa fa-check"></i><b>2.3</b> Decision trees</a><ul>
<li class="chapter" data-level="2.3.1" data-path="simple.html"><a href="simple.html#explaining-treeinterpreter"><i class="fa fa-check"></i><b>2.3.1</b> Explaining: Treeinterpreter</a></li>
<li class="chapter" data-level="2.3.2" data-path="simple.html"><a href="simple.html#more-general-bayesian-network-approaches"><i class="fa fa-check"></i><b>2.3.2</b> More general bayesian network approache(s)</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="simple.html"><a href="simple.html#interpretation-overview"><i class="fa fa-check"></i><b>2.4</b> Interpretation overview</a></li>
<li class="chapter" data-level="2.5" data-path="simple.html"><a href="simple.html#monotonicity-constraints-between-features"><i class="fa fa-check"></i><b>2.5</b> Monotonicity constraints between features</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>3</b> Explain the data</a><ul>
<li class="chapter" data-level="3.1" data-path="data.html"><a href="data.html#visualizations"><i class="fa fa-check"></i><b>3.1</b> visualizations</a></li>
<li class="chapter" data-level="3.2" data-path="data.html"><a href="data.html#pca"><i class="fa fa-check"></i><b>3.2</b> PCA</a><ul>
<li class="chapter" data-level="3.2.1" data-path="data.html"><a href="data.html#mds"><i class="fa fa-check"></i><b>3.2.1</b> MDS</a></li>
<li class="chapter" data-level="3.2.2" data-path="data.html"><a href="data.html#t-sne"><i class="fa fa-check"></i><b>3.2.2</b> t-SNE</a></li>
<li class="chapter" data-level="3.2.3" data-path="data.html"><a href="data.html#glyphs"><i class="fa fa-check"></i><b>3.2.3</b> Glyphs</a></li>
<li class="chapter" data-level="3.2.4" data-path="data.html"><a href="data.html#correlation-graphs"><i class="fa fa-check"></i><b>3.2.4</b> Correlation Graphs</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="data.html"><a href="data.html#biases.-source-httpsen.m.wikipedia.orgwikibias_statistics"><i class="fa fa-check"></i><b>3.3</b> Biases. Source: <a href="https://en.m.wikipedia.org/wiki/Bias_(statistics)" class="uri">https://en.m.wikipedia.org/wiki/Bias_(statistics)</a></a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="model-agnostic-explanations.html"><a href="model-agnostic-explanations.html"><i class="fa fa-check"></i><b>4</b> Model-agnostic explanations</a><ul>
<li class="chapter" data-level="4.1" data-path="model-agnostic-explanations.html"><a href="model-agnostic-explanations.html#global-explain-behaviour-of-system-with-data"><i class="fa fa-check"></i><b>4.1</b> Global: Explain behaviour of system with data</a><ul>
<li class="chapter" data-level="4.1.1" data-path="model-agnostic-explanations.html"><a href="model-agnostic-explanations.html#global-surrogate-models"><i class="fa fa-check"></i><b>4.1.1</b> Global surrogate models</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="model-agnostic-explanations.html"><a href="model-agnostic-explanations.html#local-explain-single-decisions"><i class="fa fa-check"></i><b>4.2</b> Local: Explain single decisions</a><ul>
<li class="chapter" data-level="4.2.1" data-path="model-agnostic-explanations.html"><a href="model-agnostic-explanations.html#local-surrogate-models-lime"><i class="fa fa-check"></i><b>4.2.1</b> Local surrogate models (LIME)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="specific.html"><a href="specific.html"><i class="fa fa-check"></i><b>5</b> Model-specific explanations for complex models</a><ul>
<li class="chapter" data-level="5.1" data-path="specific.html"><a href="specific.html#global-explanations"><i class="fa fa-check"></i><b>5.1</b> Global explanations</a><ul>
<li class="chapter" data-level="5.1.1" data-path="specific.html"><a href="specific.html#random-forests-treeinterpreter"><i class="fa fa-check"></i><b>5.1.1</b> Random Forests: Treeinterpreter</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">exML: Explainable machine learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="simple" class="section level1">
<h1><span class="header-section-number">2</span> Keep it simple</h1>
<p>The most straight forward way to achieve explainable machine learning algorithms is to use only a subset algorithms that yield an understandable model structure.</p>
<p>These are:</p>
<ul>
<li>linear models</li>
<li>trees</li>
<li>rules</li>
</ul>
<p>In the following chapters these we will talk about the algorithm with it’s variants. Not in detail, only the basics, because there are already a ton of books, videos, tutorials, papers and so on about them. We will focus on how to interpret the models and why they are explainable. The chapter covers linear models, decision trees, decision rules, neighbour methods and graphical models.</p>
<div id="overview" class="section level2">
<h2><span class="header-section-number">2.1</span> Overview</h2>
<table>
<thead>
<tr class="header">
<th align="left">Algorithm</th>
<th align="left">Linear</th>
<th align="left">Monotonicity</th>
<th align="left">Interaction built-in</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Linear models</td>
<td align="left">Yes</td>
<td align="left">Yes</td>
<td align="left">No</td>
</tr>
<tr class="even">
<td align="left">Decision trees</td>
<td align="left">No</td>
<td align="left">Not by default</td>
<td align="left">Yes</td>
</tr>
<tr class="odd">
<td align="left">Decision rules</td>
<td align="left">No</td>
<td align="left">Not by default</td>
<td align="left">Yes</td>
</tr>
<tr class="even">
<td align="left">Naive bayes</td>
<td align="left">Yes</td>
<td align="left">Yes</td>
<td align="left">No</td>
</tr>
<tr class="odd">
<td align="left">Nearest neighbours</td>
<td align="left">No</td>
<td align="left">No</td>
<td align="left">No</td>
</tr>
</tbody>
</table>
</div>
<div id="linear-models" class="section level2">
<h2><span class="header-section-number">2.2</span> Linear models</h2>
<p>Linear models have been and are still used by statistician, computer scientists and other people with quantitative problems. They learn straightforward linear (and monotonic) relationships between the target and the features. The target changes by a learned weight depending on the feature. Monotonicity makes the interpretation easy.</p>
<p>Linear models can be used to model the dependency of a regression variable (here Y) on K covariates. As the name says, the learned relationships are linear in the form of</p>
<p><span class="math display">\[y_{i} = \beta_{0} + \beta_{1} \cdot x_{i,1} + \ldots + \beta_{K} x_{i,K} + \epsilon_{i}\]</span></p>
<p>The i-th observation’s outcome is a weighted sum of it’s K features. The <span class="math inline">\(\beta_{k}\)</span> represent the learned feature weights or coefficients. The <span class="math inline">\(\epsilon_{i}\)</span> is the error we are still making, the difference between the predicted and actual outcome.</p>
<p>The biggest advantage is the linearity: It makes the estimation procedure straight forward and most importantly these linear equations have an easy to understand interpretation. That is one of the main reasons why the linear model and all it’s descendants are so widespread in academic fields like medicine, sociology, psychology and many more quantitative research fields. In this areas it is important to not only predict e.g. the clinical outcome of a patient, but also quantify the influence of the medication while at the same time accounting for things like sex, age and other variables.</p>
<div id="interpretation" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Interpretation</h3>
<p>The interpretation of the coefficients:</p>
<ul>
<li>Continuous regression variable: For an increase of one point of the variable <span class="math inline">\(x_{j}\)</span> the estimated outcome changes by <span class="math inline">\(\beta_{j}\)</span></li>
<li>Binary categorial variables: One of the variables is the reference level (in some languages the one that was coded in 0). A change of the variable <span class="math inline">\(x_{i}\)</span> the reference level to the other category changes the estimated outcome by <span class="math inline">\(\beta_{i}\)</span></li>
<li>Categorial variables with many levels: One solution to deal with many variables is to one-hot-encode them, meaning each level gets it’s own column. From a categorial variable with L levels, you only need L-1 columsn, otherwise it is over parameterized. The interpretation for each level is then according to the binary variables. Some language like R allow to</li>
<li>Intercept <span class="math inline">\(\beta_{0}\)</span>: The interpretation is: Given all continuous variables are zero and the categorial variables are on the reference level, the estimated outcome of <span class="math inline">\(y_{i}\)</span> is <span class="math inline">\(\beta_{0}\)</span>. The interpretation of <span class="math inline">\(\beta_{0}\)</span> is usually not relevant.</li>
</ul>
</div>
<div id="interpretation-example" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Interpretation example</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&#39;mlbench&#39;</span>)
<span class="kw">library</span>(<span class="st">&#39;knitr&#39;</span>)
<span class="kw">data</span>(<span class="st">&#39;BostonHousing&#39;</span>)
lm_summary =<span class="st"> </span><span class="kw">summary</span>(<span class="kw">lm</span>(medv <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> BostonHousing))<span class="op">$</span>coefficients[,<span class="kw">c</span>(<span class="st">&#39;Estimate&#39;</span>, <span class="st">&#39;Std. Error&#39;</span>)]

name_matches =<span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;crim&#39;</span>=<span class="st">&#39;per capita crime rate&#39;</span>,
                 <span class="st">&#39;zn&#39;</span>=<span class="st">&#39;proportion of residential land zoned for lots over 25,000 sq.ft&#39;</span>,
                 <span class="st">&#39;indus&#39;</span>=<span class="st">&#39;proportion of non-retail business acres per town&#39;</span>,
                 <span class="st">&#39;chas1&#39;</span>=<span class="st">&#39;Charles River dummy variable (= 1 if tract bounds river; 0 otherwise&#39;</span>,
                 <span class="st">&#39;nox&#39;</span>=<span class="st">&#39;nitric oxides concentration (parts per 10 million)&#39;</span>,
                 <span class="st">&#39;rm&#39;</span>=<span class="st">&#39;average number of rooms per dwelling&#39;</span>,
                 <span class="st">&#39;age&#39;</span>=<span class="st">&#39;proportion of owner-occupied units built prior to 1940&#39;</span>,
                 <span class="st">&#39;dis&#39;</span>=<span class="st">&#39;weighted distances to five Boston employment centres&#39;</span>,
                 <span class="st">&#39;rad&#39;</span>=<span class="st">&#39;index of accessibility to radial highways&#39;</span>,
                 <span class="st">&#39;tax&#39;</span>=<span class="st">&#39;full-value property-tax rate per USD 10,000&#39;</span>,
                 <span class="st">&#39;ptratio&#39;</span>=<span class="st">&#39;pupil-teacher ratio by town&#39;</span>,
                 <span class="st">&#39;b&#39;</span>=<span class="st">&#39;1000(B - 0.63)^2 where B is the proportion of blacks by town&#39;</span>,
                 <span class="st">&#39;lstat&#39;</span>=<span class="st">&#39;percentage of lower status of the population&#39;</span>,
                 <span class="st">&#39;medv&#39;</span>=<span class="st">&#39;median value of owner-occupied homes in USD 1000&#39;</span>, <span class="st">&#39;(Intercept)&#39;</span>=<span class="st">&#39;(Intercept)&#39;</span>)
<span class="kw">rownames</span>(lm_summary) =<span class="st"> </span>name_matches[<span class="kw">rownames</span>(lm_summary)]
<span class="kw">kable</span>(lm_summary)</code></pre></div>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Estimate</th>
<th align="right">Std. Error</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>(Intercept)</td>
<td align="right">36.4594884</td>
<td align="right">5.1034588</td>
</tr>
<tr class="even">
<td>per capita crime rate</td>
<td align="right">-0.1080114</td>
<td align="right">0.0328650</td>
</tr>
<tr class="odd">
<td>proportion of residential land zoned for lots over 25,000 sq.ft</td>
<td align="right">0.0464205</td>
<td align="right">0.0137275</td>
</tr>
<tr class="even">
<td>proportion of non-retail business acres per town</td>
<td align="right">0.0205586</td>
<td align="right">0.0614957</td>
</tr>
<tr class="odd">
<td>Charles River dummy variable (= 1 if tract bounds river; 0 otherwise</td>
<td align="right">2.6867338</td>
<td align="right">0.8615798</td>
</tr>
<tr class="even">
<td>nitric oxides concentration (parts per 10 million)</td>
<td align="right">-17.7666112</td>
<td align="right">3.8197437</td>
</tr>
<tr class="odd">
<td>average number of rooms per dwelling</td>
<td align="right">3.8098652</td>
<td align="right">0.4179253</td>
</tr>
<tr class="even">
<td>proportion of owner-occupied units built prior to 1940</td>
<td align="right">0.0006922</td>
<td align="right">0.0132098</td>
</tr>
<tr class="odd">
<td>weighted distances to five Boston employment centres</td>
<td align="right">-1.4755668</td>
<td align="right">0.1994547</td>
</tr>
<tr class="even">
<td>index of accessibility to radial highways</td>
<td align="right">0.3060495</td>
<td align="right">0.0663464</td>
</tr>
<tr class="odd">
<td>full-value property-tax rate per USD 10,000</td>
<td align="right">-0.0123346</td>
<td align="right">0.0037605</td>
</tr>
<tr class="even">
<td>pupil-teacher ratio by town</td>
<td align="right">-0.9527472</td>
<td align="right">0.1308268</td>
</tr>
<tr class="odd">
<td>1000(B - 0.63)^2 where B is the proportion of blacks by town</td>
<td align="right">0.0093117</td>
<td align="right">0.0026860</td>
</tr>
<tr class="even">
<td>percentage of lower status of the population</td>
<td align="right">-0.5247584</td>
<td align="right">0.0507153</td>
</tr>
</tbody>
</table>
</div>
<div id="coding-categorial-variables" class="section level3">
<h3><span class="header-section-number">2.2.3</span> Coding categorial variables:</h3>
<p>There are several ways to represent a categorial variable, which has an influence on the interpretation: <a href="http://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/" class="uri">http://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/</a> and <a href="http://heidiseibold.github.io/page7/" class="uri">http://heidiseibold.github.io/page7/</a></p>
<p>Described above is the dummy coding, which is usually sufficient. Using different codings boils down to creating different matrices from your one column with the categorial variable. An overview:</p>
<ul>
<li>Dummy coding compares each level to the reference level. The intercept is the mean of the reference group</li>
<li>Simple coding also compares each level to the reference, but the intercept is the overall mean.</li>
<li>Deviation coding: Intercept is overall mean, and levels are compared to the mean</li>
<li>Split coding: compare each level to the previous level. Usually used when there is an order in the levels.</li>
<li>Helmert coding: …</li>
</ul>
</div>
<div id="explaining-a-single-observation" class="section level3">
<h3><span class="header-section-number">2.2.4</span> Explaining a single observation:</h3>
<p>Let’s look at a concrete example:</p>
<p>You are trying to predict the house price using the notorious Boston house prize data set. So y is the prize of the house and your X are: …</p>
<p>The fitted linear model for the prize comes down to the following equation:</p>
<p>EQUATION</p>
</div>
<div id="the-disadvantages-of-linear-models" class="section level3">
<h3><span class="header-section-number">2.2.5</span> The disadvantages of linear models</h3>
<p>They can only represent linear relationships as the name suggests. Each non-linearity or interaction has to be hand-crafted and explicitly given to the model as an input feature. Because of possible high correlation between features, it is possible that a feature that is positively correlated with the outcome might get a negative weight in a linear model, because in the high dimensional space it is negatively correlated. An example: You have a model to predict the rent price and have features like number of rooms and size of the flat. Of course flat size and room number are highly correlated, the bigger a flat the more rooms it has. If you now take both variables into a linear model it might happen, that the flat size is the better predictor and get’s a large positive weight. The room number might end up getting a negative weight, because given that a flat has the same size, increasing the number of rooms could make it less valuable.<br />
### Towards complexer relationships within linear model class - Adding interactions - Adding non-linear terms like polynomials - Stratifying data by variable and fitting linear models on subsets</p>
</div>
<div id="linear-models-beyond-gaussian-regression" class="section level3">
<h3><span class="header-section-number">2.2.6</span> Linear models beyond gaussian regression</h3>
<ul>
<li>Logistic regression</li>
<li>Lasso, Ridge, elasticnet</li>
<li>GAMs</li>
<li>Quantile regression</li>
</ul>
</div>
</div>
<div id="decision-trees" class="section level2">
<h2><span class="header-section-number">2.3</span> Decision trees</h2>
<div id="explaining-treeinterpreter" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Explaining: Treeinterpreter</h3>
<p><a href="https://github.com/andosa/treeinterpreter" class="uri">https://github.com/andosa/treeinterpreter</a> ## RuleFit ## Decision rules ## Decision tables ## Nearest neighbours ### Learning deep k-nearest neighbour representations ## Bayesian network classifiers ## Naive Bayes Classifier and other graphical models ### Naive bayes Good in case you want interpretation of all features. Bad: No interaction, but even strong assumption of independence of features given the class. But if you indeed have independent features, then it might be the best model.</p>
</div>
<div id="more-general-bayesian-network-approaches" class="section level3">
<h3><span class="header-section-number">2.3.2</span> More general bayesian network approache(s)</h3>
<div id="bayesian-network-augmented-naive-bayes-ban-illustrated" class="section level4">
<h4><span class="header-section-number">2.3.2.1</span> Bayesian Network-Augmented Naïve Bayes (BAN) illustrated</h4>
</div>
<div id="general-bayesian-network" class="section level4">
<h4><span class="header-section-number">2.3.2.2</span> General Bayesian Network</h4>
</div>
</div>
</div>
<div id="interpretation-overview" class="section level2">
<h2><span class="header-section-number">2.4</span> Interpretation overview</h2>
<p>INSERT HERE: One example of classification task and one for regression task plus for each a table with the interpretations per model (maybe only example for one variable). Plus verbal template for each interpretation.</p>
</div>
<div id="monotonicity-constraints-between-features" class="section level2">
<h2><span class="header-section-number">2.5</span> Monotonicity constraints between features</h2>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="intro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="data.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
