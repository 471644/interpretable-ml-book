<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Interpretable Machine Learning</title>
  <meta name="description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisions more interpretable.">
  <meta name="generator" content="bookdown 0.6 and GitBook 2.6.7">

  <meta property="og:title" content="Interpretable Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisions more interpretable." />
  <meta name="github-repo" content="christophM/interpretable-ml-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Interpretable Machine Learning" />
  
  <meta name="twitter:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisions more interpretable." />
  

<meta name="author" content="Christoph Molnar">


<meta name="date" content="2018-02-08">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="pdp.html">
<link rel="next" href="permutation-feature-importance.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.0/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.4/datatables.js"></script>
<link href="libs/dt-core-1.10.16/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.16/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.16/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/dt-core-bootstrap-1.10.16/css/dataTables.bootstrap.min.css" rel="stylesheet" />
<link href="libs/dt-core-bootstrap-1.10.16/css/dataTables.bootstrap.extra.css" rel="stylesheet" />
<script src="libs/dt-core-bootstrap-1.10.16/js/jquery.dataTables.min.js"></script>
<script src="libs/dt-core-bootstrap-1.10.16/js/dataTables.bootstrap.min.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110543840-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110543840-1');
</script>

<!-- For the Bitcoin donation button-->
<script type="text/javascript" src="https://blockchain.info/Resources/js/pay-now-button.js"></script>



</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Interpretable machine learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="what-to-expect-from-this-book.html"><a href="what-to-expect-from-this-book.html"><i class="fa fa-check"></i><b>1.1</b> What to Expect from This Book</a></li>
<li class="chapter" data-level="1.2" data-path="storytime.html"><a href="storytime.html"><i class="fa fa-check"></i><b>1.2</b> Storytime</a><ul>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#lightning-never-strikes-twice"><i class="fa fa-check"></i>Lightning never strikes twice</a></li>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#trust-fall"><i class="fa fa-check"></i>Trust fall</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html"><i class="fa fa-check"></i><b>1.3</b> What Is Machine Learning?</a></li>
<li class="chapter" data-level="1.4" data-path="definitions.html"><a href="definitions.html"><i class="fa fa-check"></i><b>1.4</b> Definitions</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="interpretability.html"><a href="interpretability.html"><i class="fa fa-check"></i><b>2</b> Interpretability</a><ul>
<li class="chapter" data-level="2.1" data-path="interpretability-importance.html"><a href="interpretability-importance.html"><i class="fa fa-check"></i><b>2.1</b> The Importance of Interpretability</a></li>
<li class="chapter" data-level="2.2" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html"><i class="fa fa-check"></i><b>2.2</b> Scope of Interpretability</a><ul>
<li class="chapter" data-level="2.2.1" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#algorithm-transparency"><i class="fa fa-check"></i><b>2.2.1</b> Algorithm transparency</a></li>
<li class="chapter" data-level="2.2.2" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-holistic-model-interpretability"><i class="fa fa-check"></i><b>2.2.2</b> Global, Holistic Model Interpretability</a></li>
<li class="chapter" data-level="2.2.3" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-model-interpretability-on-a-modular-level"><i class="fa fa-check"></i><b>2.2.3</b> Global Model Interpretability on a Modular Level</a></li>
<li class="chapter" data-level="2.2.4" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#local-interpretability-for-a-single-prediction"><i class="fa fa-check"></i><b>2.2.4</b> Local Interpretability for a Single Prediction</a></li>
<li class="chapter" data-level="2.2.5" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#local-interpretability-for-a-group-of-prediction"><i class="fa fa-check"></i><b>2.2.5</b> Local Interpretability for a Group of Prediction</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="evaluating-interpretability.html"><a href="evaluating-interpretability.html"><i class="fa fa-check"></i><b>2.3</b> Evaluating Interpretability</a><ul>
<li class="chapter" data-level="2.3.1" data-path="evaluating-interpretability.html"><a href="evaluating-interpretability.html#approaches-for-evaluating-the-interpretability-quality"><i class="fa fa-check"></i><b>2.3.1</b> Approaches for Evaluating the Interpretability Quality</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="explanation.html"><a href="explanation.html"><i class="fa fa-check"></i><b>2.4</b> Human-style Explanations</a><ul>
<li class="chapter" data-level="2.4.1" data-path="explanation.html"><a href="explanation.html#what-is-an-explanation"><i class="fa fa-check"></i><b>2.4.1</b> What is an explanation?</a></li>
<li class="chapter" data-level="2.4.2" data-path="explanation.html"><a href="explanation.html#good-explanation"><i class="fa fa-check"></i><b>2.4.2</b> What is a “good” explanation?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>3</b> Datasets</a><ul>
<li class="chapter" data-level="3.1" data-path="bike-data.html"><a href="bike-data.html"><i class="fa fa-check"></i><b>3.1</b> Bike Sharing Counts (Regression)</a></li>
<li class="chapter" data-level="3.2" data-path="spam-data.html"><a href="spam-data.html"><i class="fa fa-check"></i><b>3.2</b> YouTube Spam Comments (Text Classification)</a></li>
<li class="chapter" data-level="3.3" data-path="cervical-data.html"><a href="cervical-data.html"><i class="fa fa-check"></i><b>3.3</b> Risk Factors for Cervical Cancer (Classification)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple.html"><a href="simple.html"><i class="fa fa-check"></i><b>4</b> Interpretable Models</a><ul>
<li class="chapter" data-level="4.1" data-path="limo.html"><a href="limo.html"><i class="fa fa-check"></i><b>4.1</b> Linear Model</a><ul>
<li class="chapter" data-level="4.1.1" data-path="limo.html"><a href="limo.html#interpretation"><i class="fa fa-check"></i><b>4.1.1</b> Interpretation</a></li>
<li class="chapter" data-level="4.1.2" data-path="limo.html"><a href="limo.html#interpretation-example"><i class="fa fa-check"></i><b>4.1.2</b> Interpretation Example</a></li>
<li class="chapter" data-level="4.1.3" data-path="limo.html"><a href="limo.html#interpretation-templates"><i class="fa fa-check"></i><b>4.1.3</b> Interpretation templates</a></li>
<li class="chapter" data-level="4.1.4" data-path="limo.html"><a href="limo.html#visual-parameter-interpretation"><i class="fa fa-check"></i><b>4.1.4</b> Visual parameter interpretation</a></li>
<li class="chapter" data-level="4.1.5" data-path="limo.html"><a href="limo.html#explaining-single-predictions"><i class="fa fa-check"></i><b>4.1.5</b> Explaining Single Predictions</a></li>
<li class="chapter" data-level="4.1.6" data-path="limo.html"><a href="limo.html#cat.code"><i class="fa fa-check"></i><b>4.1.6</b> Coding Categorical Features</a></li>
<li class="chapter" data-level="4.1.7" data-path="limo.html"><a href="limo.html#the-disadvantages-of-linear-models"><i class="fa fa-check"></i><b>4.1.7</b> The disadvantages of linear models</a></li>
<li class="chapter" data-level="4.1.8" data-path="limo.html"><a href="limo.html#do-linear-models-create-good-explanations"><i class="fa fa-check"></i><b>4.1.8</b> Do linear models create good explanations?</a></li>
<li class="chapter" data-level="4.1.9" data-path="limo.html"><a href="limo.html#extending-linear-models"><i class="fa fa-check"></i><b>4.1.9</b> Extending Linear Models</a></li>
<li class="chapter" data-level="4.1.10" data-path="limo.html"><a href="limo.html#sparse-linear"><i class="fa fa-check"></i><b>4.1.10</b> Sparse linear models</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="logistic.html"><a href="logistic.html"><i class="fa fa-check"></i><b>4.2</b> Logistic Regression</a><ul>
<li class="chapter" data-level="4.2.1" data-path="logistic.html"><a href="logistic.html#whats-wrong-with-linear-regression-models-for-classification"><i class="fa fa-check"></i><b>4.2.1</b> What’s Wrong with Linear Regression Models for Classification?</a></li>
<li class="chapter" data-level="4.2.2" data-path="logistic.html"><a href="logistic.html#logistic-regression"><i class="fa fa-check"></i><b>4.2.2</b> Logistic Regression</a></li>
<li class="chapter" data-level="4.2.3" data-path="logistic.html"><a href="logistic.html#interpretation-1"><i class="fa fa-check"></i><b>4.2.3</b> Interpretation</a></li>
<li class="chapter" data-level="4.2.4" data-path="logistic.html"><a href="logistic.html#example"><i class="fa fa-check"></i><b>4.2.4</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="tree.html"><a href="tree.html"><i class="fa fa-check"></i><b>4.3</b> Decision Tree</a><ul>
<li class="chapter" data-level="4.3.1" data-path="tree.html"><a href="tree.html#interpretation-2"><i class="fa fa-check"></i><b>4.3.1</b> Interpretation</a></li>
<li class="chapter" data-level="4.3.2" data-path="tree.html"><a href="tree.html#interpretation-example-1"><i class="fa fa-check"></i><b>4.3.2</b> Interpretation Example</a></li>
<li class="chapter" data-level="4.3.3" data-path="tree.html"><a href="tree.html#advantages"><i class="fa fa-check"></i><b>4.3.3</b> Advantages</a></li>
<li class="chapter" data-level="4.3.4" data-path="tree.html"><a href="tree.html#disadvantages"><i class="fa fa-check"></i><b>4.3.4</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="rulefit.html"><a href="rulefit.html"><i class="fa fa-check"></i><b>4.4</b> RuleFit</a><ul>
<li class="chapter" data-level="4.4.1" data-path="rulefit.html"><a href="rulefit.html#interpretation-and-example"><i class="fa fa-check"></i><b>4.4.1</b> Interpretation and Example</a></li>
<li class="chapter" data-level="4.4.2" data-path="rulefit.html"><a href="rulefit.html#guidelines"><i class="fa fa-check"></i><b>4.4.2</b> Guidelines</a></li>
<li class="chapter" data-level="4.4.3" data-path="rulefit.html"><a href="rulefit.html#theory"><i class="fa fa-check"></i><b>4.4.3</b> Theory</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="other-interpretable-models.html"><a href="other-interpretable-models.html"><i class="fa fa-check"></i><b>4.5</b> Other Interpretable Models</a><ul>
<li class="chapter" data-level="4.5.1" data-path="other-interpretable-models.html"><a href="other-interpretable-models.html#naive-bayes-classifier"><i class="fa fa-check"></i><b>4.5.1</b> Naive Bayes classifier</a></li>
<li class="chapter" data-level="4.5.2" data-path="other-interpretable-models.html"><a href="other-interpretable-models.html#k-nearest-neighbours"><i class="fa fa-check"></i><b>4.5.2</b> K-Nearest Neighbours</a></li>
<li class="chapter" data-level="4.5.3" data-path="other-interpretable-models.html"><a href="other-interpretable-models.html#and-so-many-more"><i class="fa fa-check"></i><b>4.5.3</b> And so many more …</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="agnostic.html"><a href="agnostic.html"><i class="fa fa-check"></i><b>5</b> Model-Agnostic Methods</a><ul>
<li class="chapter" data-level="5.1" data-path="pdp.html"><a href="pdp.html"><i class="fa fa-check"></i><b>5.1</b> Partial Dependence Plot (PDP)</a><ul>
<li class="chapter" data-level="5.1.1" data-path="pdp.html"><a href="pdp.html#examples"><i class="fa fa-check"></i><b>5.1.1</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="ice.html"><a href="ice.html"><i class="fa fa-check"></i><b>5.2</b> Individual Conditional Expectation (ICE) Plot</a><ul>
<li class="chapter" data-level="5.2.1" data-path="ice.html"><a href="ice.html#example-1"><i class="fa fa-check"></i><b>5.2.1</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="permutation-feature-importance.html"><a href="permutation-feature-importance.html"><i class="fa fa-check"></i><b>5.3</b> Permutation Feature Importance</a></li>
<li class="chapter" data-level="5.4" data-path="lime.html"><a href="lime.html"><i class="fa fa-check"></i><b>5.4</b> Local Surrogate Models (LIME)</a><ul>
<li class="chapter" data-level="5.4.1" data-path="lime.html"><a href="lime.html#lime-for-tabular-data"><i class="fa fa-check"></i><b>5.4.1</b> LIME for Tabular Data</a></li>
<li class="chapter" data-level="5.4.2" data-path="lime.html"><a href="lime.html#lime-for-text"><i class="fa fa-check"></i><b>5.4.2</b> LIME for Text</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="contribute.html"><a href="contribute.html"><i class="fa fa-check"></i><b>6</b> Contribute</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interpretable Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ice" class="section level2">
<h2><span class="header-section-number">5.2</span> Individual Conditional Expectation (ICE) Plot</h2>
<p>The partial dependence plot for visualising the average effect of a feature is a global method, because it does not focus on specific instances, but on an overall average. The equivalent to a PDP for local expectations is called individual conditional expectation (ICE) plot <span class="citation">(Goldstein et al. <a href="#ref-goldstein2015peeking">2015</a>)</span>. An ICE plot visualises the dependence of the predicted response on a feature for EACH instance separately, resulting in multiple lines, one for each instance, compared to one line in partial dependence plots. A PDP is the average of the lines of an ICE plot. The values for a line (and one instance) can be computed by leaving all other features the same, creating variants of this instance by replacing the feature’s value with values from a grid and letting the black box make the predictions with these newly created instances. The result is a set of points for an instance with the feature value from the grid and the respective predictions.</p>
<p>So, what do you gain by looking at individual expectations, instead of partial dependencies? Partial dependence plots can obfuscate a heterogeneous relationship that comes from interactions. PDPs can show you how the average relationship between feature <span class="math inline">\(x_S\)</span> and <span class="math inline">\(\hat{y}\)</span> looks like. This works only well in cases where the interactions between <span class="math inline">\(x_S\)</span> and the remaining <span class="math inline">\(x_C\)</span> are weak. In case of interactions, the ICE plot will give a lot more insight.</p>
<p>A more formal definition: In ICE plots, for each instance in <span class="math inline">\(\{(x_{S_i}, x_{C_i})\}_{i=1}^N\)</span> the curve <span class="math inline">\(\hat{f}_S^{(i)}\)</span> is plotted against <span class="math inline">\(x_{S_i}\)</span>, while <span class="math inline">\(x_{C_i}\)</span> is kept fixed.</p>
<div id="example-1" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Example</h3>
<p>Let’s go back to the dataset about risk factors for cervical cancer from Chapter <a href="cervical-data.html#cervical-data">3.3</a> and see how each instance’s prediction is associated with the feature ‘Age’. The model we will analyse is a RandomForest that predicts the probability of cancer for a woman given risk factors. In the partial dependence plot from Chapter <a href="pdp.html#pdp">5.1</a> we have seen that the cancer probability increases around the age of 50, but does it hold true for each woman in the dataset? The ICE plot (Figure <a href="ice.html#fig:ice-cervical">5.5</a>) reveals that the most women’s predicted probability follows the average pattern of increase at 50, but there are a few exceptions: For the few women that have a high predicted probability at a young age, the predicted cancer probability does not change much with increasing age.</p>
Figure <a href="ice.html#fig:ice-bike">5.6</a> shows an ICE plot for the bike rental prediction (the underlying prediction model is a RandomForest). The data is described in Chapter <a href="bike-data.html#bike-data">3.1</a>. All curves seem to follow the same course, so there seem to be no obvious interactions. That means that the PDP is already a good summary of the relationships of the displayed features and the predicted bike rentals.
<div class="figure" style="text-align: center"><span id="fig:ice-cervical"></span>
<img src="interpretable-ml_files/figure-html/ice-cervical-1.svg" alt="Individual conditional expectation plot of cervical cancer probability by age. Each line represents the conditional expectation for one woman. Most women with a low cancer probability in younger years see an increase in predicted cancer probability, given all other feature value stay the same. Interestingly for a few women that have a high estimated cancer probability bigger than 0.4, the estimated probability does not change much with higher age." width="80%" />
<p class="caption">
FIGURE 5.5: Individual conditional expectation plot of cervical cancer probability by age. Each line represents the conditional expectation for one woman. Most women with a low cancer probability in younger years see an increase in predicted cancer probability, given all other feature value stay the same. Interestingly for a few women that have a high estimated cancer probability bigger than 0.4, the estimated probability does not change much with higher age.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:ice-bike"></span>
<img src="interpretable-ml_files/figure-html/ice-bike-1.svg" alt="Individual conditional expectation plot of expected bike rentals and weather conditions. The same effects as in the partial dependence plots can be observed." width="80%" />
<p class="caption">
FIGURE 5.6: Individual conditional expectation plot of expected bike rentals and weather conditions. The same effects as in the partial dependence plots can be observed.
</p>
</div>
<div id="centred-ice-plot" class="section level4">
<h4><span class="header-section-number">5.2.1.1</span> Centred ICE Plot</h4>
<p>There is one issue with ICE plots: It can be hard to see if the individual conditional expectation curves differ between individuals, because they start at different <span class="math inline">\(\hat{f}(x)\)</span>. An easy fix is to centre the curves at a certain point in <span class="math inline">\(x_S\)</span> and only display the difference in the predicted response. The resulting plot is called centred ICE plot (c-ICE). Anchoring the curves at the lower end of <span class="math inline">\(x_S\)</span> is a good choice. The new curves are defined as: <span class="math display">\[\hat{f}_{cent}^{(i)} = \hat{f}_i - \mathbf{1}\hat{f}(x^{\text{*}}, x_{C_i}), \]</span> where <span class="math inline">\(\mathbf{1}\)</span> is a vector of 1’s with the appropriate number of dimensions (usually one- or two-dimensional), <span class="math inline">\(\hat{f}\)</span> the fitted model and <span class="math inline">\(x^{\text{*}}\)</span> the anchor point.</p>
</div>
<div id="example-2" class="section level4">
<h4><span class="header-section-number">5.2.1.2</span> Example</h4>
Taking the plot in Figure <a href="ice.html#fig:ice-cervical">5.5</a> and centring the lines at the youngest observed age yields Figure <a href="ice.html#fig:ice-cervical-centered">5.7</a>. With the centred ICE plots it is easier to compare the curves of individual instances. This can be useful when we are not interested in seeing the absolute change of a predicted value, but rather the difference in prediction compared to a fixed point of the feature range.
<div class="figure" style="text-align: center"><span id="fig:ice-cervical-centered"></span>
<img src="interpretable-ml_files/figure-html/ice-cervical-centered-1.svg" alt="Centred ICE plot for predicted cervical cancer risk probability by age. The lines are fixed to 0 at age 13 and each point shows the difference to the prediction with age 13. Compared to age 18, the predictions for most instances stay the same and see an increase up to 20 percent. A few cases show the opposite behaviour: The predicted probability decreases with increasing age." width="80%" />
<p class="caption">
FIGURE 5.7: Centred ICE plot for predicted cervical cancer risk probability by age. The lines are fixed to 0 at age 13 and each point shows the difference to the prediction with age 13. Compared to age 18, the predictions for most instances stay the same and see an increase up to 20 percent. A few cases show the opposite behaviour: The predicted probability decreases with increasing age.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:ice-bike-centered"></span>
<img src="interpretable-ml_files/figure-html/ice-bike-centered-1.svg" alt="Centred individual conditional expectation plots of expected bike rentals by weather condition. The lines were fixed at value 0 for each feature and instance. The lines show the difference in prediction compared to the prediction with the respective feature value at 0." width="80%" />
<p class="caption">
FIGURE 5.8: Centred individual conditional expectation plots of expected bike rentals by weather condition. The lines were fixed at value 0 for each feature and instance. The lines show the difference in prediction compared to the prediction with the respective feature value at 0.
</p>
</div>
</div>
<div id="derivative-ice-plot" class="section level4">
<h4><span class="header-section-number">5.2.1.3</span> Derivative ICE Plot</h4>
<p>Another way to make it visually easier to spot heterogeneity is to look at the individual derivatives of <span class="math inline">\(\hat{f}\)</span> with respect to <span class="math inline">\(x_S\)</span> instead of the predicted response <span class="math inline">\(\hat{f}\)</span>. The resulting plot is called derivative ICE plot (d-ICE). The derivatives of a function (or curve) tell you in which direction changes occur and if any occur at all. With the derivative ICE plot it is easy to spot value ranges in a feature where the black box’s predicted values change for (at least some) instances. If there is no interaction between <span class="math inline">\(x_S\)</span> and <span class="math inline">\(x_C\)</span>, then <span class="math inline">\(\hat{f}\)</span> can be expressed as: <span class="math display">\[\hat{f}(x) = \hat{f}(x_S, x_C) = g(x_S) + h(x_C), \text{ so that } \frac{\delta\hat{f}(x)}{\delta x_S} = g&#39;(x_S)\]</span> Without interactions, the individual partial derivatives should be the same for all instances. If they differ, it is because of interactions and it will become visible in the d-ICE plot. In addition to displaying the individual curves for derivative <span class="math inline">\(\hat{f}\)</span>, showing the standard deviation of derivative <span class="math inline">\(\hat{f}\)</span> helps to highlight regions in <span class="math inline">\(x_S\)</span> with heterogeneity in the estimated derivatives.</p>
</div>
<div id="example-3" class="section level4">
<h4><span class="header-section-number">5.2.1.4</span> Example</h4>
As we have seen, the most changes in estimated cancer probability happen around age 45. This is confirmed by the derivative ICE plot in Figure <a href="ice.html#fig:ice-cervical-derivative">5.9</a>.
<div class="figure" style="text-align: center"><span id="fig:ice-cervical-derivative"></span>
<img src="interpretable-ml_files/figure-html/ice-cervical-derivative-1.svg" alt="Derivative ICE plot of predicted cancer probability by age. Between age 14 and the early forties, a few instance see changes in prediction both upwards and downwards, but the majorities derivatives are near zero. Between age 45 and 50, most women's prediction curves have a positive derivative, indicating an increase in predicted cancer probability." width="80%" />
<p class="caption">
FIGURE 5.9: Derivative ICE plot of predicted cancer probability by age. Between age 14 and the early forties, a few instance see changes in prediction both upwards and downwards, but the majorities derivatives are near zero. Between age 45 and 50, most women’s prediction curves have a positive derivative, indicating an increase in predicted cancer probability.
</p>
</div>
<p>Figure <a href="ice.html#fig:ice-bike-derivative">5.10</a> shows the derivative ICE plot for the bike rental model.</p>
<div class="figure" style="text-align: center"><span id="fig:ice-bike-derivative"></span>
<img src="interpretable-ml_files/figure-html/ice-bike-derivative-1.svg" alt="Derivative individual conditional expectation plot of expected bike rentals and weather conditions." width="80%" />
<p class="caption">
FIGURE 5.10: Derivative individual conditional expectation plot of expected bike rentals and weather conditions.
</p>
</div>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-goldstein2015peeking">
<p>Goldstein, Alex, Adam Kapelner, Justin Bleich, and Emil Pitkin. 2015. “Peeking Inside the Black Box: Visualizing Statistical Learning with Plots of Individual Conditional Expectation.” <em>Journal of Computational and Graphical Statistics</em> 24 (1). Taylor &amp; Francis: 44–65.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="pdp.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="permutation-feature-importance.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/christophM/interpretable-ml-book/edit/master/chapters/05.3-agnostic-ice.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
