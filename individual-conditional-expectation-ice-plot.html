<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Interpretable machine learning</title>
  <meta name="description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisons more interpretable.">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Interpretable machine learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisons more interpretable." />
  <meta name="github-repo" content="christophM/xai-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Interpretable machine learning" />
  
  <meta name="twitter:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisons more interpretable." />
  

<meta name="author" content="Christoph Molnar">


<meta name="date" content="2017-11-19">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="pdp.html">
<link rel="next" href="permutation-feature-importance.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-0.9/htmlwidgets.js"></script>
<script src="libs/datatables-binding-0.2/datatables.js"></script>
<link href="libs/dt-core-1.10.12/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.12/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.12/js/jquery.dataTables.min.js"></script>



</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Interpretable machine learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="what-to-expect-from-this-book.html"><a href="what-to-expect-from-this-book.html"><i class="fa fa-check"></i><b>1.1</b> What to expect from this book</a></li>
<li class="chapter" data-level="1.2" data-path="what-is-machine-learning-and-why-is-it-important.html"><a href="what-is-machine-learning-and-why-is-it-important.html"><i class="fa fa-check"></i><b>1.2</b> What is machine learning and why is it important?</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="interpretability.html"><a href="interpretability.html"><i class="fa fa-check"></i><b>2</b> Interpretability</a><ul>
<li class="chapter" data-level="2.1" data-path="interpretability-importance.html"><a href="interpretability-importance.html"><i class="fa fa-check"></i><b>2.1</b> The importance of machine learning interpretability</a></li>
<li class="chapter" data-level="2.2" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html"><i class="fa fa-check"></i><b>2.2</b> Scope of interpretability</a><ul>
<li class="chapter" data-level="2.2.1" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#algorithm-transparency"><i class="fa fa-check"></i><b>2.2.1</b> Algorithm transparency</a></li>
<li class="chapter" data-level="2.2.2" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-holistic-model-interpretability"><i class="fa fa-check"></i><b>2.2.2</b> Global, holistic model interpretability</a></li>
<li class="chapter" data-level="2.2.3" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-model-interpretability-on-a-modular-level"><i class="fa fa-check"></i><b>2.2.3</b> Global model interpretability on a modular level</a></li>
<li class="chapter" data-level="2.2.4" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#explain-the-prediction-for-a-single-instance"><i class="fa fa-check"></i><b>2.2.4</b> Explain the prediction for a single instance</a></li>
<li class="chapter" data-level="2.2.5" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#explain-the-predictions-for-a-group-of-instances"><i class="fa fa-check"></i><b>2.2.5</b> Explain the predictions for a group of instances</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="evaluating-interpretability.html"><a href="evaluating-interpretability.html"><i class="fa fa-check"></i><b>2.3</b> Evaluating interpretability</a><ul>
<li class="chapter" data-level="2.3.1" data-path="evaluating-interpretability.html"><a href="evaluating-interpretability.html#approaches-for-evaluating-the-explanation-quality"><i class="fa fa-check"></i><b>2.3.1</b> Approaches for evaluating the explanation quality</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>3</b> Datasets</a><ul>
<li class="chapter" data-level="3.1" data-path="bike-data.html"><a href="bike-data.html"><i class="fa fa-check"></i><b>3.1</b> Bike sharing counts (regression)</a></li>
<li class="chapter" data-level="3.2" data-path="spam-data.html"><a href="spam-data.html"><i class="fa fa-check"></i><b>3.2</b> Youtube spam comments (text classification)</a></li>
<li class="chapter" data-level="3.3" data-path="cervical-data.html"><a href="cervical-data.html"><i class="fa fa-check"></i><b>3.3</b> Risk factors for cervical cancer (classification)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="definitions.html"><a href="definitions.html"><i class="fa fa-check"></i><b>4</b> Definitions</a></li>
<li class="chapter" data-level="5" data-path="simple.html"><a href="simple.html"><i class="fa fa-check"></i><b>5</b> Interpretable models</a><ul>
<li class="chapter" data-level="5.1" data-path="terminology.html"><a href="terminology.html"><i class="fa fa-check"></i><b>5.1</b> Terminology</a></li>
<li class="chapter" data-level="5.2" data-path="limo.html"><a href="limo.html"><i class="fa fa-check"></i><b>5.2</b> Linear models</a><ul>
<li class="chapter" data-level="5.2.1" data-path="limo.html"><a href="limo.html#interpretation"><i class="fa fa-check"></i><b>5.2.1</b> Interpretation</a></li>
<li class="chapter" data-level="5.2.2" data-path="limo.html"><a href="limo.html#interpretation-example"><i class="fa fa-check"></i><b>5.2.2</b> Interpretation example</a></li>
<li class="chapter" data-level="" data-path="limo.html"><a href="limo.html#interpretation-templates"><i class="fa fa-check"></i>Interpretation templates</a></li>
<li class="chapter" data-level="5.2.3" data-path="limo.html"><a href="limo.html#visual-parameter-interpretation"><i class="fa fa-check"></i><b>5.2.3</b> Visual parameter interpretation</a></li>
<li class="chapter" data-level="5.2.4" data-path="limo.html"><a href="limo.html#explaining-single-predictions"><i class="fa fa-check"></i><b>5.2.4</b> Explaining single predictions</a></li>
<li class="chapter" data-level="5.2.5" data-path="limo.html"><a href="limo.html#cat.code"><i class="fa fa-check"></i><b>5.2.5</b> Coding categorical features</a></li>
<li class="chapter" data-level="5.2.6" data-path="limo.html"><a href="limo.html#the-disadvantages-of-linear-models"><i class="fa fa-check"></i><b>5.2.6</b> The disadvantages of linear models</a></li>
<li class="chapter" data-level="5.2.7" data-path="limo.html"><a href="limo.html#towards-complexer-relationships-within-linear-model-class"><i class="fa fa-check"></i><b>5.2.7</b> Towards complexer relationships within linear model class</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="sparse-linear-models.html"><a href="sparse-linear-models.html"><i class="fa fa-check"></i><b>5.3</b> Sparse linear models</a></li>
<li class="chapter" data-level="5.4" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html"><i class="fa fa-check"></i><b>5.4</b> Logistic regression: a linear model for classification</a><ul>
<li class="chapter" data-level="5.4.1" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html#whats-wrong-with-linear-regression-for-classification"><i class="fa fa-check"></i><b>5.4.1</b> What’s wrong with linear regression for classification?</a></li>
<li class="chapter" data-level="5.4.2" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html#logistic-regression"><i class="fa fa-check"></i><b>5.4.2</b> Logistic regression</a></li>
<li class="chapter" data-level="5.4.3" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html#interpretation-1"><i class="fa fa-check"></i><b>5.4.3</b> Interpretation</a></li>
<li class="chapter" data-level="5.4.4" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html#example"><i class="fa fa-check"></i><b>5.4.4</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>5.5</b> Decision trees</a><ul>
<li class="chapter" data-level="5.5.1" data-path="decision-trees.html"><a href="decision-trees.html#interpretation-2"><i class="fa fa-check"></i><b>5.5.1</b> Interpretation</a></li>
<li class="chapter" data-level="5.5.2" data-path="decision-trees.html"><a href="decision-trees.html#interpretation-example-1"><i class="fa fa-check"></i><b>5.5.2</b> Interpretation example</a></li>
<li class="chapter" data-level="5.5.3" data-path="decision-trees.html"><a href="decision-trees.html#advantages"><i class="fa fa-check"></i><b>5.5.3</b> Advantages</a></li>
<li class="chapter" data-level="5.5.4" data-path="decision-trees.html"><a href="decision-trees.html#disadvantages"><i class="fa fa-check"></i><b>5.5.4</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html"><i class="fa fa-check"></i><b>5.6</b> Other simple, interpretable models</a><ul>
<li class="chapter" data-level="5.6.1" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html#naive-bayes-classifier"><i class="fa fa-check"></i><b>5.6.1</b> Naive bayes classifier</a></li>
<li class="chapter" data-level="5.6.2" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html#k-nearest-neighbours"><i class="fa fa-check"></i><b>5.6.2</b> k-nearest neighbours</a></li>
<li class="chapter" data-level="5.6.3" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html#rulefit"><i class="fa fa-check"></i><b>5.6.3</b> RuleFit</a></li>
<li class="chapter" data-level="5.6.4" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html#and-so-many-more"><i class="fa fa-check"></i><b>5.6.4</b> And so many more …</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="agnostic.html"><a href="agnostic.html"><i class="fa fa-check"></i><b>6</b> Model-agnostic tools for interpretability</a><ul>
<li class="chapter" data-level="6.1" data-path="pdp.html"><a href="pdp.html"><i class="fa fa-check"></i><b>6.1</b> Partial dependence plot</a></li>
<li class="chapter" data-level="6.2" data-path="individual-conditional-expectation-ice-plot.html"><a href="individual-conditional-expectation-ice-plot.html"><i class="fa fa-check"></i><b>6.2</b> Individual Conditional Expectation (ICE) plot</a></li>
<li class="chapter" data-level="6.3" data-path="permutation-feature-importance.html"><a href="permutation-feature-importance.html"><i class="fa fa-check"></i><b>6.3</b> Permutation feature importance</a><ul>
<li class="chapter" data-level="6.3.1" data-path="permutation-feature-importance.html"><a href="permutation-feature-importance.html#model-dependent-feature-importance"><i class="fa fa-check"></i><b>6.3.1</b> Model dependent feature importance</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="local-surrogate-models-lime.html"><a href="local-surrogate-models-lime.html"><i class="fa fa-check"></i><b>6.4</b> Local surrogate models (LIME)</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interpretable machine learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="individual-conditional-expectation-ice-plot" class="section level2">
<h2><span class="header-section-number">6.2</span> Individual Conditional Expectation (ICE) plot</h2>
<p>The partial dependence plot is for visualizing the averaged effect of a feature is a global method, because it does not focus on the partial dependence of a specific instance, but on an average over all. The equivalent to a PDP for local expectations is called individiual conditional expectation (ICE) plot <span class="citation">(Goldstein et al. <a href="#ref-goldstein2015peeking">2015</a>)</span>. An ICE plot visualizes the dependence of each instance’s predicted response on a feature. They are event simpler than PDPs, since no averaging is needed. Instead of drawing one line for a feature, each instance in the dataset gets it’s own line. The values for a line can be computed easily, by leaving all other features the same, but creating variants of the instance of interest and letting the black box make the predictions or classifications. The result is a set of points for a varying feature, for one specific instance. The lines for the instances can look quite differently (if the black box allows interactions between features), because the course of the line depends on the specific values of each instance. For drawing each line, the <span class="math inline">\(x_C\)</span> are fixed for this one instance, and the <span class="math inline">\(x_C\)</span> is varied on a grid and the <span class="math inline">\(\hat(y)\)</span> calculated with <span class="math inline">\(\hat(f)\)</span>.</p>
<p>So, what do you gain by looking at individual expectations, instead of partial dependencies? This averaged display can obfuscate a heterogeneous relationship that comes from interactions. ICE plots  solve this problem by plotting the relationship between feature and predicted response for individual observations. It can be seen as an extension to the standard PDP. PDP can show you how the average relationship between feature <span class="math inline">\(x_S\)</span> and <span class="math inline">\(\hat(y)\)</span> looks like. This works only well in cases where the interactions between <span class="math inline">\(x_S\)</span> and the remaining <span class="math inline">\(x_C\)</span> are weak. If there are interactions, a ICE plot will give a lot more insight.</p>
A more formal definition: In ICE plots, for each observation in <span class="math inline">\(\{(x_{S_i}, x_{C_i})\}_{i=1}^N\)</span> the curve <span class="math inline">\(\hat{f}_S^{(i)}\)</span> is plotted against <span class="math inline">\(x_{S_i}\)</span>, while <span class="math inline">\(x_{C_i}\)</span> is kept fixed. #### Example Let’s go back to the dataset about risk factors for cervical cancers and see how each instance’s prediction is associated with the feature ‘Age’. In the partial dependence plot chapter {<span class="citation">(<span class="citeproc-not-found" data-reference-id="pdp"><strong>???</strong></span>)</span>} we have seen that the probability increases around the age of 50, but does this hold true for each woman in the dataset? The ICE plot reveals that the most women’s predicted probability follows the average pattern of increase at 50, but there are a few exceptions: In a few cases, the prediction of cancer probability does not change much with the age, and that is for women that have a high predicted probability.
<div class="figure"><span id="fig:ice-cervical"></span>
<img src="xai-book_files/figure-html/ice-cervical-1.svg" alt="Individual conditional expectation plot of cervical cancer probability and age. Most women with a low cancer probability in younger years see an increase in predicted cancer probability, given all other feature values. Interestingly for a few women that have a high estimated cancer probability &gt; 0.4, the estimated probability does not change much with higher age. " width="672" />
<p class="caption">
FIGURE 6.5: Individual conditional expectation plot of cervical cancer probability and age. Most women with a low cancer probability in younger years see an increase in predicted cancer probability, given all other feature values. Interestingly for a few women that have a high estimated cancer probability &gt; 0.4, the estimated probability does not change much with higher age.
</p>
</div>
<div class="figure"><span id="fig:ice-bike"></span>
<img src="xai-book_files/figure-html/ice-bike-1.svg" alt="Individual conditional expectation plot of expected bike rentals and weather conditions . Same effects as in the partial dependence plot can be seen." width="672" />
<p class="caption">
FIGURE 6.6: Individual conditional expectation plot of expected bike rentals and weather conditions . Same effects as in the partial dependence plot can be seen.
</p>
</div>
<div id="centered-ice-plot" class="section level4">
<h4><span class="header-section-number">6.2.0.1</span> Centered ICE plot</h4>
<p>There is one issue with the ICE plot: It can be hard to see if the individual conditionl expectations curve differ between individuals when they start at different <span class="math inline">\(\hat{f^{(i)}}\)</span>. An easy fix is to center the curves at a certain point in <span class="math inline">\(x_S\)</span> and only display the difference in predited response. The resulting plot is called centered ICE plot (c-ICE). It is a kind of anchoring, and doing this at the lower end of <span class="math inline">\(x_S\)</span> is a good choice. The new curves are defined as: <span class="math display">\[\hat{f}_{cent}^{(i)} = \hat{f}_i - 1\hat{f}(x^{\text{*}}, x_{C_i}), \]</span> where <span class="math inline">\(1\)</span> is a vector of 1’s with the appropriate dimensions (usually one- or two-dimensional), and <span class="math inline">\(\hat{f}\)</span> the fitted model.</p>
</div>
<div id="example-1" class="section level4">
<h4><span class="header-section-number">6.2.0.2</span> Example</h4>
Taking Figure @ref{fig:ice-cervical} and centering the lines at the youngest observed age yields Figure @ref{fig:ice-cervical-centered}. It is easier to see now, how the relative change of the curves from the youngest age is. This can be useful when we are not interested in seing the absolute change of a predicted value, but rather the difference in prediction compared to a fixed point of the feature range.
<div class="figure"><span id="fig:ice-cervical-centered"></span>
<img src="xai-book_files/figure-html/ice-cervical-centered-1.svg" alt="Centered ICE plot for predicted cervical cancer risk probability and age. Compared to age 18, the most predictions for most instances stay the same and see an increase up to +20%. A few cases show the opposite behaviour: The predicted probability decreases with increasing age. " width="672" />
<p class="caption">
FIGURE 6.7: Centered ICE plot for predicted cervical cancer risk probability and age. Compared to age 18, the most predictions for most instances stay the same and see an increase up to +20%. A few cases show the opposite behaviour: The predicted probability decreases with increasing age.
</p>
</div>
<div class="figure"><span id="fig:ice-bike-centered"></span>
<img src="xai-book_files/figure-html/ice-bike-centered-1.svg" alt="Centered individual conditional expectation plot of expected bike rentals and weather conditions." width="672" />
<p class="caption">
FIGURE 6.8: Centered individual conditional expectation plot of expected bike rentals and weather conditions.
</p>
</div>
</div>
<div id="derivative-ice-plot" class="section level4">
<h4><span class="header-section-number">6.2.0.3</span> Derivative ICE plot</h4>
<p>Another way to make it it visually easier to spot heterogenity is to look at the individual derivatives of <span class="math inline">\(\hat(f)\)</span> with respect to <span class="math inline">\(x_S\)</span> instead of the predicted response <span class="math inline">\(\hat(f)\)</span>. The resulting plot is called derivative ICE plot (d-ICE). The derivatives of a function (or curve) tells you in which direction changes occur and if any occur at all. With the derivative ICE plot it is easy to spot value ranges in a feature where the black box’s predicted value changes for (at least some) instances. If there is no interaction between <span class="math inline">\(x_S\)</span> and <span class="math inline">\(x_C\)</span>, then <span class="math inline">\(\hat{f}\)</span> can be expressed as: <span class="math display">\[\hat{f}(x) = \hat(f)(x_S, x_C) = g(x_S) + h(x_C), \text{ so that } \frac{\delta\hat{f}(x)}{\delta x_S} = g&#39;(x_S)\]</span> Without interactions, the individual partial derivatives should be the same for all observations. If they differ, it’s because of interactions and it will become visible in the d-ICE plot. In addition to displaying the individual curves for derivative <span class="math inline">\(\hat{f}\)</span>, showing the standard deviation of derivative <span class="math inline">\(\hat{f}\)</span> helps to highlight regions in <span class="math inline">\(x_S\)</span> with heterogeneity in the estimated derivatives.</p>
<p><span class="citation">(Goldstein et al. <a href="#ref-goldstein2015peeking">2015</a>)</span></p>
</div>
<div id="example-2" class="section level4">
<h4><span class="header-section-number">6.2.0.4</span> Example</h4>
As we have seen, the most changes in estimated cancer probability happen around age 45. This is confirmed by the derivative ICE plot in Figure @ref{fig:ice-cervical-derivative}.
<div class="figure"><span id="fig:ice-cervical-derivative"></span>
<img src="xai-book_files/figure-html/ice-cervical-derivative-1.svg" alt="Derivatice ICE plot of predicted cancer probability and age. Between age 14 and the early forties, a few instance see changes in prediction both upwards and downards, but the majorities derivatives are near zero. Between age 45 and 50, most women's prediction curves have a positive derivative, indicating an increase in predicted cancer probability." width="672" />
<p class="caption">
FIGURE 6.9: Derivatice ICE plot of predicted cancer probability and age. Between age 14 and the early forties, a few instance see changes in prediction both upwards and downards, but the majorities derivatives are near zero. Between age 45 and 50, most women’s prediction curves have a positive derivative, indicating an increase in predicted cancer probability.
</p>
</div>
<div class="figure"><span id="fig:ice-bike-derivative"></span>
<img src="xai-book_files/figure-html/ice-bike-derivative-1.svg" alt="Derivative individual conditional expectation plot of expected bike rentals and weather conditions." width="672" />
<p class="caption">
FIGURE 6.10: Derivative individual conditional expectation plot of expected bike rentals and weather conditions.
</p>
</div>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-goldstein2015peeking">
<p>Goldstein, Alex, Adam Kapelner, Justin Bleich, and Emil Pitkin. 2015. “Peeking Inside the Black Box: Visualizing Statistical Learning with Plots of Individual Conditional Expectation.” <em>Journal of Computational and Graphical Statistics</em> 24 (1). Taylor &amp; Francis: 44–65.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="pdp.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="permutation-feature-importance.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/christophM/xai-book/edit/master/05.3-agnostic-ice.Rmd",
"text": "Edit"
},
"download": ["xai-book.pdf"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

<!-- </html> -->
