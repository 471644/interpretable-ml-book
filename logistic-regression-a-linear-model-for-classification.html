<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Interpretable machine learning</title>
  <meta name="description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisons more interpretable.">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Interpretable machine learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisons more interpretable." />
  <meta name="github-repo" content="christophM/xai-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Interpretable machine learning" />
  
  <meta name="twitter:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisons more interpretable." />
  

<meta name="author" content="Christoph Molnar">


<meta name="date" content="2017-10-27">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="sparse-linear-models.html">
<link rel="next" href="decision-trees.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-0.9/htmlwidgets.js"></script>
<script src="libs/datatables-binding-0.2/datatables.js"></script>
<link href="libs/dt-core-1.10.12/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.12/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.12/js/jquery.dataTables.min.js"></script>



</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Explainable machine learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="who-should-read-this-book.html"><a href="who-should-read-this-book.html"><i class="fa fa-check"></i><b>1.1</b> Who should read this book</a></li>
<li class="chapter" data-level="1.2" data-path="outline.html"><a href="outline.html"><i class="fa fa-check"></i><b>1.2</b> Outline</a></li>
<li class="chapter" data-level="1.3" data-path="what-is-machine-learning-and-why-is-it-important.html"><a href="what-is-machine-learning-and-why-is-it-important.html"><i class="fa fa-check"></i><b>1.3</b> What is machine learning and why is it important?</a></li>
<li class="chapter" data-level="1.4" data-path="definitions.html"><a href="definitions.html"><i class="fa fa-check"></i><b>1.4</b> Definitions</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="interpretability.html"><a href="interpretability.html"><i class="fa fa-check"></i><b>2</b> Interpretability</a><ul>
<li class="chapter" data-level="2.1" data-path="when-is-interpretability-important.html"><a href="when-is-interpretability-important.html"><i class="fa fa-check"></i><b>2.1</b> When is interpretability important?</a></li>
<li class="chapter" data-level="2.2" data-path="the-bigger-picture.html"><a href="the-bigger-picture.html"><i class="fa fa-check"></i><b>2.2</b> The bigger picture</a></li>
<li class="chapter" data-level="2.3" data-path="scope-of-explainability.html"><a href="scope-of-explainability.html"><i class="fa fa-check"></i><b>2.3</b> Scope of explainability</a><ul>
<li class="chapter" data-level="2.3.1" data-path="scope-of-explainability.html"><a href="scope-of-explainability.html#algorithm-transparency"><i class="fa fa-check"></i><b>2.3.1</b> Algorithm transparency</a></li>
<li class="chapter" data-level="2.3.2" data-path="scope-of-explainability.html"><a href="scope-of-explainability.html#global-holistic-model-explainability"><i class="fa fa-check"></i><b>2.3.2</b> Global, holistic model explainability</a></li>
<li class="chapter" data-level="2.3.3" data-path="scope-of-explainability.html"><a href="scope-of-explainability.html#global-model-explainability-on-a-modular-level"><i class="fa fa-check"></i><b>2.3.3</b> Global model explainability on a modular level</a></li>
<li class="chapter" data-level="2.3.4" data-path="scope-of-explainability.html"><a href="scope-of-explainability.html#explain-the-decision-for-a-single-instance"><i class="fa fa-check"></i><b>2.3.4</b> Explain the decision for a single instance</a></li>
<li class="chapter" data-level="2.3.5" data-path="scope-of-explainability.html"><a href="scope-of-explainability.html#explain-the-decisions-for-a-group-of-instances"><i class="fa fa-check"></i><b>2.3.5</b> Explain the decisions for a group of instances</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="evaluating-explainability.html"><a href="evaluating-explainability.html"><i class="fa fa-check"></i><b>2.4</b> Evaluating explainability</a><ul>
<li class="chapter" data-level="2.4.1" data-path="evaluating-explainability.html"><a href="evaluating-explainability.html#approaches-for-evaluation-of-the-explanation-quality"><i class="fa fa-check"></i><b>2.4.1</b> Approaches for evaluation of the explanation quality</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="datasets.html"><a href="datasets.html"><i class="fa fa-check"></i><b>3</b> Datasets</a><ul>
<li class="chapter" data-level="3.1" data-path="regression-dataset-bike-sharing-counts.html"><a href="regression-dataset-bike-sharing-counts.html"><i class="fa fa-check"></i><b>3.1</b> Regression dataset: Bike sharing counts</a></li>
<li class="chapter" data-level="3.2" data-path="the-dataset-speed-dating.html"><a href="the-dataset-speed-dating.html"><i class="fa fa-check"></i><b>3.2</b> The dataset: speed dating</a></li>
<li class="chapter" data-level="3.3" data-path="TubeSpam.html"><a href="TubeSpam.html"><i class="fa fa-check"></i><b>3.3</b> TubeSpam dataset: Spam classification on YouTube comments</a></li>
<li class="chapter" data-level="3.4" data-path="risk-factors-for-cervical-cancer.html"><a href="risk-factors-for-cervical-cancer.html"><i class="fa fa-check"></i><b>3.4</b> Risk factors for cervical cancer</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple.html"><a href="simple.html"><i class="fa fa-check"></i><b>4</b> Simple, interpretable models</a><ul>
<li class="chapter" data-level="4.1" data-path="terminology.html"><a href="terminology.html"><i class="fa fa-check"></i><b>4.1</b> Terminology</a></li>
<li class="chapter" data-level="4.2" data-path="overview.html"><a href="overview.html"><i class="fa fa-check"></i><b>4.2</b> Overview</a></li>
<li class="chapter" data-level="4.3" data-path="limo.html"><a href="limo.html"><i class="fa fa-check"></i><b>4.3</b> Linear models</a><ul>
<li class="chapter" data-level="4.3.1" data-path="limo.html"><a href="limo.html#interpretation"><i class="fa fa-check"></i><b>4.3.1</b> Interpretation</a></li>
<li class="chapter" data-level="4.3.2" data-path="limo.html"><a href="limo.html#interpretation-example"><i class="fa fa-check"></i><b>4.3.2</b> Interpretation example</a></li>
<li class="chapter" data-level="4.3.3" data-path="limo.html"><a href="limo.html#interpretation-templates"><i class="fa fa-check"></i><b>4.3.3</b> Interpretation templates</a></li>
<li class="chapter" data-level="4.3.4" data-path="limo.html"><a href="limo.html#visual-parameter-interpretation"><i class="fa fa-check"></i><b>4.3.4</b> Visual parameter interpretation</a></li>
<li class="chapter" data-level="4.3.5" data-path="limo.html"><a href="limo.html#explaining-single-predictions"><i class="fa fa-check"></i><b>4.3.5</b> Explaining single predictions</a></li>
<li class="chapter" data-level="4.3.6" data-path="limo.html"><a href="limo.html#coding-categorical-variables"><i class="fa fa-check"></i><b>4.3.6</b> Coding categorical variables:</a></li>
<li class="chapter" data-level="4.3.7" data-path="limo.html"><a href="limo.html#the-disadvantages-of-linear-models"><i class="fa fa-check"></i><b>4.3.7</b> The disadvantages of linear models</a></li>
<li class="chapter" data-level="4.3.8" data-path="limo.html"><a href="limo.html#towards-complexer-relationships-within-linear-model-class"><i class="fa fa-check"></i><b>4.3.8</b> Towards complexer relationships within linear model class</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="sparse-linear-models.html"><a href="sparse-linear-models.html"><i class="fa fa-check"></i><b>4.4</b> Sparse linear models</a></li>
<li class="chapter" data-level="4.5" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html"><i class="fa fa-check"></i><b>4.5</b> Logistic regression: a linear model for classification</a><ul>
<li class="chapter" data-level="4.5.1" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html#whats-wrong-with-linear-regression-for-classification"><i class="fa fa-check"></i><b>4.5.1</b> What’s wrong with linear regression for classification?</a></li>
<li class="chapter" data-level="4.5.2" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html#logistic-regression"><i class="fa fa-check"></i><b>4.5.2</b> Logistic regression</a></li>
<li class="chapter" data-level="4.5.3" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html#interpretation-1"><i class="fa fa-check"></i><b>4.5.3</b> Interpretation</a></li>
<li class="chapter" data-level="4.5.4" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html#example"><i class="fa fa-check"></i><b>4.5.4</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>4.6</b> Decision trees</a><ul>
<li class="chapter" data-level="4.6.1" data-path="decision-trees.html"><a href="decision-trees.html#interpretation-2"><i class="fa fa-check"></i><b>4.6.1</b> Interpretation</a></li>
<li class="chapter" data-level="4.6.2" data-path="decision-trees.html"><a href="decision-trees.html#interpretation-example-1"><i class="fa fa-check"></i><b>4.6.2</b> Interpretation example</a></li>
<li class="chapter" data-level="4.6.3" data-path="decision-trees.html"><a href="decision-trees.html#advantages"><i class="fa fa-check"></i><b>4.6.3</b> Advantages</a></li>
<li class="chapter" data-level="4.6.4" data-path="decision-trees.html"><a href="decision-trees.html#disadvantages"><i class="fa fa-check"></i><b>4.6.4</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html"><i class="fa fa-check"></i><b>4.7</b> Other simple, interpretable models</a><ul>
<li class="chapter" data-level="4.7.1" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html#naive-bayes-classifier"><i class="fa fa-check"></i><b>4.7.1</b> Naive bayes classifier</a></li>
<li class="chapter" data-level="4.7.2" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html#k-nearest-neighbours"><i class="fa fa-check"></i><b>4.7.2</b> k-nearest neighbours</a></li>
<li class="chapter" data-level="4.7.3" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html#rulefit"><i class="fa fa-check"></i><b>4.7.3</b> RuleFit</a></li>
<li class="chapter" data-level="4.7.4" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html#and-so-many-more"><i class="fa fa-check"></i><b>4.7.4</b> And so many more …</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="model-agnostic-explanations.html"><a href="model-agnostic-explanations.html"><i class="fa fa-check"></i><b>5</b> Model-agnostic explanations</a><ul>
<li class="chapter" data-level="5.1" data-path="global-explain-the-behaviour-of-a-model.html"><a href="global-explain-the-behaviour-of-a-model.html"><i class="fa fa-check"></i><b>5.1</b> Global: Explain the behaviour of a model</a><ul>
<li class="chapter" data-level="5.1.1" data-path="global-explain-the-behaviour-of-a-model.html"><a href="global-explain-the-behaviour-of-a-model.html#pdp"><i class="fa fa-check"></i><b>5.1.1</b> Partial dependence plot</a></li>
<li class="chapter" data-level="5.1.2" data-path="global-explain-the-behaviour-of-a-model.html"><a href="global-explain-the-behaviour-of-a-model.html#average-marginal-effects"><i class="fa fa-check"></i><b>5.1.2</b> Average Marginal Effects}</a></li>
<li class="chapter" data-level="5.1.3" data-path="global-explain-the-behaviour-of-a-model.html"><a href="global-explain-the-behaviour-of-a-model.html#feature-importance"><i class="fa fa-check"></i><b>5.1.3</b> Feature importance</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="local-explain-a-single-decisions.html"><a href="local-explain-a-single-decisions.html"><i class="fa fa-check"></i><b>5.2</b> Local: Explain a single decisions</a><ul>
<li class="chapter" data-level="5.2.1" data-path="local-explain-a-single-decisions.html"><a href="local-explain-a-single-decisions.html#individual-conditional-expectation-ice-plot"><i class="fa fa-check"></i><b>5.2.1</b> Individual Conditional Expectation (ICE) plot</a></li>
<li class="chapter" data-level="5.2.2" data-path="local-explain-a-single-decisions.html"><a href="local-explain-a-single-decisions.html#local-surrogate-models-lime"><i class="fa fa-check"></i><b>5.2.2</b> Local surrogate models (LIME)</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="model-agnostic-why-not-use-them-on-the-data-itself.html"><a href="model-agnostic-why-not-use-them-on-the-data-itself.html"><i class="fa fa-check"></i><b>5.3</b> Model-agnostic: Why not use them on the data itself?</a></li>
<li class="chapter" data-level="5.4" data-path="explanation-types.html"><a href="explanation-types.html"><i class="fa fa-check"></i><b>5.4</b> Explanation types</a><ul>
<li class="chapter" data-level="5.4.1" data-path="explanation-types.html"><a href="explanation-types.html#structured-output"><i class="fa fa-check"></i><b>5.4.1</b> Structured output</a></li>
<li class="chapter" data-level="5.4.2" data-path="explanation-types.html"><a href="explanation-types.html#viz-explanation"><i class="fa fa-check"></i><b>5.4.2</b> Visualization</a></li>
<li class="chapter" data-level="5.4.3" data-path="explanation-types.html"><a href="explanation-types.html#natural-language-narratives"><i class="fa fa-check"></i><b>5.4.3</b> Natural language (narratives)</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interpretable machine learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="logistic-regression-a-linear-model-for-classification" class="section level2">
<h2><span class="header-section-number">4.5</span> Logistic regression: a linear model for classification</h2>
<p>Logistic regression is the linear regression models counterpart for classification problems.</p>
<div id="whats-wrong-with-linear-regression-for-classification" class="section level3">
<h3><span class="header-section-number">4.5.1</span> What’s wrong with linear regression for classification?</h3>
<p>The gaussian linear model works well in most regression setup, but fails in the classification case. Why is that? In case of two classes, you could label one of the classes with 0 and the other with a 1 and use a linear model on it and it would work. There are a few problems with that approach:</p>
<ul>
<li>A linear model does try to give you probabilities, but it treats the classes as numbers (0 and 1) and fits the best hyperplane (if you have one feature, it’s a line) that minimizes the distances between the points and the hyperplane. So it simply interpolates between the points, but there is no meaning in it and you cannot interpret it as probabilities.</li>
<li>Also a linear model will extrapolate the features and give you values below zero and above one, which are not meaningful and should tell you that there might be a more clever approach to doing classification.</li>
<li>Since the predicted outcome is not a probability but some linear interpolation between points there is no meaningful threshold at which you can distinguish one class from the other. A good illustration of this issue was given on (Stackoverflow)[<a href="https://stats.stackexchange.com/questions/22381/why-not-approach-classification-through-regression" class="uri">https://stats.stackexchange.com/questions/22381/why-not-approach-classification-through-regression</a>], which I reproduced in Figure @ref{fig:linear-class-threshold}</li>
<li>Linear models don’t extend to classification problems with multiple classes. You would have to start giving labeling the next class with a 2, then 3 and so on. The classes might not have any order to them, but the linear model would force a weird structure on the relationship between the features and your class predictions. So for all features with a positive weight, the higher the features value the more they contribute to the prediction of a class with a higher number, even if the classes with similar numbers are not really related.</li>
</ul>
<div class="figure"><span id="fig:linear-class-threshold"></span>
<img src="xai-book_files/figure-html/linear-class-threshold-1.svg" alt="An illustration why linear regression does not work well in a binary classification setting. A linear model is fitted on the artificial task of classifying a tumor as malignant (1) or benign (0) depending on the tumor size. Each point is a tumor, the x-axis shows the size of the tumor, the y-axis the malignancy, points are slightly jittered to avoid overplotting of points. The lines display the fitted curve from the linear model. In the data setting on the left, we can use 0.5 as a threshold for the predicted outcome of the linear model for seperating benign from malignant tumors. After introducing a few more malignant tumor cases, especially one with a large tumor size the regression line shifts and a threshold of 0.5 would not separate  the classes any longer. That's a reason why logistic regression is better suited for classification problems." width="672" />
<p class="caption">
FIGURE 4.1: An illustration why linear regression does not work well in a binary classification setting. A linear model is fitted on the artificial task of classifying a tumor as malignant (1) or benign (0) depending on the tumor size. Each point is a tumor, the x-axis shows the size of the tumor, the y-axis the malignancy, points are slightly jittered to avoid overplotting of points. The lines display the fitted curve from the linear model. In the data setting on the left, we can use 0.5 as a threshold for the predicted outcome of the linear model for seperating benign from malignant tumors. After introducing a few more malignant tumor cases, especially one with a large tumor size the regression line shifts and a threshold of 0.5 would not separate the classes any longer. That’s a reason why logistic regression is better suited for classification problems.
</p>
</div>
</div>
<div id="logistic-regression" class="section level3">
<h3><span class="header-section-number">4.5.2</span> Logistic regression</h3>
<p>The solution is logistic regression. Instead of fitting a straight line/hyperplane and uses a non-linear function, the logistic function to squeeze the output between 0 and 1. The logistic function is defined as <span class="math display">\[ logistic(\eta) = \frac{1}{1 + exp(-\eta)}\]</span> And it looks like this:</p>
<div class="figure"><span id="fig:logistic-function"></span>
<img src="xai-book_files/figure-html/logistic-function-1.svg" alt="The logistic function. At input 0 it outputs 0.5." width="672" />
<p class="caption">
FIGURE 4.2: The logistic function. At input 0 it outputs 0.5.
</p>
</div>
<p>The step from linear regression models to logistic regression is kind of straight forward. Before we modeled the relationship like this: <span class="math display">\[\hat{y}_{i} = \beta_{0} + \beta_{1} \cdot x_{i,1} + \ldots + \beta_{K} x_{i,K} \]</span> Now we want probabilities, which are between 0 and 1, so we wrap the right side of the equation into the logistic regression function and simply force the output to be between 0 and 1: <span class="math display">\[P(y_{i}=1) =  \frac{1}{1 + exp(-(\beta_{0} + \beta_{1} \cdot x_{i,1} + \ldots + \beta_{K} x_{i,K}))}\]</span></p>
Let’s check the tumor size example again. But now instead of the linear regression model, we use the logistic regression model:
<div class="figure"><span id="fig:logistic-class-threshold"></span>
<img src="xai-book_files/figure-html/logistic-class-threshold-1.svg" alt="Logistic regression successfully finds the correct decision boundary to distinguish between malignant (class=1) and benign (class=0) tumors dependent on it's size in this illustrative example. The blue line is the logistic function shifted and squeezed so that it fits the data." width="672" />
<p class="caption">
FIGURE 4.3: Logistic regression successfully finds the correct decision boundary to distinguish between malignant (class=1) and benign (class=0) tumors dependent on it’s size in this illustrative example. The blue line is the logistic function shifted and squeezed so that it fits the data.
</p>
</div>
<p>It works better than with logistic regression and we can use 0.5 as a threshold. The line does not shift much, when including the additional datapoints.</p>
</div>
<div id="interpretation-1" class="section level3">
<h3><span class="header-section-number">4.5.3</span> Interpretation</h3>
<p>The interpretation of the coefficients differs from linear regression models. Because now our target value is not some arbitrary number, but a probability between 0 and 1. Also through the logistic function, the influence of the features on the target probability has become non-linear. That’s why we need to reformulate the equation for the interpretation&gt; <span class="math display">\[log\left(\frac{P(y_{i}=1)}{(1 - P(y_{i}=1))}\right) =  log\left(\frac{P(y_{i}=1)}{ P(y_{i}=0)}\right) = \beta_{0} + \beta_{1} \cdot x_{i,1} + \ldots + \beta_{K} x_{i,K}\]</span> <span class="math inline">\(\frac{P(y_{i}=1)}{(1 - P(y_{i}=1))}\)</span> is also called odds (probability of event vs. probability of no event) and <span class="math inline">\(log\left(\frac{P(y_{i}=1)}{(1 - P(y_{i}=1))}\right)\)</span> are the log odds. So with a logistic regression model we have a linear model for the log odds. Great! Doesn’t sound helpful! Well, with a bit of shuffling again, you can find out how the prediction changes, when one of the features <span class="math inline">\(x{\cdot, k}\)</span> is changed by 1 point. For this we can first apply the <span class="math inline">\(exp()\)</span> function on both sides of the equation: <span class="math display">\[\frac{P(y_{i}=1)}{(1 - P(y_{i}=1))} = odds_i =  exp\left(\beta_{0} + \beta_{1} \cdot x_{i,1} + \ldots + \beta_{K} x_{i,K}\right)\]</span> Then we compare what happens when we increase one of the <span class="math inline">\(x_{i,j}&#39;s\)</span> by 1. But instead of looking at the difference, we look at the ratio of the two predictions, you will see why: <span class="math display">\[ \frac{odds_{i, x_i + 1}}{odds_i}= \frac{exp\left(\beta_{0} + \beta_{1} \cdot x_{i,1} + \ldots + \beta_{k} \cdot (x_{i,k} + 1)  + \ldots+ \beta_{K} x_{i,K}\right)}{exp\left(\beta_{0} + \beta_{1} \cdot x_{i,1} + \ldots + \beta_{k} \cdot x_{i,k}  + \ldots+ \beta_{K} x_{i,K}\right) }  \]</span> Using the rule that <span class="math inline">\(\frac{exp(a)}{exp(b)} = exp(a - b)\)</span> gives us: <span class="math display">\[ \frac{odds_{i, x_i + 1}}{odds_i}=exp\left( (\beta_{0} + \beta_{1} \cdot x_{i,1} + \ldots + \beta_{k} \cdot (x_{i,k} + 1)  + \ldots+ \beta_{K} x_{i,K}\right) - \left(\beta_{0} + \beta_{1} \cdot x_{i,1} + \ldots + \beta_{k} \cdot x_{i,k}  + \ldots+ \beta_{K} x_{i,K})\right)\]</span> And then we can remove a lot of terms from the equation, which is convenient: <span class="math display">\[ \frac{odds_{i, x_i + 1}}{odds_i}=  exp\left( \beta_{k} \cdot (x_{i,k} + 1) - \beta_{k} \cdot x_{i,k} \right) = exp\left(\beta_k\right)\]</span></p>
<p>And we end up with something simple like <span class="math inline">\(\exp(\beta_k)\)</span>. So a change in <span class="math inline">\(x_k\)</span> by one unit changes the odds ratio (multiplicatively) by a factor of <span class="math inline">\(\exp(\beta_k)\)</span>. We could also interpret it this way: A change in <span class="math inline">\(x_k\)</span> by one unit change the log odds ratio by <span class="math inline">\(\beta_k\)</span> units, but most people do the former because thinking in logs is known to be hard on the brain. Interpreting the odds ratio already needs a bit of getting used to. If you have odds of 2, it means that the probability for <span class="math inline">\(y_i = 1\)</span> is twice as big as <span class="math inline">\(y_i = 0\)</span>. If you have a <span class="math inline">\(\beta\)</span> (=odds ratio) of <span class="math inline">\(0.7\)</span>, then an increase in the respective x by one unit multiplies the odds by <span class="math inline">\(\exp(0.7) \approx 2\)</span> and your odds would be 4. But usually you don’t deal with the odds and only interpret the <span class="math inline">\(\beta\)</span> as the odds ratios. Because for actually calculating the odds you would need to set a value for each <span class="math inline">\(x_{i,k}\)</span> for all <span class="math inline">\(k\)</span>, which only makes sense if you want to look at one specific instance of your dataset.</p>
<p>Here are the interpretations for the logistic regression model with different variable types:</p>
<ul>
<li>Continuous variable: For an increase of one unit of the variable <span class="math inline">\(x_{j}\)</span> the estimated odds change (multiplicatively) by a factor of <span class="math inline">\(\exp{\beta_{j}}\)</span></li>
<li>Binary categorical variables: One of the variables is the reference level (in some languages the one that was coded in 0). A change of the variable <span class="math inline">\(x_{i}\)</span> the reference level to the other category changes the estimated odds change (multiplicatively) by a factor of <span class="math inline">\(\exp{\beta_{j}}\)</span></li>
<li>Categorical variables with many levels: One solution to deal with many variables is to one-hot-encode them, meaning each level gets it’s own column. From a categorical variable with L levels, you only need L-1 columsn, otherwise it is over parameterized. The interpretation for each level is then according to the binary variables. Some language like R allow to</li>
<li>Intercept <span class="math inline">\(\beta_{0}\)</span>: The interpretation is: Given all continuous variables are zero and the categorical variables are on the reference level, the estimated odds are is <span class="math inline">\(\exp{\beta_{0}}\)</span>. The interpretation of <span class="math inline">\(\beta_{0}\)</span> is usually not relevant.</li>
</ul>
</div>
<div id="example" class="section level3">
<h3><span class="header-section-number">4.5.4</span> Example</h3>
<p>With the logistic regression model we can predict cervical cancer given risk factors.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Estimate</th>
<th align="right">Odds ratio</th>
<th align="right">Std. Error</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Intercept</td>
<td align="right">2.9101469</td>
<td align="right">18.3594963</td>
<td align="right">0.3225918</td>
</tr>
<tr class="even">
<td>Hormonal contraceptives y/n</td>
<td align="right">0.1166594</td>
<td align="right">1.1237366</td>
<td align="right">0.2989597</td>
</tr>
<tr class="odd">
<td>Smokes y/n</td>
<td align="right">-0.2557759</td>
<td align="right">0.7743154</td>
<td align="right">0.3719329</td>
</tr>
<tr class="even">
<td>Num. of pregnancies</td>
<td align="right">-0.0368039</td>
<td align="right">0.9638651</td>
<td align="right">0.0965331</td>
</tr>
<tr class="odd">
<td>Num. of diagnosed STDs</td>
<td align="right">-0.8154926</td>
<td align="right">0.4424213</td>
<td align="right">0.3260103</td>
</tr>
<tr class="even">
<td>Intrauterine device y/n</td>
<td align="right">-0.6163016</td>
<td align="right">0.5399376</td>
<td align="right">0.3995933</td>
</tr>
</tbody>
</table>
<p>Interpretation of a numerical variable (‘Num. of diagnosed STDs’): An increase of the number of diagnosed STDs changes (decreases) the odds for cancer vs. no cancer multiplicatively by 0.44, given all other features stay the same. Keep in mind that correlation does not imply causation. No recommendation here to get STDs.</p>
<p>Interpretation of a categorical variable (‘Hormonal contraceptives y/n’): For women with hormonal contraceptives, the odds for cancer vs no cancer are by a factor of 1.12 higher, compared women without hormonal contraceptives, given all other features stay the same.</p>
<p>Again as in the linear models, the interpretations are always coming with the clause that ‘all other features stay the same’.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="sparse-linear-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="decision-trees.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/christophM/xai-book/edit/master/04-interpretable-models.Rmd",
"text": "Edit"
},
"download": ["xai-book.pdf"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

<!-- </html> -->
