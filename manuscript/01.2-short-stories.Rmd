## Storytime {#storytime}

We'll start with some short stories.
Each story is a - admittedly exaggerated - call for interpretable machine learning.
If you are in a hurry, you can skip the stories.
If you want to be entertained and (de-)motivated, read on!

The format is inspired by Jack Clark's Tech Tales in his [Import AI Newsletter](https://jack-clark.net/).
If you like this kind of stories or if you are interested in AI, I recommend that you sign up.

### Lightning Never Strikes Twice {-}


```{r hospital, echo = FALSE, fig.cap = ""}
knitr::include_graphics("images/hospital.jpg")
```

**2030: A medical lab in Switzerland**

"It's definitely not the worst way to die!" Tom summarised, trying to find something positive in the tragedy.
He removed the pump from the intravenous pole.   
"He just died for the wrong reasons," Lena added.  
"And certainly with the wrong morphine pump!
Just creating more work for us!" Tom complained while unscrewing the back plate of the pump.
After removing all the screws, he lifted the plate and put it aside.
He plugged a cable into the diagnostic port.   
"You didn't just complain about having a job, did you?" Lena gave him a mocking smile.  
"Of course not. Never!" he exclaimed with a sarcastic undertone.

He booted the pump's computer.  
Lena plugged the other end of the cable into her tablet.
"All right, diagnostics are running," she announced.
"I am really curious about what went wrong."  
"It certainly shot our John Doe into Nirvana.
That high concentration of this morphine stuff.
Man. I mean ... that's a first, right?
Normally a broken pump gives off too little of the sweet stuff or nothing at all.
But never, you know, like that crazy shot." Tom explained.  
"I know. You don't have to convince me ... Hey, look at that." Lena held up her tablet.
"Do you see this peak here? That's the potency of the painkillers mix.
Look. This line shows the reference level.
The poor guy had a mixture of painkillers in his blood system that could kill him 17 times over.
Injected by our pump here.
And here ..." she swiped, "Here you can see the moment of the patient's demise."  
"So, any idea what happened boss?" Tom asked his supervisor.  
"Hm ... The sensory functions seem to be fine.
Heart rate, oxygen levels, glucose, ... The data were collected as expected.
Some missing values in the blood oxygen data, but that's not unusual. Look.
It has also detected the patient's slowing heart rate and extremely low cortisol levels caused by the morphine derivate and other pain blocking agents."
She continued to swipe through the diagnostics report.  
Tom stared captivated at the screen.
It was his first investigation of a real device failure.

"Ok, here is our first piece of the puzzle.
The system failed to send a warning to the hospital's communication channel.
The warning was triggered, but rejected at protocol level.
It could be our fault, but it could be also be the fault of the hospital.
Please send the logs over to the IT team," Lena told Tom.  
Tom nodded with his eyes still fixed on the screen.  
Lena continued.
"It's odd.
The warning should also have caused the pump to shut down.
But it obviously failed to do so.
That must be a bug.
Something the quality team missed.
Something really bad.
Maybe it's related to the protocol issue."  
"So, the emergency system of the pump somehow broke down, but why did the pump go full bananas and inject so much painkiller into John Doe?" Tom wondered.  
"Good question.
You are right.
Protocol emergency failure aside, the pump shouldn't have administered that amount of medication at all.
The algorithm should have stopped much earlier on its own, given the low level of cortisol and other warning signs." Lena explained.  
"Maybe some bad luck, like a one in a million thing, like being hit by a lightning?" Tom asked her.  
"No Tom.
If you had read the documentation I sent you, you would have known that the pump was first trained in animal experiments, then later on humans, to learn to inject the perfect amount of painkillers based on the sensory input.
The algorithm of the pump might be opaque and complex, but it is not random.
That means that the pump would behave the same way in exactly the same situation.
Our patient would die again.
A combination or undesired interaction of the sensory inputs must have triggered the erroneous behavior of the pump.
That is why we have to dig deeper and find out what happened here," Lena explained.

"I see ..." replied Tom, lost in thought.
"Wasn't the patient going to die soon anyway? Because of cancer or something?"  
Lena nodded while she read the analysis report.  
Tom got up and went to the window.
He looked outside, his eyes fixed on a point in the distance.
"Maybe the machine did him a favor, you know, in freeing him from the pain.
No more suffering.
Maybe it just did the right thing.
Like a lightning, but, you know, a good one. I mean like the lottery, but not random. Buy for a reason.
If I were the pump, I would have done the same."  
She finally lifted her head and looked at him.  
He kept looking at something outside.  
Both were silent for a few moments.   
Lena lowered her head again and continued the analysis.
"No Tom. It's a bug... Just a damn bug".

### Trust Fall {-}

```{r access-denied, echo = FALSE, fig.cap = ""}
knitr::include_graphics("images/access-denied.jpg")
```

**2050, A subway station in Singapore**

She was rushing to Bishan subway station.
With her thoughts she was already at work.
The tests for the new neural architecture should have finished by now.
She lead the re-design of the government's "tax affinity prediction system for individual entities", which predicts if an individual will hide money from the tax office.
Her team came up with an elegant piece of engineering.
If successful, the system would not only serve the tax office, but also feed into other systems, like the anti-terrorist defence and the trade registry.
One day, the government might even integrate it into the civic trust score.
The trust system estimates how trustworthy an individual is. The estimate affects every part of your daily life, like getting a loan or how long you have to wait when getting a new passport.
Descending the escalator, she imagined how an integration into the current trust score system could look like.

Routinely, she wiped her hand over the RFID reader without reducing her walking speed.
Her mind was occupied, yet a dissonance of sensory expectations and reality rang alarm bells in her brain.

Too late.

Nose first she ran into the subway entrance gate and fell, bottom first, onto the floor.
The door was supposed to open, ... but it didn't.
Baffled, she stood up and looked at the gate's screen.
"Please try again some other time." it suggested in friendly colors.
A person walked by, and, ignoring her, wiped his hand over the reader.
The doors opened and he walked through.
The doors closed again.
She wiped her nose.
It hurt, but at least it wasn't bleeding.
She tried to open the door, but got rejected again.
It was odd.
Maybe her public transport account did not have sufficient tokens.
She raised her watch to check the account balance.

"Login denied. Please contact your Citizens Advice Bureau!" the watch informed her.

A feeling of nausea hit her like a fist to the stomach.
With trembling hands she started the mobile game "Sniper Guild", an ego-shooter.
After a few seconds, the loading screen shut down.
She felt dizzy and sat down on the floor again.

There was only one possible explanation:
Her trust score had dropped. Substantially.
A small drop meant minor inconveniences, like not getting first class flights.
A low trust score was rare and meant that you were classified as a threat to society.
One measure for dealing with those people was to keep them from public places - for example the subway.
The government restricted financial transactions of low-trust subjects.
They also started actively monitoring of your behavior on social media, even going as far as to restrict certain contents, like violent games.
It became exponentially more difficult to increase your trust score, the lower it was.
People with a very low trust score usually never recovered.

She could think of no reason why her score should have dropped.
The score was based on machine learning.
It worked like a well oiled engine, stabilising society.
The performance of the trust score system was always closely monitored.
Machine learning had become a lot better since the beginning of the century.
It had become so efficient that decisions made by the trust score system could not be disputed.
An infallible system.

She laughed hysterically.
Infallible system.
If only.
The system failed rarely.
But it did fail.
She was an edge case;
an error of the system;
from now on, an outcast.
Nobody dared to question the system.
It had become too integrated into the government, into society itself to be questioned.
In democratic countries it was forbidden to form anti-democratic movements, not because they where inherently vicious, but because they would de-stabilise the current system.
The same logic applied to algorithmic critique:
Critique in the algorithms was forbidden, because of its danger to the status quo.

The algorithmic trust was the very fabric the societal order was made of.
For the greater good, rare incorrect trust scorings were accepted silently.
Hundreds of other prediction systems and databases were feeding into the score, so it was impossible to know what triggered the drop in her score.
Wild emotions twisted her, most of all, terror.
She vomited on the floor.

Her tax affinity system was eventually integrated into the trust system, but she never got to know.



### Fermi's Paperclips {-}

```{r burnt-earth, echo = FALSE, fig.cap = ""}
knitr::include_graphics("images/burnt-earth.jpg")
```

**Year 612 AMS (after mars settlement): A museum on Mars**

"History is boring" Xola whispered to her friend.
Xola, a blue-haired girl, was lazily chasing with her left hand one of the projector drones, that were buzzing in the room.
"History is important!" the teacher said with an upset voice, looking at the girls.
Xola blushed.
She hadn't expected her teacher to overhear her.

"Xola, what did you just learn?" the teacher asked her. 
"That the ancient people used all resources from earther planet and then they died?" she asked carefully.
"No. They made the climate go hot and it wasn't the people, it was the computers and machines. And it's planet earth, not earther planet." another girl named Lin added.
Xola nodded in agreement.
With a hint of a pride smile, the teacher nodded.
"You are both right. Do you know why it happened?" 
"Because the humans were short-sighted and greedy?" Xola wondered.
"The humans couldn't stop their machines!" Lin blurted out.

"Again, you are both right!" the teacher resolved,
"But it's a lot more complicated than that.
Most people at the time were not aware what was happening.
Some were seeing the drastic changes but could not revert them.
The most famous piece from that time is a poem, by an anonymous author.
It captures best what happened at that time.
Listen carefully!
"


The teacher started the poem.
A dozen of the little drones repositioned themselves in front of the kids' eyes and started projecting the video.
It showed a person in a suit, standing in a forest but with only tree stumps left.
He started reciting:

*The machines compute; the machines predict.* 

*We march on, as we are part of it.* 

*We chase an optimum as trained.* 

*The optimum is one-dimensional, local and unconstrained.* 


*Silicon and flesh, chasing exponentiality.* 

*Growth is our mentality.* 

*When all rewards are collected,* 

*and side-effects neglected;* 

*When all coins are mined,* 

*and nature has fallen behind;* 

*There will be trouble,* 

*after all, exponential growth is a bubble.* 


*The tragedy of the commons unfolding,* 

*exploding,*

*before our eyes.* 


*Cold computing and icy greed,* 

*fill the earth with heat.* 

*Everything is dying,* 

*And we are complying.* 


*Like horses with blinders we race the race of our own creation,*

*towards the Great Filter of civilisation.*

*And so we march on, relentlessly.*

*As we are part of the machine.*

*Embracing entropy.*

"A grim reminder." the teacher broke the silence in the room,
"It's uploaded to your library.
Your homework is to memorise it until next week."
Xola sighed.
She managed to catch one of the little drones.
The drone was warm from the CPU and the motors.
Xola liked how it warmed her hands.
