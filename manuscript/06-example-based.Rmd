```{r, message = FALSE, warning = FALSE, echo = FALSE}
devtools::load_all()
set.seed(42)
```


# Example-based explanations {#example-based}

Example-based explanations methods select particular instances of the dataset to explain the behavior of machine learning models or to explain the underlying data distribution.

*Keywords: example-based explanations, case-based reasoning (CBR), solving by analogy*

Example-based explanations are mostly model-agnostic, because they make any machine learning model more interpretable.
The difference with model-agnostic methods is that the example-based explanation methods select instances of the dataset and don't create summaries of features (such as [feature importance](#feature-importance) or [partial dependence](#pdp).
Example-based explanations only make sense if we can represent an instance of the data in a humanly understandable way.
This works well for images, because we can view them directly.
It's more difficult to represent tabular data in a meaningful way, because an instance can consist of hundreds or thousands of features.
Listing all feature values to describe an instance is usually not useful.
It works well if there are only a handful of features or if we have a way to summarize an instance.

Example-based explanations help humans construct mental models of the machine learning model and the data the machine learning model has been trained on.
It especially helps to understand complex data distributions.


But what do I mean by example-based explanations?
We often use them in our jobs and daily lives.
Let's start with some real world examples [^cbr]:

A physician sees a patient with an unusual cough and a mild fever.
The patient's symptoms remind her of another patient she had years ago with similar symptoms. 
She suspects that her current patient could have the same disease and takes a blood sample to test for this specific disease.

A data scientist is working on a new project for one of his clients:
Analysis of the risk factors that lead to the failure of production machines for keyboards.
The data scientist remembers a similar project he worked on and re-uses parts of the code from the old project because he thinks the client wants the same analysis.

A kitten sits on the windowstill of a burning and uninhabited house. 
The fire department has already arrived and one of the firefighters ponders for a second whether he can risk going into the building to save the kitten 
He remembers some similar scenarios in his life as a firefighter: 
old wooden houses that have been burning slowly for some time 
In a similar stage of the fire, some of those houses had became unstable and eventually collapsed.
Because of the similarity of this case, he decides not to enter, because the risk of the house collapsing is too great. 
Fortunately, the kitty jumps out of the window, lands safely and nobody is harmed in the fire (happy end!).

These stories illustrate examples of how we humans think in example or analogies.
The blueprint of example-based explanations (sometimes called case-based reasoning) is: 
Thing B is similar to thing A and A caused Y, so I predict that B will cause Y as well.
Implicitly, some machine learning approaches work example-based.
[Decision trees](#tree) partition the data into nodes based on the similarities of the data points in the features that are important for predicting the target.
A decision tree predicts a new data points by finding the data points that are similar (= in the same terminal node) and returning the average of the outcomes of those points as a prediction.
The k-nearest neighbours (knn) machine learning model works explicitly with example-based predictions. 
A knn model predicts a new data point by asking what the k nearest data points are for the new data point and returning the average of the outcomes of those neighbours as a prediction.
The prediction of a knn can be explained by returning the k neighbours, which - again - is only meaningful if we have a good way to represent a single instance.

This chapter covers the following example-based interpretability methods:

- [k-nearest neighbours model](#other-interpretable): A (interpretable) machine learning model  based on examples.
- **Counterfactuals and adverserial examples**. Counterfactuals tell us how an instance has to change to reverse its prediction. 
The focus is on explaining a single prediction. 
Adversarial examples are counterfactuals used to fool machine learning models. 
The emphasis is on flipping the prediction and not explaining it. (WORK IN PROGRESS)
- [Prototypes and criticisms](proto). Prototypes are a selection of representative instances from the data and criticisms are instances that are not well represented by those prototypes.
- **Archetypes** are the most extreme instances in the data based on the features. (WORK IN PROGRESS)
- **Influence Functions** is a method to identify the instances that were most influential for a prediction model. [^koh] (WORK IN PROGRESS)


## Prototypes and criticisms {#proto}

A **prototype** is a data instance that is representative of all the data.
Prototypes can improve the interpretability of complex data distributions, but they may not be sufficient to explain the data.
They are only sufficient if the data distribution within the classes is very homogeneous.
A **criticism** is a data instance that is not well represented by the set of prototypes.
The purpose of criticisms is to provide insights together with prototypes, especially for data points which the prototypes don't represent well.
Prototypes and criticisms can be used independently from machine learning to describe only the data, but they can also be used to create an interpretable model or to make a black box model interpretable.

In this chapter I use the word '(data) point' to refer to a single instance, to emphasize the interpretation that an instance is also a point in a coordinate system where each feature is a dimension.
The following figures show an artificial data distribution, with some of the instances chosen as prototypes and some as criticisms.
The small points are the data, the large points the prototypes and the large triangles are the criticisms.
The prototypes are selected (manually) to cover the centers of the data distribution and the criticisms are points in a cluster without a prototype.
Prototypes and criticisms are always actual instances from the data.

```{r, fig.cap = "Prototypes and criticisms."}
set.seed(1)
dat1 = data.frame(x1 = rnorm(20, mean = 4, sd = 0.3), x2 = rnorm(20, mean = 1, sd = 0.3))
dat2 = data.frame(x1 = rnorm(30, mean = 2, sd = 0.2), x2 = rnorm(30, mean = 2, sd = 0.2))
dat3 = data.frame(x1 = rnorm(40, mean = 3, sd = 0.2), x2 = rnorm(40, mean = 3))
dat4 = data.frame(x1 = rnorm(7, mean = 4, sd = 0.1), x2 = rnorm(7, mean = 2.5, sd = 0.1))

dat = rbind(dat1, dat2, dat3, dat4)
dat$type = "data"
dat$type[c(7, 23, 77)] = "prototype"
dat$type[c(81,95)] = "criticism"

ggplot(dat, aes(x = x1, y = x2)) + geom_point(alpha = 0.7) +
  geom_point(data = filter(dat, type!='data'), aes(shape = type), size = 9, alpha = 1, color = "blue") + 
  scale_shape_manual(breaks = c("prototype", "criticism"), values = c(19, 18)) 

```

I selected the prototypes manually, which doesn't scale well and probably leads to poor results.
There are many approaches to find prototypes in the data. 
One of these is k-medoids, a clustering algorithm related to the k-means algorithm.
Any clustering algorithm that returns actual data points as cluster centers would qualify for selecting prototypes.
But most of these methods find only prototypes, but no criticisms.
This chapter presents MMD-critic by Kim et. al (2016)[^critique], an approach that combines finding prototypes and criticisms in a single framework.

MMD-critic compares the distribution of the data and the distribution of the selected prototypes.
This is the central concept for understanding the MMD-critic method.
MMD-critic selects prototypes that minimize the discrepancy between the two distributions.
Data points in areas with high data density are good prototypes, especially when points  are selected from different 'data clusters'.
Data points from regions that are not vwell explained  by the prototypes are selected as criticisms.

Let's delve deeper into the theory.

#### Theory

The MMD-critic procedure on a high-level can be summarized briefly:

1. Set the number of prototypes and criticisms you want to find.
1. Select prototypes with greedy search. 
Prototypes are selected so that the distribution of the prototypes is close to the data distribution.
1. Select criticisms with greedy search. 
Points are selected as criticisms when the distribution of prototypes and of the data differ the most.

We need a couple of ingredients to find prototypes and criticisms for a dataset with MMD-critic.
As the most basic ingredient, we need a **kernel function** to estimate the data densities.
A kernel is a function that weights two data points according to their distance.
Based on density estimates, we need a measure that tells us how different two distributions are so that we can determine whether the distribution of the prototypes we select is close to the data distribution.
This is solved by measuring the **maximum mean discrepancy (MMD)**.
Also based on the kernel function, we need the **witness function** to tell us how different two distribution are at a particular data point. 
With the witness function, we can select criticisms, i.e. data points at which the distribution of prototypes and data diverges and the witness function takes on large absolute values.
The last ingredient is a search strategy for good prototypes and criticisms, which is solved with a simple **greedy search**.


Let's start with the **maximum mean discrepancy (MMD)**, which measures the discrepancy between two distributions.
The selection of prototypes creates a density distribution of prototypes.
The aim of MMC-critic is to minimize the discrepancy between this distribution of the prototypes and the data distribution. 
We want to evaluate whether the distributions are different, based on their empirical distributions which are with the help of the by kernel densities.
The maximum mean discrepancy measures the difference between two distributions, which is the supremum over a function space of differences between the expectation according to the two distributions.
All clear?
Personally, I understand these concepts much better when I see the formulas, how something is calculated with data.
The following formula shows how to calculate the squared MMD measure (MMD2):

$$MMD^2=\frac{1}{m}\sum_{i,j=1}^m{}k(z_i,z_j)-\frac{2}{mn}\sum_{i,j=1}^{m,n}k(z_i,x_j)+\frac{1}{n^2}\sum_{i,j=1}^n{}k(x_i,x_j)$$

k is a kernel function that measures the similarity of two points, but more about this later.
m is the number of prototypes z, and n is the number of data points x in our original dataset.
The prototypes z are a selection of data points x.
Each point is multidimensional, that is it can have multiple features. 
The goal of MMD-critic is to minimize MMD2.
The closer MMD2 is to zero, the better the distribution of the prototypes fits the data.

The following graphic illustrates the MMD2 measure. 
The first plot shows the data points with two features, whereby the estimation of the data density is displayed with a shaded background.
Each of the other plots shows different selections of prototypes, along with the MMD2 measure in the plot titles.
The prototypes are the large red dots and their distribution is shown as contour lines.
The selection of the prototypes that best cover the data in these scenarios (bottom left) has the lowest discrepancy value.

```{r mmd, fig.cap = "The squared maximum mean discrepancy measure (MMD2) for a dataset with two features and different selections of prototypes."}
set.seed(42)
n = 40
# create dataset from three gaussians in 2d
dt1 = data.frame(x1 = rnorm(n, mean = 1, sd = 0.1), x2 = rnorm(n, mean = 1, sd = 0.3))
dt2 = data.frame(x1 = rnorm(n, mean = 4, sd = 0.3), x2 = rnorm(n, mean = 2, sd = 0.3))
dt3 = data.frame(x1 = rnorm(n, mean = 3, sd = 0.5), x2 = rnorm(n, mean = 3, sd = 0.3))
dt4 = data.frame(x1 = rnorm(n, mean = 2.6, sd = 0.1), x2 = rnorm(n, mean = 1.7, sd = 0.1))
dt = rbind(dt1, dt2, dt3, dt4)


radial = function(x1, x2, sigma = 1) {
  dist = sum((x1 - x2)^2)
  exp(-dist/(2*sigma^2))
}


cross.kernel = function(d1, d2) {
  kk = c()
  for (i in 1:nrow(d1)) {
    for (j in 1:nrow(d2)) {
      res = radial(d1[i,], d2[j,])
      kk = c(kk, res)
    }
  }
  mean(kk)
}

mmd2 = function(d1, d2) {
  cross.kernel(d1, d1) - 2 * cross.kernel(d1, d2) + cross.kernel(d2,d2)
}

# create 3 variants of prototypes
pt1 = rbind(dt1[c(1,2),], dt4[1,])
pt2 = rbind(dt1[1,], dt2[3,], dt3[19,])
pt3 = rbind(dt2[3,], dt3[19,])

# create plot with all data and density estimation
p = ggplot(dt, aes(x = x1, y = x2)) + 
  stat_density_2d(geom = "tile", aes(fill = ..density..), contour = FALSE, alpha = 0.9) + 
  geom_point() + 
  scale_fill_gradient2(low = "white", high = "blue", guide = "none") + 
  scale_x_continuous(limits = c(0, NA)) + 
  scale_y_continuous(limits = c(0, NA))
# create plot for each prototype
p1 = p + geom_point(data = pt1, color = "red", size = 4) + geom_density_2d(data = pt1, color = "red") + 
  ggtitle(sprintf("%.3f MMD2", mmd2(dt, pt1))) 

p2 = p + geom_point(data = pt2, color = "red", size = 4) + 
  geom_density_2d(data = pt2, color = "red") + 
  ggtitle(sprintf("%.3f MMD2", mmd2(dt, pt2)))

p3 = p + geom_point(data = pt3, color = "red", size = 4) + 
  geom_density_2d(data = pt3, color = "red") + 
  ggtitle(sprintf("%.3f MMD2", mmd2(dt, pt3)))
# TODO: Add custom legend for prototypes

# overlay mmd measure for each plot
gridExtra::grid.arrange(p, p1, p2, p3, ncol = 2)
```


A choice for the kernel is the radial basis function kernel:

$$k(x,x')=exp\left(\gamma||x-x'||^2\right)$$
where ||x-x'|| is the Euclidean distance between two points.
$\gamma$ is a scaling parameter. 
The value of the kernel decreases with the distance between the two points and ranges between zero and one:
Zero when the two points are infinitely far apart' 
One when the two points are equal.

We combine the MMD measure and the kernel with greedy search in an algorithm for finding prototypes:

- Start with an empty list of prototypes.
- While the number of prototypes is below the chosen number m:
    - For each point in the dataset, check how much the MMD2 of the prototypes is reduced the point is added to the list. Add the data point that minimizes the MMD2 to the list.
- Return the list of prototypes.

The remaining ingredient we need to find criticisms is the witness function, which tells us how much two probability distributions differ at a particular point. 
It can be estimated using:

$$g(x)=\frac{1}{n}\sum_{i=1}^nk(x,x_i)-\frac{1}{m}\sum_{j=1}^mk(x,z_j)$$
The witness function checks the difference between two density estimates for a particular point.
For two datasets (with the same features), the witness function gives you the means of evaluating in which empirical distribution the point x fits more.
To find criticisms, we look for extreme values of the witness function in both negative and positive directions.
If the witness function for a point x is close to zero, the density function of the data and the prototypes are close together, which means that the distribution of prototypes resembles the distribution of the data at point x.
A positive witness function at point x means that the prototype distribution overestimates the data distribution (for example if we select a prototype with few data points nearby);
a negative witness function at point x means that the prototype distribution underestimates the data distribution (for example if there are many data points around x, but haven't selected any prototypes nearby).

To give you more intuition, let's reuse the prototypes from the plot beforehand with the lowest MMD2 and display the witness function for a few manually selected points.
The labels in the following plot show the value of the witness function for various points marked as triangles
Only the point in the middle has a high absolute value and is therefore a good candidate for a criticism.


```{r witness, fig.cap = "Evaluations of the witness function at different points."}
witness = function(x, dist1, dist2, sigma = 1) {
  k1 = apply(dist1, 1, function(z) radial(x, z, sigma = sigma))
  k2 = apply(dist2, 1, function(z) radial(x, z, sigma = sigma))
  mean(k1) - mean(k2)
}

w.points.indices = c(125, 2, 60, 19, 100)
wit.points = dt[w.points.indices,]
wit.points$witness = apply(wit.points, 1, function(x) round(witness(x[c("x1", "x2")], pt2, dt, sigma = 1), 3))

p + geom_point(data = pt2, color = "red") + 
  geom_density_2d(data = pt2, color = "red") + 
  ggtitle(sprintf("%.3f MMD^2", mmd2(dt, pt2))) + 
  geom_label(data = wit.points, aes(label = witness), alpha = 0.9, vjust = "top") + 
    geom_point(data = wit.points, color = "black", shape = 17, size = 4) 
```

The witness function allows us to explicitly search for data instances that are not ell represented by the prototypes.
Criticisms are points with high absolute value in the witness function.
The process of finding criticisms is the same greedy search as finding the prototypes. 
But instead of reducing the overall MMD2, we are looking for points that maximize a cost function that includes the witness function and a regularizer term.
The additional term in the optimization function enforces diversity in the points, which is needed so that the points come from the different cluster.

This second step is independent of how the prototypes are found.
I could also have handpicked some prototypes and used the procedure described here to learn criticisms.
Or the prototypes could come from any clustering procedure, like k-medoids.

That's it with the important parts of MMD-critic theory. 
One question remains:
**How can MMD-critic be used for interpretable machine learning?**

MMD-critic can add interpretability in three ways: 
1) By helping to understand the data distribution better; 2) By building an interpretable model; 3) By making a black box model interpretable.

If you only apply MMD-critic to your data to find prototypes and criticisms it will improve understanding of the data, especially when you have a complex distribution with some edge cases.
Judging from that I would have to cover boxplots, summary statistics, scatter plots and all the other tools for descriptive statistics tools in this book (which I don't).
But you can do more things with MMD-critic!

For example, you can build an interpretable prediction model from the prototypes.
The resulting model is a nearest prototype model. 
After learning prototypes, the model returns the outcome of the nearest prototype as the prediction of a new data point.
As an explanation for the prediction, the prototype itself is returned.
The prediction function is defined as:

$$\hat{f}(x)=argmax_{i\in{}S}k(x,x_i)$$

meaning that we choose the prototype i from the set of prototypes S, that is closest to the new data point in the sense that produces the highest kernel function value.
This procedure has three tuning parameters: 
The type of kernel, the kernel scaling parameter and the number of prototypes.
All parameters can be optimized within a cross validation loop.
The criticisms are not used for this approach.

As a third option, we can use MMD-critic for making any machine learning model more explainable globally by studying prototypes and criticisms together with their model predictions.
The procedure is as follows:

1. Find prototypes and criticisms with MMD-critic.
1. Train a machine learning model as usual.
1. Predict the prototypes and criticisms with the ML model.
1. Analyse the predictions: In which cases was the algorithm wrong? Now you have an interpretable set of examples, where you know that it represents the data well and it can help you find the weaknesses of the machine learning model.

How does that help?
Remember when Google's image classifier tagged black people as Gorillas?
Maybe they should have used the procedure described here before deploying their image recognition algorithm.
Simply checking the performance of the model is not enough, because if it were 99% correct, this issue could still be in the 1%.
And labels can also be wrong!
Going through all the training data and doing a sanity check if the prediction is problematic might have uncovered the problem, but would be infeasible.
But choosing - let's say a couple of thousands of - prototypes and criticisms is feasible and might have uncovered a problem with the data:
It might have shown that for the image class 'human' there are only people with white skin, which indicates a problem with the diversity in the dataset.
Or it might have shown one or more image of a person with dark skin as prototype or (probably) as criticism with the infamous 'Gorilla' model prediction.
I am not promising that MMD-critic would catch these kind of errors for certain, but it's a good sanity check.

### Examples:

I took the examples from the MMD-critic paper. 
Both applications are with images.
Each image was represented using image embeddings with 2048 dimensions. 
An image embedding is an abstract representation of an image by a vector, which can be extracted from the weights of a neural network that has been trained to solve an image recognition task, in this case it was the ImageNet classification dataset.
The kernel distances between images were calculated using these embedding vectors.

The first dataset contains different breeds of dogs from the ImageNet dataset.
MMD-critic is applied on data of two dog breed classes.
For the dogs on the left, the resulting prototypes mostly show the face of the dog, whereas criticisms are images without the dog faces or in different coloring (like black and white). 
On the right side, the prototypes contain images of dogs in various poses outdoors. 
The criticisms contain dogs in costumes and other unusual cases.

```{r, prototypes-and-criticisms, fig.cap = "Prototypes and criticisms for two types of dog breeds from the ImageNet dataset."}
knitr::include_graphics("images/proto-critique.png")
```

Another application of MMD-critic features a hand-written digit dataset.
Each image shows a hand-written digit and I would expect that the prototypes will show images of the most common ways of writing a digit and the criticisms some less common ways.

Looking at the actual prototypes and criticisms images you might notice that there are different numbers of images per digit. 
That's because  a fixed number of prototypes and criticisms were searched for over the complete dataset and not with a fixed number per class.
As expected, the prototypes show different ways of writing the digits.
The criticisms include examples with unusually thick or thin lines but also unrecognizable digits.

```{r, prototypes-and-criticisms2, fig.cap = "Prototypes and criticisms for a hand-written digits dataset."}
knitr::include_graphics("images/proto-critique2.png")
```


### Advantages

- In a user study, the authors of MMD-critic gave test subjects images they had to visually match to one of two sets of images, each representing one of two classes (e.g. two dog breed).
The **subjects performed best when the sets where showing prototypes and criticisms** instead of random images of that class.
- You can freely **choose the number of prototypes and criticisms**.
- MMD-critic works by with density estimates of the data. 
This **works with any type of data and any type of machine learning model**.
- The algorithm is **straightforward to implement**.
- MMD-critic is very flexible in how it is used to add interpretability: 
It can be used to understand complex data distributions; 
It can be an interpretable machine learning model by itself; 
Or it can shed light on the workings of a black box machine learning model.
- **Finding criticisms is agnostic to how the prototypes have been selected**.
But it makes more sense to also select prototypes according to MMD-critic, because then both prototypes and criticisms are created by the same method of comparing the prototypes and data densities.


### Disadvantages

- You have to **choose the number of prototypes and criticisms**.
As much as this can be a nice-to-have, this is also a disadvantage. 
How many prototypes and criticisms do we actually need?
The more the better? The less the better?
The number of prototypes and criticisms has to be set in advance and there are no instructions how to choose a good number.
Only in the case of using MMD-critic to build a classifier, we have a way to directly optimize it.
A solution could be a screeplot, which would show on the x-axis the number of prototypes and the MMD2 measure on the y-axis. 
We would choose the number of prototypes at which the MMD2 curve flattens.
- The other parameters are the choice of the kernel and the kernel scaling parameter.
We have the same problem as with the number of prototypes and criticisms:
**How do we select a kernel and its scaling parameter?**
Again, when we use MMD-critic as a nearest prototype classifier, we can tune the choice of kernel and the parameter.
But for the unsupervised use cases of MMD-critic it is unclear =.
(Maybe I am a bit harsh here, since all unsupervised problems have this issue.)
- It takes all the features as input, **disregarding the fact that some features might not be relevant** in the context of a supervised problem.
- There is some code available, but it is **not yet implemented as nicely packaged and documented software**.


### Code and Alternatives

- An implementation of MMD-critic can be found here: [https://github.com/BeenKim/MMD-critic](https://github.com/BeenKim/MMD-critic).
- The simplest alternative approach to finding prototypes is [k-medoids](https://en.wikipedia.org/wiki/K-medoids)
, a classification technique for finding data points that represent others. Has similarities to k-means. [^medoids]


[^medoids]: Kaufman, Leonard, and Peter Rousseeuw. Clustering by means of medoids. North-Holland, 1987.

[^bcm]: Kim, B., Rudin, C., & Shah, J. (n.d.). The Bayesian Case Model: A Generative Approach for Case-Based Reasoning and Prototype Classification.

[^critique]: Kim, Been, Rajiv Khanna, and Oluwasanmi O. Koyejo. "Examples are not enough, learn to criticize! criticism for interpretability." Advances in Neural Information Processing Systems. 2016.


[^cbr]: Aamodt, A., & Plaza, E. (1994). Case-based reasoning : Foundational issues, methodological variations, and system approaches. AI Communications, 7(1), 39–59.

[^koh]: Koh, P. W., & Liang, P. (2017). Understanding Black-box Predictions via Influence Functions. Retrieved from http://arxiv.org/abs/1703.04730
