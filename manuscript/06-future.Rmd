# A look into the crystal ball

What will the future of machine learning and interpretability bring?
This chapter is a highly speculative and highly subjective view on the future. 



## Interpretability will increase adoption of machine learning
In many areas and sectors, interpretability will be the key for adoptions of machine learning. 
Many people I spoke to are not using machine learning because they cannot explain the model to others. 
This is more annecdotal evidence.
But I believe that interpretability will solve this issue and make machine learning attractive for organisations and people that demand some transparency.


## The trend will be model-agnostic methods
I believe model-agnostic methods is the way to go. 
Intrinsically interpretable methods will have a subordinate role, mostly as surrogate model, but not modelling the data itself. 

What data scientists and statisticians currently do: Model the data. 
What they will do in the future: Model the black box. 

## Analysis of models, instead of data
Confidence intervals
p-values and tests for pdps, for local models, 
Error analysis for feature importance in the black box feature space. 

Complete separation of optimization for predicition and optimization for interpretation. 

We will get benchmarks and measures for how good interpretability is. 


## AutoML + IML
AutoML + IML will be the norm

Automated data scientist. 


## The automated data scientist
Automated scientist: Generation of hypothesis, testing, interpretation of results. 
Active learning 

Accelerating automation: Automation of the scientific process, automation of knowledge generation. 
Revolution of science (after the data revolution in which we are now).


## Directions for future research

- Definition of interpretability
- Interpretability benchmarks
- More work on local surrogate models
- Testing for models
- Variance of models
- Special interpretability tools for time series, text
- Methods for unsupervised machine learning. In theory all the existing methods should work though, because the structure is - after the model is trained - the same: predict of a column. 
- 



