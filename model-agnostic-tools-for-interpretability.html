<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Interpretable machine learning</title>
  <meta name="description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisons more interpretable.">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Interpretable machine learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisons more interpretable." />
  <meta name="github-repo" content="christophM/xai-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Interpretable machine learning" />
  
  <meta name="twitter:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisons more interpretable." />
  

<meta name="author" content="Christoph Molnar">


<meta name="date" content="2017-11-09">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="other-simple-interpretable-models.html">
<link rel="next" href="pdp.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-0.9/htmlwidgets.js"></script>
<script src="libs/datatables-binding-0.2/datatables.js"></script>
<link href="libs/dt-core-1.10.12/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.12/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.12/js/jquery.dataTables.min.js"></script>



</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Interpretable machine learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="who-should-read-this-book.html"><a href="who-should-read-this-book.html"><i class="fa fa-check"></i><b>1.1</b> Who should read this book</a></li>
<li class="chapter" data-level="1.2" data-path="outline.html"><a href="outline.html"><i class="fa fa-check"></i><b>1.2</b> Outline</a></li>
<li class="chapter" data-level="1.3" data-path="what-is-machine-learning-and-why-is-it-important.html"><a href="what-is-machine-learning-and-why-is-it-important.html"><i class="fa fa-check"></i><b>1.3</b> What is machine learning and why is it important?</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="interpretability.html"><a href="interpretability.html"><i class="fa fa-check"></i><b>2</b> Interpretability</a><ul>
<li class="chapter" data-level="2.1" data-path="when-is-interpretability-important.html"><a href="when-is-interpretability-important.html"><i class="fa fa-check"></i><b>2.1</b> When is interpretability important?</a></li>
<li class="chapter" data-level="2.2" data-path="the-bigger-picture.html"><a href="the-bigger-picture.html"><i class="fa fa-check"></i><b>2.2</b> The bigger picture</a></li>
<li class="chapter" data-level="2.3" data-path="scope-of-intepretability.html"><a href="scope-of-intepretability.html"><i class="fa fa-check"></i><b>2.3</b> Scope of intepretability</a><ul>
<li class="chapter" data-level="2.3.1" data-path="scope-of-intepretability.html"><a href="scope-of-intepretability.html#algorithm-transparency"><i class="fa fa-check"></i><b>2.3.1</b> Algorithm transparency</a></li>
<li class="chapter" data-level="2.3.2" data-path="scope-of-intepretability.html"><a href="scope-of-intepretability.html#global-holistic-model-explainability"><i class="fa fa-check"></i><b>2.3.2</b> Global, holistic model explainability</a></li>
<li class="chapter" data-level="2.3.3" data-path="scope-of-intepretability.html"><a href="scope-of-intepretability.html#global-model-explainability-on-a-modular-level"><i class="fa fa-check"></i><b>2.3.3</b> Global model explainability on a modular level</a></li>
<li class="chapter" data-level="2.3.4" data-path="scope-of-intepretability.html"><a href="scope-of-intepretability.html#explain-the-decision-for-a-single-instance"><i class="fa fa-check"></i><b>2.3.4</b> Explain the decision for a single instance</a></li>
<li class="chapter" data-level="2.3.5" data-path="scope-of-intepretability.html"><a href="scope-of-intepretability.html#explain-the-decisions-for-a-group-of-instances"><i class="fa fa-check"></i><b>2.3.5</b> Explain the decisions for a group of instances</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="evaluating-interpretability.html"><a href="evaluating-interpretability.html"><i class="fa fa-check"></i><b>2.4</b> Evaluating interpretability</a><ul>
<li class="chapter" data-level="2.4.1" data-path="evaluating-interpretability.html"><a href="evaluating-interpretability.html#approaches-for-evaluation-of-the-explanation-quality"><i class="fa fa-check"></i><b>2.4.1</b> Approaches for evaluation of the explanation quality</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="datasets.html"><a href="datasets.html"><i class="fa fa-check"></i><b>3</b> Datasets</a><ul>
<li class="chapter" data-level="3.1" data-path="bike-data.html"><a href="bike-data.html"><i class="fa fa-check"></i><b>3.1</b> Bike sharing counts (regression)</a></li>
<li class="chapter" data-level="3.2" data-path="spam-data.html"><a href="spam-data.html"><i class="fa fa-check"></i><b>3.2</b> Youtube spam comments (text classification)</a></li>
<li class="chapter" data-level="3.3" data-path="cervical-data.html"><a href="cervical-data.html"><i class="fa fa-check"></i><b>3.3</b> Risk factors for cervical cancer (classification)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="definitions.html"><a href="definitions.html"><i class="fa fa-check"></i><b>4</b> Definitions</a></li>
<li class="chapter" data-level="5" data-path="simple.html"><a href="simple.html"><i class="fa fa-check"></i><b>5</b> Interpretable models</a><ul>
<li class="chapter" data-level="5.1" data-path="terminology.html"><a href="terminology.html"><i class="fa fa-check"></i><b>5.1</b> Terminology</a></li>
<li class="chapter" data-level="5.2" data-path="overview.html"><a href="overview.html"><i class="fa fa-check"></i><b>5.2</b> Overview</a></li>
<li class="chapter" data-level="5.3" data-path="limo.html"><a href="limo.html"><i class="fa fa-check"></i><b>5.3</b> Linear models</a><ul>
<li class="chapter" data-level="5.3.1" data-path="limo.html"><a href="limo.html#interpretation"><i class="fa fa-check"></i><b>5.3.1</b> Interpretation</a></li>
<li class="chapter" data-level="5.3.2" data-path="limo.html"><a href="limo.html#interpretation-example"><i class="fa fa-check"></i><b>5.3.2</b> Interpretation example</a></li>
<li class="chapter" data-level="5.3.3" data-path="limo.html"><a href="limo.html#interpretation-templates"><i class="fa fa-check"></i><b>5.3.3</b> Interpretation templates</a></li>
<li class="chapter" data-level="5.3.4" data-path="limo.html"><a href="limo.html#visual-parameter-interpretation"><i class="fa fa-check"></i><b>5.3.4</b> Visual parameter interpretation</a></li>
<li class="chapter" data-level="5.3.5" data-path="limo.html"><a href="limo.html#explaining-single-predictions"><i class="fa fa-check"></i><b>5.3.5</b> Explaining single predictions</a></li>
<li class="chapter" data-level="5.3.6" data-path="limo.html"><a href="limo.html#coding-categorical-variables"><i class="fa fa-check"></i><b>5.3.6</b> Coding categorical variables:</a></li>
<li class="chapter" data-level="5.3.7" data-path="limo.html"><a href="limo.html#the-disadvantages-of-linear-models"><i class="fa fa-check"></i><b>5.3.7</b> The disadvantages of linear models</a></li>
<li class="chapter" data-level="5.3.8" data-path="limo.html"><a href="limo.html#towards-complexer-relationships-within-linear-model-class"><i class="fa fa-check"></i><b>5.3.8</b> Towards complexer relationships within linear model class</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="sparse-linear-models.html"><a href="sparse-linear-models.html"><i class="fa fa-check"></i><b>5.4</b> Sparse linear models</a></li>
<li class="chapter" data-level="5.5" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html"><i class="fa fa-check"></i><b>5.5</b> Logistic regression: a linear model for classification</a><ul>
<li class="chapter" data-level="5.5.1" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html#whats-wrong-with-linear-regression-for-classification"><i class="fa fa-check"></i><b>5.5.1</b> What’s wrong with linear regression for classification?</a></li>
<li class="chapter" data-level="5.5.2" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html#logistic-regression"><i class="fa fa-check"></i><b>5.5.2</b> Logistic regression</a></li>
<li class="chapter" data-level="5.5.3" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html#interpretation-1"><i class="fa fa-check"></i><b>5.5.3</b> Interpretation</a></li>
<li class="chapter" data-level="5.5.4" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html#example"><i class="fa fa-check"></i><b>5.5.4</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>5.6</b> Decision trees</a><ul>
<li class="chapter" data-level="5.6.1" data-path="decision-trees.html"><a href="decision-trees.html#interpretation-2"><i class="fa fa-check"></i><b>5.6.1</b> Interpretation</a></li>
<li class="chapter" data-level="5.6.2" data-path="decision-trees.html"><a href="decision-trees.html#interpretation-example-1"><i class="fa fa-check"></i><b>5.6.2</b> Interpretation example</a></li>
<li class="chapter" data-level="5.6.3" data-path="decision-trees.html"><a href="decision-trees.html#advantages"><i class="fa fa-check"></i><b>5.6.3</b> Advantages</a></li>
<li class="chapter" data-level="5.6.4" data-path="decision-trees.html"><a href="decision-trees.html#disadvantages"><i class="fa fa-check"></i><b>5.6.4</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html"><i class="fa fa-check"></i><b>5.7</b> Other simple, interpretable models</a><ul>
<li class="chapter" data-level="5.7.1" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html#naive-bayes-classifier"><i class="fa fa-check"></i><b>5.7.1</b> Naive bayes classifier</a></li>
<li class="chapter" data-level="5.7.2" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html#k-nearest-neighbours"><i class="fa fa-check"></i><b>5.7.2</b> k-nearest neighbours</a></li>
<li class="chapter" data-level="5.7.3" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html#rulefit"><i class="fa fa-check"></i><b>5.7.3</b> RuleFit</a></li>
<li class="chapter" data-level="5.7.4" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html#and-so-many-more"><i class="fa fa-check"></i><b>5.7.4</b> And so many more …</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="model-agnostic-tools-for-interpretability.html"><a href="model-agnostic-tools-for-interpretability.html"><i class="fa fa-check"></i><b>6</b> Model-agnostic tools for interpretability</a><ul>
<li class="chapter" data-level="6.1" data-path="pdp.html"><a href="pdp.html"><i class="fa fa-check"></i><b>6.1</b> Partial dependence plot</a></li>
<li class="chapter" data-level="6.2" data-path="individual-conditional-expectation-ice-plot.html"><a href="individual-conditional-expectation-ice-plot.html"><i class="fa fa-check"></i><b>6.2</b> Individual Conditional Expectation (ICE) plot</a></li>
<li class="chapter" data-level="6.3" data-path="permutation-feature-importance.html"><a href="permutation-feature-importance.html"><i class="fa fa-check"></i><b>6.3</b> Permutation feature importance</a><ul>
<li class="chapter" data-level="6.3.1" data-path="permutation-feature-importance.html"><a href="permutation-feature-importance.html#model-dependent-feature-importance"><i class="fa fa-check"></i><b>6.3.1</b> Model dependent feature importance</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="local-surrogate-models-lime.html"><a href="local-surrogate-models-lime.html"><i class="fa fa-check"></i><b>6.4</b> Local surrogate models (LIME)</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interpretable machine learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="model-agnostic-tools-for-interpretability" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Model-agnostic tools for interpretability</h1>
<p>Separating the explanations from the machine learning model (= model-agnostic explanations) gives some benefits. The big advantage of model-agnostic vs model-specific explanation algorithm is the flexibility. When the explanation system is independently applicable even when the underlying model is switched, it frees the practitioner to use different machine learning models without restrictions. It is also more efficient to build interfaces on top of model-agnostic systems, because this has to be done only once and not for each model-specific explanation system. Usually not one but many types of machine learning models are tested in development time and if you want to compare the models in terms of interpretability this is easier with model-agnostic explanations because the system is the same for both models that are being compared <span class="citation">(Ribeiro, Singh, and Guestrin <a href="#ref-Ribeiro2016b">2016</a>)</span>.</p>
<p>The alternatives are either using only interpretable models as introduced in Chapter 2, which has the big disadvantage to usually loose accuracy compared to other approaches. The other alternative is to use more flexible model classes that come with built in explanations. The drawback here is that it ties you to this one algorithm and it will be hard to switch to something else.</p>
<p>Desirable aspects of a model-agnostic explanation system <span class="citation">(Ribeiro, Singh, and Guestrin <a href="#ref-Ribeiro2016b">2016</a>)</span>: - Model flexibility: Not being tied to an underlying particular machine learning model. The method should work for random forests as well as convolutional neural networks - Explanation flexibility: Not being tied to a certain form of explanation. In some cases it might be useful to have a linear formula in other cases some decision rules - Representation flexibility: The explanation system should not have to use the same feature representation as the model that is being explained. So when a text classifier uses abstract word embedding vectors, it might be preferable to use the presence of single words for the explanation.</p>
<!--chapter:end:05.1-agnostic.Rmd--> 
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Ribeiro2016b">
<p>Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. 2016. “Model-Agnostic Interpretability of Machine Learning.” <em>ICML Workshop on Human Interpretability in Machine Learning</em>, no. Whi.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="other-simple-interpretable-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="pdp.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/christophM/xai-book/edit/master/05.2-agnostic-pdp.Rmd",
"text": "Edit"
},
"download": ["xai-book.pdf"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

<!-- </html> -->
