<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Interpretable Machine Learning</title>
  <meta name="description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisions more interpretable.">
  <meta name="generator" content="bookdown 0.6 and GitBook 2.6.7">

  <meta property="og:title" content="Interpretable Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisions more interpretable." />
  <meta name="github-repo" content="christophM/interpretable-ml-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Interpretable Machine Learning" />
  
  <meta name="twitter:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisions more interpretable." />
  

<meta name="author" content="Christoph Molnar">


<meta name="date" content="2018-02-15">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="agnostic.html">
<link rel="next" href="ice.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.0/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.4/datatables.js"></script>
<link href="libs/dt-core-1.10.16/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.16/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.16/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/dt-core-bootstrap-1.10.16/css/dataTables.bootstrap.min.css" rel="stylesheet" />
<link href="libs/dt-core-bootstrap-1.10.16/css/dataTables.bootstrap.extra.css" rel="stylesheet" />
<script src="libs/dt-core-bootstrap-1.10.16/js/jquery.dataTables.min.js"></script>
<script src="libs/dt-core-bootstrap-1.10.16/js/dataTables.bootstrap.min.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110543840-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110543840-1');
</script>

<!-- For the Bitcoin donation button-->
<script type="text/javascript" src="https://blockchain.info/Resources/js/pay-now-button.js"></script>



</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Interpretable machine learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="what-to-expect-from-this-book.html"><a href="what-to-expect-from-this-book.html"><i class="fa fa-check"></i><b>1.1</b> What to Expect from This Book</a></li>
<li class="chapter" data-level="1.2" data-path="storytime.html"><a href="storytime.html"><i class="fa fa-check"></i><b>1.2</b> Storytime</a><ul>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#lightning-never-strikes-twice"><i class="fa fa-check"></i>Lightning never strikes twice</a></li>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#trust-fall"><i class="fa fa-check"></i>Trust fall</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html"><i class="fa fa-check"></i><b>1.3</b> What Is Machine Learning?</a></li>
<li class="chapter" data-level="1.4" data-path="definitions.html"><a href="definitions.html"><i class="fa fa-check"></i><b>1.4</b> Definitions</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="interpretability.html"><a href="interpretability.html"><i class="fa fa-check"></i><b>2</b> Interpretability</a><ul>
<li class="chapter" data-level="2.1" data-path="interpretability-importance.html"><a href="interpretability-importance.html"><i class="fa fa-check"></i><b>2.1</b> The Importance of Interpretability</a></li>
<li class="chapter" data-level="2.2" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html"><i class="fa fa-check"></i><b>2.2</b> Scope of Interpretability</a><ul>
<li class="chapter" data-level="2.2.1" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#algorithm-transparency"><i class="fa fa-check"></i><b>2.2.1</b> Algorithm transparency</a></li>
<li class="chapter" data-level="2.2.2" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-holistic-model-interpretability"><i class="fa fa-check"></i><b>2.2.2</b> Global, Holistic Model Interpretability</a></li>
<li class="chapter" data-level="2.2.3" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-model-interpretability-on-a-modular-level"><i class="fa fa-check"></i><b>2.2.3</b> Global Model Interpretability on a Modular Level</a></li>
<li class="chapter" data-level="2.2.4" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#local-interpretability-for-a-single-prediction"><i class="fa fa-check"></i><b>2.2.4</b> Local Interpretability for a Single Prediction</a></li>
<li class="chapter" data-level="2.2.5" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#local-interpretability-for-a-group-of-prediction"><i class="fa fa-check"></i><b>2.2.5</b> Local Interpretability for a Group of Prediction</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="evaluating-interpretability.html"><a href="evaluating-interpretability.html"><i class="fa fa-check"></i><b>2.3</b> Evaluating Interpretability</a><ul>
<li class="chapter" data-level="2.3.1" data-path="evaluating-interpretability.html"><a href="evaluating-interpretability.html#approaches-for-evaluating-the-interpretability-quality"><i class="fa fa-check"></i><b>2.3.1</b> Approaches for Evaluating the Interpretability Quality</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="explanation.html"><a href="explanation.html"><i class="fa fa-check"></i><b>2.4</b> Human-style Explanations</a><ul>
<li class="chapter" data-level="2.4.1" data-path="explanation.html"><a href="explanation.html#what-is-an-explanation"><i class="fa fa-check"></i><b>2.4.1</b> What is an explanation?</a></li>
<li class="chapter" data-level="2.4.2" data-path="explanation.html"><a href="explanation.html#good-explanation"><i class="fa fa-check"></i><b>2.4.2</b> What is a “good” explanation?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>3</b> Datasets</a><ul>
<li class="chapter" data-level="3.1" data-path="bike-data.html"><a href="bike-data.html"><i class="fa fa-check"></i><b>3.1</b> Bike Sharing Counts (Regression)</a></li>
<li class="chapter" data-level="3.2" data-path="spam-data.html"><a href="spam-data.html"><i class="fa fa-check"></i><b>3.2</b> YouTube Spam Comments (Text Classification)</a></li>
<li class="chapter" data-level="3.3" data-path="cervical-data.html"><a href="cervical-data.html"><i class="fa fa-check"></i><b>3.3</b> Risk Factors for Cervical Cancer (Classification)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple.html"><a href="simple.html"><i class="fa fa-check"></i><b>4</b> Interpretable Models</a><ul>
<li class="chapter" data-level="4.1" data-path="limo.html"><a href="limo.html"><i class="fa fa-check"></i><b>4.1</b> Linear Model</a><ul>
<li class="chapter" data-level="4.1.1" data-path="limo.html"><a href="limo.html#interpretation"><i class="fa fa-check"></i><b>4.1.1</b> Interpretation</a></li>
<li class="chapter" data-level="4.1.2" data-path="limo.html"><a href="limo.html#interpretation-example"><i class="fa fa-check"></i><b>4.1.2</b> Interpretation Example</a></li>
<li class="chapter" data-level="4.1.3" data-path="limo.html"><a href="limo.html#interpretation-templates"><i class="fa fa-check"></i><b>4.1.3</b> Interpretation templates</a></li>
<li class="chapter" data-level="4.1.4" data-path="limo.html"><a href="limo.html#visual-parameter-interpretation"><i class="fa fa-check"></i><b>4.1.4</b> Visual parameter interpretation</a></li>
<li class="chapter" data-level="4.1.5" data-path="limo.html"><a href="limo.html#explaining-single-predictions"><i class="fa fa-check"></i><b>4.1.5</b> Explaining Single Predictions</a></li>
<li class="chapter" data-level="4.1.6" data-path="limo.html"><a href="limo.html#cat.code"><i class="fa fa-check"></i><b>4.1.6</b> Coding Categorical Features</a></li>
<li class="chapter" data-level="4.1.7" data-path="limo.html"><a href="limo.html#the-disadvantages-of-linear-models"><i class="fa fa-check"></i><b>4.1.7</b> The disadvantages of linear models</a></li>
<li class="chapter" data-level="4.1.8" data-path="limo.html"><a href="limo.html#do-linear-models-create-good-explanations"><i class="fa fa-check"></i><b>4.1.8</b> Do linear models create good explanations?</a></li>
<li class="chapter" data-level="4.1.9" data-path="limo.html"><a href="limo.html#extending-linear-models"><i class="fa fa-check"></i><b>4.1.9</b> Extending Linear Models</a></li>
<li class="chapter" data-level="4.1.10" data-path="limo.html"><a href="limo.html#sparse-linear"><i class="fa fa-check"></i><b>4.1.10</b> Sparse linear models</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="logistic.html"><a href="logistic.html"><i class="fa fa-check"></i><b>4.2</b> Logistic Regression</a><ul>
<li class="chapter" data-level="4.2.1" data-path="logistic.html"><a href="logistic.html#whats-wrong-with-linear-regression-models-for-classification"><i class="fa fa-check"></i><b>4.2.1</b> What’s Wrong with Linear Regression Models for Classification?</a></li>
<li class="chapter" data-level="4.2.2" data-path="logistic.html"><a href="logistic.html#logistic-regression"><i class="fa fa-check"></i><b>4.2.2</b> Logistic Regression</a></li>
<li class="chapter" data-level="4.2.3" data-path="logistic.html"><a href="logistic.html#interpretation-1"><i class="fa fa-check"></i><b>4.2.3</b> Interpretation</a></li>
<li class="chapter" data-level="4.2.4" data-path="logistic.html"><a href="logistic.html#example"><i class="fa fa-check"></i><b>4.2.4</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="tree.html"><a href="tree.html"><i class="fa fa-check"></i><b>4.3</b> Decision Tree</a><ul>
<li class="chapter" data-level="4.3.1" data-path="tree.html"><a href="tree.html#interpretation-2"><i class="fa fa-check"></i><b>4.3.1</b> Interpretation</a></li>
<li class="chapter" data-level="4.3.2" data-path="tree.html"><a href="tree.html#interpretation-example-1"><i class="fa fa-check"></i><b>4.3.2</b> Interpretation Example</a></li>
<li class="chapter" data-level="4.3.3" data-path="tree.html"><a href="tree.html#advantages"><i class="fa fa-check"></i><b>4.3.3</b> Advantages</a></li>
<li class="chapter" data-level="4.3.4" data-path="tree.html"><a href="tree.html#disadvantages"><i class="fa fa-check"></i><b>4.3.4</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="rulefit.html"><a href="rulefit.html"><i class="fa fa-check"></i><b>4.4</b> RuleFit</a><ul>
<li class="chapter" data-level="4.4.1" data-path="rulefit.html"><a href="rulefit.html#interpretation-and-example"><i class="fa fa-check"></i><b>4.4.1</b> Interpretation and Example</a></li>
<li class="chapter" data-level="4.4.2" data-path="rulefit.html"><a href="rulefit.html#guidelines"><i class="fa fa-check"></i><b>4.4.2</b> Guidelines</a></li>
<li class="chapter" data-level="4.4.3" data-path="rulefit.html"><a href="rulefit.html#theory"><i class="fa fa-check"></i><b>4.4.3</b> Theory</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="other-interpretable-models.html"><a href="other-interpretable-models.html"><i class="fa fa-check"></i><b>4.5</b> Other Interpretable Models</a><ul>
<li class="chapter" data-level="4.5.1" data-path="other-interpretable-models.html"><a href="other-interpretable-models.html#naive-bayes-classifier"><i class="fa fa-check"></i><b>4.5.1</b> Naive Bayes classifier</a></li>
<li class="chapter" data-level="4.5.2" data-path="other-interpretable-models.html"><a href="other-interpretable-models.html#k-nearest-neighbours"><i class="fa fa-check"></i><b>4.5.2</b> K-Nearest Neighbours</a></li>
<li class="chapter" data-level="4.5.3" data-path="other-interpretable-models.html"><a href="other-interpretable-models.html#and-so-many-more"><i class="fa fa-check"></i><b>4.5.3</b> And so many more …</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="agnostic.html"><a href="agnostic.html"><i class="fa fa-check"></i><b>5</b> Model-Agnostic Methods</a><ul>
<li class="chapter" data-level="5.1" data-path="pdp.html"><a href="pdp.html"><i class="fa fa-check"></i><b>5.1</b> Partial Dependence Plot (PDP)</a><ul>
<li class="chapter" data-level="5.1.1" data-path="pdp.html"><a href="pdp.html#examples"><i class="fa fa-check"></i><b>5.1.1</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="ice.html"><a href="ice.html"><i class="fa fa-check"></i><b>5.2</b> Individual Conditional Expectation (ICE) Plot</a><ul>
<li class="chapter" data-level="5.2.1" data-path="ice.html"><a href="ice.html#example-1"><i class="fa fa-check"></i><b>5.2.1</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="permutation-feature-importance.html"><a href="permutation-feature-importance.html"><i class="fa fa-check"></i><b>5.3</b> Permutation Feature Importance</a></li>
<li class="chapter" data-level="5.4" data-path="lime.html"><a href="lime.html"><i class="fa fa-check"></i><b>5.4</b> Local Surrogate Models (LIME)</a><ul>
<li class="chapter" data-level="5.4.1" data-path="lime.html"><a href="lime.html#lime-for-tabular-data"><i class="fa fa-check"></i><b>5.4.1</b> LIME for Tabular Data</a></li>
<li class="chapter" data-level="5.4.2" data-path="lime.html"><a href="lime.html#lime-for-text"><i class="fa fa-check"></i><b>5.4.2</b> LIME for Text</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>5.5</b> Shapley Value Explanations</a><ul>
<li class="chapter" data-level="5.5.1" data-path="shapley.html"><a href="shapley.html#the-general-idea"><i class="fa fa-check"></i><b>5.5.1</b> The general idea</a></li>
<li class="chapter" data-level="5.5.2" data-path="shapley.html"><a href="shapley.html#interpretation-and-example-1"><i class="fa fa-check"></i><b>5.5.2</b> Interpretation and example</a></li>
<li class="chapter" data-level="5.5.3" data-path="shapley.html"><a href="shapley.html#the-shapley-value-in-detail"><i class="fa fa-check"></i><b>5.5.3</b> The Shapley Value in Detail</a></li>
<li class="chapter" data-level="5.5.4" data-path="shapley.html"><a href="shapley.html#advantages-1"><i class="fa fa-check"></i><b>5.5.4</b> Advantages</a></li>
<li class="chapter" data-level="5.5.5" data-path="shapley.html"><a href="shapley.html#disadvantages-1"><i class="fa fa-check"></i><b>5.5.5</b> Disadvantages</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="contribute.html"><a href="contribute.html"><i class="fa fa-check"></i><b>6</b> Contribute</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interpretable Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="pdp" class="section level2">
<h2><span class="header-section-number">5.1</span> Partial Dependence Plot (PDP)</h2>
<p>The partial dependence plot shows the marginal effect of a feature on the predicted outcome <span class="citation">(J. H. Friedman <a href="#ref-friedman2001greedy">2001</a>)</span>. Have a glance at Figure <a href="pdp.html#fig:pdp-cervical">5.3</a> to get some intuition before diving into the theory of partial dependencies. A partial dependence plot can show if the relationship between the target and a feature is linear, monotonic or something else. Applied to a linear regression model, partial dependence plots will always show a linear relationship, for example.</p>
<p>The partial dependence function for regression is defined as: <span class="math display">\[\hat{f}_{x_S}(x_S) = E_{x_C}\left[\hat{f}(x_S, x_C)\right] = \int \hat{f}(x_S, x_C) dP(x_C)\]</span> The term <span class="math inline">\(x_S\)</span> is the set of features for which the partial dependence function should be plotted and <span class="math inline">\(x_C\)</span> are the other features that were used in the machine learning model <span class="math inline">\(\hat{f}\)</span>. Usually, there are only one or two features in <span class="math inline">\(x_S\)</span>. Together, <span class="math inline">\(x_S\)</span> and <span class="math inline">\(x_C\)</span> make up <span class="math inline">\(x\)</span>. Partial dependence works by averaging the machine learning model output <span class="math inline">\(\hat{f}\)</span> over the distribution of the features <span class="math inline">\(x_C\)</span>, so that the remaining function shows the relationship between the <span class="math inline">\(x_S\)</span>, in which we are interested, and the predicted outcome.</p>
<p>The partial function <span class="math inline">\(\hat{f}_{x_S}\)</span> along <span class="math inline">\(x_S\)</span> is estimated by calculating averages in the training data, which is also known as Monte Carlo method: <span class="math display">\[ \hat{f}_{x_S}(x_S) = \frac{1}{n} \sum_{i=1}^n \hat{f}(x_S, x_{Ci}) \]</span> In this formula <span class="math inline">\(x_{iC}\)</span> are concrete values taken from the data for the features we are not interested and <span class="math inline">\(n\)</span> the number of instances in the dataset. Note that <span class="math inline">\(\hat{f}_{x_S}\)</span> only depends on features <span class="math inline">\(x_S\)</span> as input. For classification, where the machine model outputs probabilities, the partial dependence function displays the probability for a certain class given different values for features <span class="math inline">\(x_S\)</span>. A straightforward way to handle multi-class problems is to plot one line per class.</p>
<p>The partial dependence plot is a global method: The method takes into account all instances and makes a statement about the global relationship of a feature with the predicted outcome.</p>
<div id="examples" class="section level3">
<h3><span class="header-section-number">5.1.1</span> Examples</h3>
<p>In practice, the set of features <span class="math inline">\(x_S\)</span> usually only contains one feature or a maximum of two, because one feature produces 2D plots and two features produce 3D plots. Everything beyond that is quite tricky. Even 3D on a 2D paper or monitor is already challenging.</p>
<p>Let’s turn to the regression example with the bike counts from Chapter <a href="bike-data.html#bike-data">3.1</a> and have a look at how the weather affects the predicted bike rentals. We first fit a machine learning model on the dataset, for which we want to analyse the partial dependencies. In this case, we fitted a RandomForest to predict the bike rentals and make use of the partial dependence method to understand what relationships the model learned. Figure <a href="pdp.html#fig:pdp-bike">5.2</a> shows the influence of the weather features on the predicted bike counts. For warm (but not too hot) weather, the model predicts a high number of bike rentals on average. The potential bikers are increasingly inhibited in engaging in cycling when humidity reaches above 60%. Also, the more wind the less people like to bike, which makes sense. Interestingly, the predicted bike counts don’t drop between 25 and 35 km/h windspeed, but maybe there is just not enough training data. At least intuitively I would expect the bike rentals to drop with any increase in windspeed, especially when the windspeed is very high.</p>
<p>Figure <a href="pdp.html#fig:pdp-cervical">5.3</a> shows a partial dependence plot example for cervical cancer classification (see Chapter <a href="cervical-data.html#cervical-data">3.3</a> for the data). Again, we fit a RandomForest to predict whether a woman has cervical cancer given some risk factors. Any other type of model would have worked as well. The interpretation is analogue to the partial dependence plots for regression.</p>
<p>Figure <a href="pdp.html#fig:pdp-cervical-2d">5.4</a> shows an example of a partial dependence plot with two features.</p>
<div class="figure" style="text-align: center"><span id="fig:pdp-bike"></span>
<img src="interpretable-ml_files/figure-html/pdp-bike-1.svg" alt="Partial dependence plot of rental bike count and different weather measurements (Temperature, Humidity, Windspeed). The biggest differences can be seen in different temperatures: With rising temperatures, on average the bike rentals rise, until 20C degrees, where it stays the same also for hotter temperatures and drops a bit again towards 30C degrees." width="80%" />
<p class="caption">
FIGURE 5.2: Partial dependence plot of rental bike count and different weather measurements (Temperature, Humidity, Windspeed). The biggest differences can be seen in different temperatures: With rising temperatures, on average the bike rentals rise, until 20C degrees, where it stays the same also for hotter temperatures and drops a bit again towards 30C degrees.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:pdp-cervical"></span>
<img src="interpretable-ml_files/figure-html/pdp-cervical-1.svg" alt="Partial dependence plot of cancer probability and the risk factors age and number of years with hormonal contraceptives. For the age feature, the models partial dependence shows that on average, the cancer probability is low before 45, spikes between age 45 and 55 and plateaus after that. The number of years on hormonal contraceptives is associated with a higher cancer risk especially after 15 years." width="80%" />
<p class="caption">
FIGURE 5.3: Partial dependence plot of cancer probability and the risk factors age and number of years with hormonal contraceptives. For the age feature, the models partial dependence shows that on average, the cancer probability is low before 45, spikes between age 45 and 55 and plateaus after that. The number of years on hormonal contraceptives is associated with a higher cancer risk especially after 15 years.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:pdp-cervical-2d"></span>
<img src="interpretable-ml_files/figure-html/pdp-cervical-2d-1.svg" alt="Partial dependence plot of cancer probability and the interaction of number of years on hormonal contraceptives and number of sexual partners. Interestingly, there is some odd interaction between the two features when the number of sexual partners is 1 and the years of on hormonal contraceptives larger than 12. There are actually only two women in that group, who both happen to have cancer. So my best guess is that this was random and the model did overfit on those two women, but only more data could answer this question." width="80%" />
<p class="caption">
FIGURE 5.4: Partial dependence plot of cancer probability and the interaction of number of years on hormonal contraceptives and number of sexual partners. Interestingly, there is some odd interaction between the two features when the number of sexual partners is 1 and the years of on hormonal contraceptives larger than 12. There are actually only two women in that group, who both happen to have cancer. So my best guess is that this was random and the model did overfit on those two women, but only more data could answer this question.
</p>
</div>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-friedman2001greedy">
<p>Friedman, Jerome H. 2001. “Greedy Function Approximation: A Gradient Boosting Machine.” <em>Annals of Statistics</em>. JSTOR, 1189–1232.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="agnostic.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ice.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/christophM/interpretable-ml-book/edit/master/chapters/05.2-agnostic-pdp.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
