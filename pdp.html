<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Interpretable machine learning</title>
  <meta name="description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisons more interpretable.">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Interpretable machine learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisons more interpretable." />
  <meta name="github-repo" content="christophM/xai-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Interpretable machine learning" />
  
  <meta name="twitter:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisons more interpretable." />
  

<meta name="author" content="Christoph Molnar">


<meta name="date" content="2017-11-19">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="agnostic.html">
<link rel="next" href="individual-conditional-expectation-ice-plot.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-0.9/htmlwidgets.js"></script>
<script src="libs/datatables-binding-0.2/datatables.js"></script>
<link href="libs/dt-core-1.10.12/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.12/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.12/js/jquery.dataTables.min.js"></script>



</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Interpretable machine learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="what-to-expect-from-this-book.html"><a href="what-to-expect-from-this-book.html"><i class="fa fa-check"></i><b>1.1</b> What to expect from this book</a></li>
<li class="chapter" data-level="1.2" data-path="what-is-machine-learning-and-why-is-it-important.html"><a href="what-is-machine-learning-and-why-is-it-important.html"><i class="fa fa-check"></i><b>1.2</b> What is machine learning and why is it important?</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="interpretability.html"><a href="interpretability.html"><i class="fa fa-check"></i><b>2</b> Interpretability</a><ul>
<li class="chapter" data-level="2.1" data-path="interpretability-importance.html"><a href="interpretability-importance.html"><i class="fa fa-check"></i><b>2.1</b> The importance of machine learning interpretability</a></li>
<li class="chapter" data-level="2.2" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html"><i class="fa fa-check"></i><b>2.2</b> Scope of interpretability</a><ul>
<li class="chapter" data-level="2.2.1" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#algorithm-transparency"><i class="fa fa-check"></i><b>2.2.1</b> Algorithm transparency</a></li>
<li class="chapter" data-level="2.2.2" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-holistic-model-interpretability"><i class="fa fa-check"></i><b>2.2.2</b> Global, holistic model interpretability</a></li>
<li class="chapter" data-level="2.2.3" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-model-interpretability-on-a-modular-level"><i class="fa fa-check"></i><b>2.2.3</b> Global model interpretability on a modular level</a></li>
<li class="chapter" data-level="2.2.4" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#explain-the-prediction-for-a-single-instance"><i class="fa fa-check"></i><b>2.2.4</b> Explain the prediction for a single instance</a></li>
<li class="chapter" data-level="2.2.5" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#explain-the-predictions-for-a-group-of-instances"><i class="fa fa-check"></i><b>2.2.5</b> Explain the predictions for a group of instances</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="evaluating-interpretability.html"><a href="evaluating-interpretability.html"><i class="fa fa-check"></i><b>2.3</b> Evaluating interpretability</a><ul>
<li class="chapter" data-level="2.3.1" data-path="evaluating-interpretability.html"><a href="evaluating-interpretability.html#approaches-for-evaluating-the-explanation-quality"><i class="fa fa-check"></i><b>2.3.1</b> Approaches for evaluating the explanation quality</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>3</b> Datasets</a><ul>
<li class="chapter" data-level="3.1" data-path="bike-data.html"><a href="bike-data.html"><i class="fa fa-check"></i><b>3.1</b> Bike sharing counts (regression)</a></li>
<li class="chapter" data-level="3.2" data-path="spam-data.html"><a href="spam-data.html"><i class="fa fa-check"></i><b>3.2</b> Youtube spam comments (text classification)</a></li>
<li class="chapter" data-level="3.3" data-path="cervical-data.html"><a href="cervical-data.html"><i class="fa fa-check"></i><b>3.3</b> Risk factors for cervical cancer (classification)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="definitions.html"><a href="definitions.html"><i class="fa fa-check"></i><b>4</b> Definitions</a></li>
<li class="chapter" data-level="5" data-path="simple.html"><a href="simple.html"><i class="fa fa-check"></i><b>5</b> Interpretable models</a><ul>
<li class="chapter" data-level="5.1" data-path="terminology.html"><a href="terminology.html"><i class="fa fa-check"></i><b>5.1</b> Terminology</a></li>
<li class="chapter" data-level="5.2" data-path="limo.html"><a href="limo.html"><i class="fa fa-check"></i><b>5.2</b> Linear models</a><ul>
<li class="chapter" data-level="5.2.1" data-path="limo.html"><a href="limo.html#interpretation"><i class="fa fa-check"></i><b>5.2.1</b> Interpretation</a></li>
<li class="chapter" data-level="5.2.2" data-path="limo.html"><a href="limo.html#interpretation-example"><i class="fa fa-check"></i><b>5.2.2</b> Interpretation example</a></li>
<li class="chapter" data-level="5.2.3" data-path="limo.html"><a href="limo.html#interpretation-templates"><i class="fa fa-check"></i><b>5.2.3</b> Interpretation templates</a></li>
<li class="chapter" data-level="5.2.4" data-path="limo.html"><a href="limo.html#visual-parameter-interpretation"><i class="fa fa-check"></i><b>5.2.4</b> Visual parameter interpretation</a></li>
<li class="chapter" data-level="5.2.5" data-path="limo.html"><a href="limo.html#explaining-single-predictions"><i class="fa fa-check"></i><b>5.2.5</b> Explaining single predictions</a></li>
<li class="chapter" data-level="5.2.6" data-path="limo.html"><a href="limo.html#coding-categorical-variables"><i class="fa fa-check"></i><b>5.2.6</b> Coding categorical variables:</a></li>
<li class="chapter" data-level="5.2.7" data-path="limo.html"><a href="limo.html#the-disadvantages-of-linear-models"><i class="fa fa-check"></i><b>5.2.7</b> The disadvantages of linear models</a></li>
<li class="chapter" data-level="5.2.8" data-path="limo.html"><a href="limo.html#towards-complexer-relationships-within-linear-model-class"><i class="fa fa-check"></i><b>5.2.8</b> Towards complexer relationships within linear model class</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="sparse-linear-models.html"><a href="sparse-linear-models.html"><i class="fa fa-check"></i><b>5.3</b> Sparse linear models</a></li>
<li class="chapter" data-level="5.4" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html"><i class="fa fa-check"></i><b>5.4</b> Logistic regression: a linear model for classification</a><ul>
<li class="chapter" data-level="5.4.1" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html#whats-wrong-with-linear-regression-for-classification"><i class="fa fa-check"></i><b>5.4.1</b> What’s wrong with linear regression for classification?</a></li>
<li class="chapter" data-level="5.4.2" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html#logistic-regression"><i class="fa fa-check"></i><b>5.4.2</b> Logistic regression</a></li>
<li class="chapter" data-level="5.4.3" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html#interpretation-1"><i class="fa fa-check"></i><b>5.4.3</b> Interpretation</a></li>
<li class="chapter" data-level="5.4.4" data-path="logistic-regression-a-linear-model-for-classification.html"><a href="logistic-regression-a-linear-model-for-classification.html#example"><i class="fa fa-check"></i><b>5.4.4</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>5.5</b> Decision trees</a><ul>
<li class="chapter" data-level="5.5.1" data-path="decision-trees.html"><a href="decision-trees.html#interpretation-2"><i class="fa fa-check"></i><b>5.5.1</b> Interpretation</a></li>
<li class="chapter" data-level="5.5.2" data-path="decision-trees.html"><a href="decision-trees.html#interpretation-example-1"><i class="fa fa-check"></i><b>5.5.2</b> Interpretation example</a></li>
<li class="chapter" data-level="5.5.3" data-path="decision-trees.html"><a href="decision-trees.html#advantages"><i class="fa fa-check"></i><b>5.5.3</b> Advantages</a></li>
<li class="chapter" data-level="5.5.4" data-path="decision-trees.html"><a href="decision-trees.html#disadvantages"><i class="fa fa-check"></i><b>5.5.4</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html"><i class="fa fa-check"></i><b>5.6</b> Other simple, interpretable models</a><ul>
<li class="chapter" data-level="5.6.1" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html#naive-bayes-classifier"><i class="fa fa-check"></i><b>5.6.1</b> Naive bayes classifier</a></li>
<li class="chapter" data-level="5.6.2" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html#k-nearest-neighbours"><i class="fa fa-check"></i><b>5.6.2</b> k-nearest neighbours</a></li>
<li class="chapter" data-level="5.6.3" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html#rulefit"><i class="fa fa-check"></i><b>5.6.3</b> RuleFit</a></li>
<li class="chapter" data-level="5.6.4" data-path="other-simple-interpretable-models.html"><a href="other-simple-interpretable-models.html#and-so-many-more"><i class="fa fa-check"></i><b>5.6.4</b> And so many more …</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="agnostic.html"><a href="agnostic.html"><i class="fa fa-check"></i><b>6</b> Model-agnostic tools for interpretability</a><ul>
<li class="chapter" data-level="6.1" data-path="pdp.html"><a href="pdp.html"><i class="fa fa-check"></i><b>6.1</b> Partial dependence plot</a></li>
<li class="chapter" data-level="6.2" data-path="individual-conditional-expectation-ice-plot.html"><a href="individual-conditional-expectation-ice-plot.html"><i class="fa fa-check"></i><b>6.2</b> Individual Conditional Expectation (ICE) plot</a></li>
<li class="chapter" data-level="6.3" data-path="permutation-feature-importance.html"><a href="permutation-feature-importance.html"><i class="fa fa-check"></i><b>6.3</b> Permutation feature importance</a><ul>
<li class="chapter" data-level="6.3.1" data-path="permutation-feature-importance.html"><a href="permutation-feature-importance.html#model-dependent-feature-importance"><i class="fa fa-check"></i><b>6.3.1</b> Model dependent feature importance</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="local-surrogate-models-lime.html"><a href="local-surrogate-models-lime.html"><i class="fa fa-check"></i><b>6.4</b> Local surrogate models (LIME)</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interpretable machine learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="pdp" class="section level2">
<h2><span class="header-section-number">6.1</span> Partial dependence plot</h2>
<p>The partial dependence plot shows the marginal effect of a variable on the target (regression / classification) <span class="citation">(J. H. Friedman <a href="#ref-friedman2001greedy">2001</a>)</span>. A partial dependence plot can show if the relationship between target and feature is linear, monotonic or something else. In linear regression, those plots will always show a linear relationship.</p>
<p>The partial dependence function for regression is defined as: <span class="math display">\[f_S = E_{x_C}[f(x_S, x_C)] = \int f(x_S, x_C) dP(x_C)\]</span> The <span class="math inline">\(x_S\)</span> is the set of variables for which the partial dependence should be depicted and <span class="math inline">\(x_C\)</span> are the other variables that were used in the machine learning model. Partial dependence works by averaging out the other variables, so that the remaining function shows the relationsship between the <span class="math inline">\(x_S\)</span>, in which we are interested, and the target. <span class="math inline">\(x_S\)</span> is fixed and <span class="math inline">\(x_C\)</span> is varying.</p>
<p>The integral is estimated by calculating averages in the training data, which looks like this for regression: <span class="math display">\[ \hat{f}(x_S) = \frac{1}{n} \sum_{i=1}^n f(x_S, x_{Ci}) \]</span> In this formula, <span class="math inline">\(x\)</span> is the variable for which to calculate the partial dependence, <span class="math inline">\(x_{iC}\)</span> is the other variables and <span class="math inline">\(n\)</span> the number of instances in the data set.</p>
<p>For classification it is the logits: <span class="math display">\[ f(x) = \log p_k(x) - \frac{1}{K} \sum_{j=1}^K \log p_j(x) \]</span></p>
<p>Partial dependence plots are only partially global: They are global because they take into account all instances, but it is local in the feature, because partial dependence plots only examine one variable, as the name suggests.</p>
<div id="examples" class="section level4">
<h4><span class="header-section-number">6.1.0.1</span> Examples</h4>
<p>In practice <span class="math inline">\(x_S\)</span> usually only contains one variable or a maximum of two, because one variable produces 2D plots and two variables produce 3D plots. Everything beyond that is quite tricky. Even 3D on a 2D paper or monitor is already challenging. This example here shows an artificial dataset with two x variables on which a Random Forest was trained.</p>
<div class="figure"><span id="fig:dpd-cervical"></span>
<img src="xai-book_files/figure-html/dpd-cervical-1.svg" alt="Partial dependence plot of cancer probability and different factors. For the age feature, the models partial dependence shows that on average, the cancer probability is low before 45, spikes between age 45 and 55 and plateaus after that." width="672" />
<p class="caption">
FIGURE 6.2: Partial dependence plot of cancer probability and different factors. For the age feature, the models partial dependence shows that on average, the cancer probability is low before 45, spikes between age 45 and 55 and plateaus after that.
</p>
</div>
<div class="figure"><span id="fig:dpd-cervical-2d"></span>
<img src="xai-book_files/figure-html/dpd-cervical-2d-1.svg" alt="Partial dependence plot of cancer probability and the interaction of number of years on hormonal contraceptives and number of sexual partners. Interestingly, there is some odd interaction between the two variables when the number of sexual partners is 1 and the years of on hormonal contraceptives larger than 12. There are actually only two women in that group, who both happen to have cancer. So my best guess is that this was random and the model did overfit on those two women, but only more data could solve this question. " width="672" />
<p class="caption">
FIGURE 6.3: Partial dependence plot of cancer probability and the interaction of number of years on hormonal contraceptives and number of sexual partners. Interestingly, there is some odd interaction between the two variables when the number of sexual partners is 1 and the years of on hormonal contraceptives larger than 12. There are actually only two women in that group, who both happen to have cancer. So my best guess is that this was random and the model did overfit on those two women, but only more data could solve this question.
</p>
</div>
<p>Let’s turn to the regression example with the bike counts again and have a look at how the weather effects look like. @ref{fig:dpd-bike} shows the average influence of the weather features on the predicted bike counts. Warm, but not too hot weather makes the model predict a high number of bikes rentals. The potential bikers are increasingly inhibited in engaging in cycling when humidity reaches above 60%. Also the more wind the less people like to bike, which personally I can understand. Interestingly the predicted bike counts don’t drop between 25 and 35 km/h, but maybe there is just not enough training data. At least intuitively I would expect the bike rentals to drop with each increase in windspeed, especially when the windspeed is very high.</p>
<div class="figure"><span id="fig:dpd-bike"></span>
<img src="xai-book_files/figure-html/dpd-bike-1.svg" alt="Partial dependence plot of rental bike count and different weather measurements (Temperature, Humidity, Windspeed). The biggest differences can be seen in different temperatures: With rising temperatures, on average the bike rentals rise, until 20C degrees, where it stays the same also for hotter temperatures and drops a bit again towards 30C degrees." width="672" />
<p class="caption">
FIGURE 6.4: Partial dependence plot of rental bike count and different weather measurements (Temperature, Humidity, Windspeed). The biggest differences can be seen in different temperatures: With rising temperatures, on average the bike rentals rise, until 20C degrees, where it stays the same also for hotter temperatures and drops a bit again towards 30C degrees.
</p>
</div>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-friedman2001greedy">
<p>Friedman, Jerome H. 2001. “Greedy Function Approximation: A Gradient Boosting Machine.” <em>Annals of Statistics</em>. JSTOR, 1189–1232.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="agnostic.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="individual-conditional-expectation-ice-plot.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/christophM/xai-book/edit/master/05.2-agnostic-pdp.Rmd",
"text": "Edit"
},
"download": ["xai-book.pdf"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

<!-- </html> -->
